{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "id": "initial_id",
    "ExecuteTime": {
     "end_time": "2023-12-13T13:30:40.566225Z",
     "start_time": "2023-12-13T13:30:40.559411Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "mps_device = (torch.device(\"mps\") if torch.backends.mps.is_available() \n",
    "              else (torch.device(\"cuda\") if torch.backends.cuda.is_available()\n",
    "                    else torch.device(\"cpu\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "# Code Generation\n",
    "def generator(nr_codewords):\n",
    "    bits = torch.randint(0, 2, size=(nr_codewords, 1, 4), dtype=torch.int)\n",
    "    \n",
    "    return bits"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7b31da2dd38f4534",
    "outputId": "941e26ab-ff67-47b7-bf33-df31f8d4fd03",
    "ExecuteTime": {
     "end_time": "2023-12-13T13:30:40.897345Z",
     "start_time": "2023-12-13T13:30:40.891087Z"
    }
   },
   "id": "7b31da2dd38f4534"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000000, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "# Code Generator\n",
    "num = 1000000\n",
    "bits_info = generator(num)\n",
    "print(bits_info.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T13:30:41.219740Z",
     "start_time": "2023-12-13T13:30:41.200207Z"
    }
   },
   "id": "4c9b01bfcb95858f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hamming(7,4) Encoder"
   ],
   "metadata": {
    "collapsed": false,
    "id": "784df2c8e94a416e"
   },
   "id": "784df2c8e94a416e"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "class hamming_encode(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Use Hamming(7,4) to encode the data.\n",
    "\n",
    "        Args:\n",
    "            data: data received from the Hamming(7,4) encoder(Tensor)\n",
    "            generator matrix: generate the parity code\n",
    "\n",
    "        Returns:\n",
    "            encoded data: 4 bits original info with 3 parity code.\n",
    "        \"\"\"\n",
    "        super(hamming_encode, self).__init__()\n",
    "\n",
    "        # Define the generator matrix for Hamming(7,4)\n",
    "        self.generator_matrix = torch.tensor([\n",
    "            [1, 0, 0, 0],\n",
    "            [0, 1, 0, 0],\n",
    "            [0, 0, 1, 0],\n",
    "            [0, 0, 0, 1],\n",
    "            [1, 1, 0, 1],\n",
    "            [1, 0, 1, 1],\n",
    "            [0, 1, 1, 1],\n",
    "        ], dtype=torch.int)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        # Ensure input_data has shape (batch_size)\n",
    "        # assert input_data.size(0) == self.generator_matrix.shape[1], \"Input data must have same generator matrix row number bits.\"\n",
    "\n",
    "        # Perform matrix multiplication to encode the data\n",
    "        # result_tensor = (self.generator_matrix @ input_data.squeeze(1).mT).unsqueeze(1).T % 2\n",
    "        result_tensor = torch.matmul(input_data, self.generator_matrix.t())% 2\n",
    "\n",
    "        return result_tensor"
   ],
   "metadata": {
    "id": "134dff35e9552bc9",
    "ExecuteTime": {
     "end_time": "2023-12-13T13:30:41.799088Z",
     "start_time": "2023-12-13T13:30:41.793759Z"
    }
   },
   "id": "134dff35e9552bc9"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000000, 1, 7])\n"
     ]
    }
   ],
   "source": [
    "# Generation Encoded Data with 3 parity bits\n",
    "encoder = hamming_encode()\n",
    "encoded_codeword = encoder(bits_info)\n",
    "print(encoded_codeword.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7e7229a532d19f6",
    "outputId": "3d2f3232-43e7-4b63-974f-643c249450f8",
    "ExecuteTime": {
     "end_time": "2023-12-13T13:30:42.069513Z",
     "start_time": "2023-12-13T13:30:42.045717Z"
    }
   },
   "id": "7e7229a532d19f6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "BPSK Modulator + Noise"
   ],
   "metadata": {
    "collapsed": false,
    "id": "82e4a0c53752581c"
   },
   "id": "82e4a0c53752581c"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "# BPSK Modulator and Add Noise After Modulator\n",
    "class bpsk_modulator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Use BPSK to compress the data, which is easily to transmit.\n",
    "\n",
    "        Args:\n",
    "            codeword: data received from the Hamming(7,4) encoder(Tensor)\n",
    "\n",
    "        Returns:\n",
    "            data: Tensor contain all data modulated and add noise\n",
    "        \"\"\"\n",
    "        super(bpsk_modulator, self).__init__()\n",
    "\n",
    "    def forward(self, codeword, snr_dB):\n",
    "\n",
    "        # data = torch.tensor(data, dtype=float)\n",
    "        data = codeword.to(dtype=torch.float).to(mps_device)\n",
    "\n",
    "        # for i in range(data.shape[0]):\n",
    "        bits = data\n",
    "        bits = 2 * bits - 1\n",
    "\n",
    "        # Add Gaussian noise to the signal\n",
    "        noise_power = torch.tensor(10**(snr_dB / 10)).to(mps_device)\n",
    "        noise = torch.sqrt(1/(2*noise_power)) * torch.randn(bits.shape).to(mps_device)\n",
    "        noised_signal = bits + noise\n",
    "        # noised_signal = bits\n",
    "        data = noised_signal\n",
    "\n",
    "        return data"
   ],
   "metadata": {
    "id": "dea8f68cc3a6fb4f",
    "ExecuteTime": {
     "end_time": "2023-12-13T13:30:42.827529Z",
     "start_time": "2023-12-13T13:30:42.826357Z"
    }
   },
   "id": "dea8f68cc3a6fb4f"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.1794, -1.0887, -1.2484,  ...,  1.0919,  1.1016,  0.8902]],\n",
      "\n",
      "        [[-1.2424,  0.9542,  0.9314,  ..., -1.0613, -0.7330,  0.9257]],\n",
      "\n",
      "        [[-0.8988, -0.8386, -1.1047,  ..., -0.9659, -0.8618, -1.1255]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.3118,  1.1157,  0.8852,  ...,  1.0301,  1.1199, -0.8756]],\n",
      "\n",
      "        [[-0.8007, -1.1107,  0.9576,  ..., -1.0276,  0.8937,  0.9686]],\n",
      "\n",
      "        [[-1.0542,  1.2124, -1.0792,  ..., -1.1565,  0.9164, -1.1164]]],\n",
      "       device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "snr_dB = 15  # Signal-to-noise ratio in dB\n",
    "\n",
    "# Modulate the signal\n",
    "modulator = bpsk_modulator()\n",
    "modulated_noise_signal = modulator(encoded_codeword.to(mps_device), snr_dB)\n",
    "print(modulated_noise_signal)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "590464d8549a0582",
    "outputId": "8648f5a5-9b6a-4ea5-f5ed-54e70b98a1b1",
    "ExecuteTime": {
     "end_time": "2023-12-13T13:30:43.257861Z",
     "start_time": "2023-12-13T13:30:43.147534Z"
    }
   },
   "id": "590464d8549a0582"
  },
  {
   "cell_type": "markdown",
   "source": [
    "LLR Log-likelihood\n",
    "y = s + n\n",
    "Assuming that \\( s \\) is equally likely to be 0 or 1, and \\( n \\) is Gaussian with zero mean and variance \\( N_0/2 \\), where \\( N_0 \\) is the noise power spectral density.\n"
   ],
   "metadata": {
    "collapsed": false,
    "id": "b788f8a37d6c4add"
   },
   "id": "b788f8a37d6c4add"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "# Log-Likelihood Ratio\n",
    "def llr(signal, snr):\n",
    "    \"\"\"\n",
    "    Calculate Log Likelihood Ratio (LLR) for a simple binary symmetric channel.\n",
    "\n",
    "    Args:\n",
    "        signal (torch.Tensor): Received signal from BPSK.\n",
    "        noise_std (float): Standard deviation of the noise.\n",
    "\n",
    "    Returns:\n",
    "        llr: Log Likelihood Ratio (LLR) values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Assuming Binary Phase Shift Keying (BPSK) modulation\n",
    "    noise_std = torch.sqrt(torch.tensor(10**(snr / 10))).to(mps_device)\n",
    "\n",
    "    # Calculate the LLR\n",
    "    llr = 2 * signal * noise_std\n",
    "\n",
    "    # return llr_values, llr\n",
    "    return llr\n"
   ],
   "metadata": {
    "id": "5db7bbc0fe148325",
    "ExecuteTime": {
     "end_time": "2023-12-13T13:30:44.045792Z",
     "start_time": "2023-12-13T13:30:44.041157Z"
    }
   },
   "id": "5db7bbc0fe148325"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLR values: tensor([[[-13.2640, -12.2450, -14.0406,  ...,  12.2805,  12.3900,  10.0125]],\n",
      "\n",
      "        [[-13.9731,  10.7321,  10.4756,  ..., -11.9363,  -8.2445,  10.4110]],\n",
      "\n",
      "        [[-10.1083,  -9.4312, -12.4245,  ..., -10.8637,  -9.6928, -12.6587]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-14.7534,  12.5476,   9.9557,  ...,  11.5848,  12.5955,  -9.8475]],\n",
      "\n",
      "        [[ -9.0055, -12.4915,  10.7704,  ..., -11.5576,  10.0509,  10.8933]],\n",
      "\n",
      "        [[-11.8569,  13.6357, -12.1371,  ..., -13.0068,  10.3061, -12.5563]]],\n",
      "       device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "llr_output = llr(modulated_noise_signal, snr_dB)\n",
    "print(\"LLR values:\", llr_output)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d02cfd5d533e6248",
    "outputId": "79523dc1-c5f6-46ea-c3b1-7593deb12a97",
    "ExecuteTime": {
     "end_time": "2023-12-13T13:30:44.401328Z",
     "start_time": "2023-12-13T13:30:44.376991Z"
    }
   },
   "id": "d02cfd5d533e6248"
  },
  {
   "cell_type": "markdown",
   "source": [
    "LDPC Decoder\n",
    "\n",
    "Strange behavior recording:\n",
    "In 100 7-bit codewords, the speed on MPS(GPU) is slower than CPU. Reason unknown."
   ],
   "metadata": {
    "collapsed": false,
    "id": "73cde4898560777a"
   },
   "id": "73cde4898560777a"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "class LDPCBeliefPropagation(torch.nn.Module):\n",
    "    def __init__(self, H, llr):\n",
    "        \"\"\"\n",
    "        LDPC Belief Propagation.\n",
    "\n",
    "        Args:\n",
    "            H: Low density parity code for building tanner graph.\n",
    "            llr: Log Likelihood Ratio (LLR) values. Only for 7-bit codeword.\n",
    "\n",
    "        Returns:\n",
    "            estimated_bits: the output result from belief propagation.\n",
    "        \"\"\"\n",
    "\n",
    "        super(LDPCBeliefPropagation, self).__init__()\n",
    "        self.llr = llr\n",
    "        self.H = H\n",
    "        self.num_check_nodes, self.num_variable_nodes = H.shape\n",
    "        self.channel = llr.shape[2]\n",
    "\n",
    "        # Initialize messages\n",
    "        self.messages_v_to_c = torch.ones((self.num_variable_nodes, self.num_check_nodes, self.channel), dtype=torch.float).to(mps_device)\n",
    "        self.messages_c_to_v = torch.zeros((self.num_check_nodes, self.num_variable_nodes, self.channel), dtype=torch.float).to(mps_device)\n",
    "\n",
    "    def forward(self, max_iter):\n",
    "        # start_time = time.time()\n",
    "        for iteration in range(max_iter):\n",
    "            \n",
    "            # Variable to check node messages\n",
    "            for i in range(self.num_variable_nodes):\n",
    "                for j in range(self.num_check_nodes):\n",
    "                    \n",
    "                    # Compute messages from variable to check nodes\n",
    "                    connected_checks = self.H[j, :] == 1\n",
    "                    product = torch.prod(torch.tanh(0.5 * self.messages_v_to_c[connected_checks, j]),dim=0, keepdim=True)\n",
    "                    self.messages_v_to_c[i, j] = torch.sign(self.llr[j]) * product\n",
    "\n",
    "            # Check to variable node messages\n",
    "            for i in range(self.num_check_nodes):\n",
    "                for j in range(self.num_variable_nodes):\n",
    "                    \n",
    "                    # Compute messages from check to variable nodes\n",
    "                    connected_vars = self.H[:, j] == 1\n",
    "                    sum_msgs = torch.sum(self.messages_c_to_v[connected_vars, i]) - self.messages_v_to_c[j, i]\n",
    "                    self.messages_c_to_v[i, j] = 2 * torch.atan(torch.exp(0.5 * sum_msgs))\n",
    "\n",
    "        # Calculate the final estimated bits and only take first four bits\n",
    "        estimated_bits = torch.sign(self.llr) * torch.prod(torch.tanh(0.5 * self.messages_c_to_v))\n",
    "        tensor_1 = torch.tensor(1, device=mps_device)\n",
    "        tensor_0 = torch.tensor(0, device=mps_device)\n",
    "        estimated_bits = torch.where(estimated_bits > 0, tensor_1, tensor_0)\n",
    "        estimated_bits = estimated_bits[:, :, 0:4]\n",
    "        \n",
    "        return estimated_bits"
   ],
   "metadata": {
    "id": "43cceb3e29b1f0cb",
    "ExecuteTime": {
     "end_time": "2023-12-13T13:30:45.219246Z",
     "start_time": "2023-12-13T13:30:45.217478Z"
    }
   },
   "id": "43cceb3e29b1f0cb"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "def hard_decision_cutter(estimated_bits):\n",
    "    tensor_1 = torch.tensor(1, device=mps_device)\n",
    "    tensor_0 = torch.tensor(0, device=mps_device)\n",
    "    estimated_bits = torch.where(estimated_bits > 0, tensor_1, tensor_0)\n",
    "    estimated_bits = estimated_bits[:, :, 0:4]\n",
    "\n",
    "    return estimated_bits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T13:30:45.723145Z",
     "start_time": "2023-12-13T13:30:45.719352Z"
    }
   },
   "id": "4263bbf358f6d192"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 0, 0, 1]],\n",
      "\n",
      "        [[0, 1, 1, 1]],\n",
      "\n",
      "        [[0, 0, 0, 0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0, 1, 1, 0]],\n",
      "\n",
      "        [[0, 0, 1, 0]],\n",
      "\n",
      "        [[0, 1, 0, 1]]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "H = torch.tensor([ [1, 1, 1, 0, 0, 0, 0],\n",
    "                   [0, 0, 1, 1, 1, 0, 0],\n",
    "                   [0, 1, 0, 0, 1, 1, 0],\n",
    "                   [1, 0, 0, 1, 0, 0, 1],], device=mps_device)\n",
    "iter = 20\n",
    "ldpc_bp = LDPCBeliefPropagation(H, llr_output.to(mps_device))\n",
    "LDPC_result = ldpc_bp(iter)\n",
    "final_result = hard_decision_cutter(LDPC_result)\n",
    "\n",
    "print(LDPC_result)\n",
    "# print(f\"The Entire LDPC Belief propagation runs {time} seconds\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "id": "5048c8da067aea80",
    "outputId": "dbb58e4a-710a-42aa-9293-5ac1bf454797",
    "ExecuteTime": {
     "end_time": "2023-12-13T13:30:47.550819Z",
     "start_time": "2023-12-13T13:30:46.201283Z"
    }
   },
   "id": "5048c8da067aea80"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Comparation and Plot"
   ],
   "metadata": {
    "collapsed": false,
    "id": "f13d4e59b49c277b"
   },
   "id": "f13d4e59b49c277b"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "def calculate_ber(transmitted_bits, origin_bits):\n",
    "    # Ensure that both tensors have the same shape\n",
    "    assert transmitted_bits.shape == origin_bits.shape, \"Shapes of transmitted and received bits must be the same.\"\n",
    "\n",
    "    # Calculate the bit errors\n",
    "    errors = (transmitted_bits != origin_bits).sum().item()\n",
    "\n",
    "    # Calculate the Bit Error Rate (BER)\n",
    "    ber = errors / transmitted_bits.numel()\n",
    "\n",
    "    return ber"
   ],
   "metadata": {
    "id": "c7d315e8c561e18a",
    "outputId": "1a5d83c8-593f-47c6-ddd9-de152dce2fb2",
    "ExecuteTime": {
     "end_time": "2023-12-13T13:30:49.187257Z",
     "start_time": "2023-12-13T13:30:49.185605Z"
    }
   },
   "id": "c7d315e8c561e18a"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Describe the data:\n",
    "# bits_info: original signal\n",
    "bits_info = bits_info.to(mps_device)\n",
    "decoded_bits = final_result #output from Maximum Likelihood\n",
    "# decoded_bits = llr_output # Output from log-likelihood\n",
    "# decoded_bits =\n",
    "\n",
    "ber = calculate_ber(decoded_bits, bits_info)\n",
    "print(ber)"
   ],
   "metadata": {
    "id": "5c3bdfb073f882f6",
    "ExecuteTime": {
     "end_time": "2023-12-13T13:30:49.612388Z",
     "start_time": "2023-12-13T13:30:49.603165Z"
    }
   },
   "id": "5c3bdfb073f882f6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "66742211391abf76"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
