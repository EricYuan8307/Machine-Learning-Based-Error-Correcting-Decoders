{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-11T11:09:27.210549Z",
     "start_time": "2023-12-11T11:09:26.045745Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 0, 1],\n",
      "        [1, 0, 0, 1],\n",
      "        [1, 0, 1, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [1, 1, 0, 0],\n",
      "        [0, 1, 1, 0],\n",
      "        [0, 0, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [0, 1, 0, 0],\n",
      "        [1, 0, 0, 0],\n",
      "        [1, 0, 1, 1],\n",
      "        [1, 0, 1, 0],\n",
      "        [1, 0, 1, 0],\n",
      "        [1, 1, 0, 1],\n",
      "        [0, 1, 1, 0],\n",
      "        [0, 0, 0, 1],\n",
      "        [0, 1, 0, 1],\n",
      "        [1, 0, 0, 1],\n",
      "        [0, 0, 0, 1],\n",
      "        [1, 0, 1, 1],\n",
      "        [1, 1, 0, 0],\n",
      "        [0, 1, 1, 0],\n",
      "        [0, 0, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 0, 1],\n",
      "        [1, 0, 0, 1],\n",
      "        [1, 0, 0, 1],\n",
      "        [1, 0, 0, 1],\n",
      "        [1, 1, 0, 0],\n",
      "        [1, 1, 0, 1],\n",
      "        [0, 1, 1, 1],\n",
      "        [0, 1, 0, 0],\n",
      "        [1, 1, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 1, 1, 1],\n",
      "        [0, 0, 1, 1],\n",
      "        [0, 1, 1, 0],\n",
      "        [1, 0, 1, 1],\n",
      "        [1, 1, 1, 0],\n",
      "        [1, 0, 1, 1],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 1, 0, 1],\n",
      "        [1, 1, 0, 1],\n",
      "        [0, 0, 0, 0],\n",
      "        [1, 1, 0, 1],\n",
      "        [1, 1, 0, 0],\n",
      "        [0, 1, 0, 1],\n",
      "        [1, 1, 1, 0],\n",
      "        [1, 0, 0, 1],\n",
      "        [1, 0, 0, 0],\n",
      "        [1, 0, 0, 0],\n",
      "        [1, 1, 1, 1],\n",
      "        [0, 1, 0, 0],\n",
      "        [0, 0, 1, 1],\n",
      "        [1, 1, 0, 0],\n",
      "        [0, 0, 1, 1],\n",
      "        [0, 0, 0, 1],\n",
      "        [0, 1, 1, 0],\n",
      "        [1, 1, 0, 1],\n",
      "        [1, 0, 0, 1],\n",
      "        [1, 0, 1, 1],\n",
      "        [1, 0, 0, 0],\n",
      "        [1, 1, 0, 1],\n",
      "        [1, 0, 0, 1],\n",
      "        [0, 1, 1, 1],\n",
      "        [0, 0, 1, 0],\n",
      "        [0, 0, 1, 0],\n",
      "        [0, 0, 0, 1],\n",
      "        [1, 0, 0, 0],\n",
      "        [1, 1, 1, 1],\n",
      "        [0, 0, 1, 0],\n",
      "        [1, 0, 1, 0],\n",
      "        [0, 0, 0, 1],\n",
      "        [1, 1, 0, 1],\n",
      "        [0, 1, 1, 1],\n",
      "        [1, 0, 1, 1],\n",
      "        [0, 1, 1, 1],\n",
      "        [1, 0, 1, 0],\n",
      "        [0, 1, 0, 1],\n",
      "        [1, 0, 1, 0],\n",
      "        [1, 0, 0, 1],\n",
      "        [1, 0, 1, 0],\n",
      "        [1, 1, 0, 0],\n",
      "        [1, 0, 1, 0],\n",
      "        [0, 1, 0, 1],\n",
      "        [0, 0, 1, 0],\n",
      "        [1, 1, 1, 1],\n",
      "        [0, 1, 0, 0],\n",
      "        [1, 1, 0, 0],\n",
      "        [0, 0, 0, 1],\n",
      "        [1, 1, 1, 0],\n",
      "        [0, 1, 0, 0],\n",
      "        [1, 1, 0, 1],\n",
      "        [0, 1, 0, 0],\n",
      "        [0, 0, 1, 0],\n",
      "        [1, 1, 0, 0],\n",
      "        [0, 0, 1, 0],\n",
      "        [1, 1, 1, 0],\n",
      "        [1, 1, 0, 1],\n",
      "        [1, 1, 1, 0]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# Code Generation\n",
    "message = \"1101\"  # 4-bit binary message\n",
    "\n",
    "nr_codewords = int(100)\n",
    "bits_info = torch.randint(2, (nr_codewords, 4), dtype=torch.int)\n",
    "\n",
    "print(bits_info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T11:14:04.993607Z",
     "start_time": "2023-12-11T11:14:04.984846Z"
    }
   },
   "id": "7b31da2dd38f4534"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hamming(7,4) Encoder"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "784df2c8e94a416e"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "class hamming_encode(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "            Use Hamming(7,4) to encode the data.\n",
    "    \n",
    "        Args:\n",
    "            data: data received from the Hamming(7,4) encoder(Tensor)\n",
    "            generator matrix: generate the parity code\n",
    "    \n",
    "        Returns:\n",
    "            encoded data: 4 bits original info with 3 parity code.\n",
    "        \"\"\"\n",
    "        super(hamming_encode, self).__init__()\n",
    "\n",
    "        # Define the generator matrix for Hamming(7,4)\n",
    "        self.generator_matrix = torch.tensor([\n",
    "            [1, 0, 0, 0],\n",
    "            [0, 1, 0, 0],\n",
    "            [0, 0, 1, 0],\n",
    "            [0, 0, 0, 1],\n",
    "            [1, 1, 0, 1],\n",
    "            [1, 0, 1, 1],\n",
    "            [0, 1, 1, 1],\n",
    "        ], dtype=torch.int)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        # Ensure input_data has shape (batch_size, 4)\n",
    "        assert input_data.size(1) == 4, \"Input data must have 4 bits.\"\n",
    "\n",
    "        # Perform matrix multiplication to encode the data\n",
    "        encoded_data = torch.matmul(input_data, self.generator_matrix.t()) % 2\n",
    "\n",
    "        return encoded_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T11:14:06.397397Z",
     "start_time": "2023-12-11T11:14:06.392456Z"
    }
   },
   "id": "134dff35e9552bc9"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 0, 1, 0, 0, 1],\n",
      "        [1, 0, 0, 1, 0, 0, 1],\n",
      "        [1, 0, 1, 0, 1, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 0, 0, 0, 1, 1],\n",
      "        [0, 1, 1, 0, 1, 1, 0],\n",
      "        [0, 0, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 1, 0, 0, 1, 0, 1],\n",
      "        [1, 0, 0, 0, 1, 1, 0],\n",
      "        [1, 0, 1, 1, 0, 1, 0],\n",
      "        [1, 0, 1, 0, 1, 0, 1],\n",
      "        [1, 0, 1, 0, 1, 0, 1],\n",
      "        [1, 1, 0, 1, 1, 0, 0],\n",
      "        [0, 1, 1, 0, 1, 1, 0],\n",
      "        [0, 0, 0, 1, 1, 1, 1],\n",
      "        [0, 1, 0, 1, 0, 1, 0],\n",
      "        [1, 0, 0, 1, 0, 0, 1],\n",
      "        [0, 0, 0, 1, 1, 1, 1],\n",
      "        [1, 0, 1, 1, 0, 1, 0],\n",
      "        [1, 1, 0, 0, 0, 1, 1],\n",
      "        [0, 1, 1, 0, 1, 1, 0],\n",
      "        [0, 0, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 0, 1, 1, 0, 0],\n",
      "        [1, 0, 0, 1, 0, 0, 1],\n",
      "        [1, 0, 0, 1, 0, 0, 1],\n",
      "        [1, 0, 0, 1, 0, 0, 1],\n",
      "        [1, 1, 0, 0, 0, 1, 1],\n",
      "        [1, 1, 0, 1, 1, 0, 0],\n",
      "        [0, 1, 1, 1, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 1, 0, 1],\n",
      "        [1, 1, 0, 0, 0, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 1, 1, 0, 0, 1],\n",
      "        [0, 0, 1, 1, 1, 0, 0],\n",
      "        [0, 1, 1, 0, 1, 1, 0],\n",
      "        [1, 0, 1, 1, 0, 1, 0],\n",
      "        [1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 0, 1, 1, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 1, 0, 1, 0],\n",
      "        [1, 1, 0, 1, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 0, 1, 1, 0, 0],\n",
      "        [1, 1, 0, 0, 0, 1, 1],\n",
      "        [0, 1, 0, 1, 0, 1, 0],\n",
      "        [1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 1, 0, 0, 1],\n",
      "        [1, 0, 0, 0, 1, 1, 0],\n",
      "        [1, 0, 0, 0, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 1, 0, 0, 1, 0, 1],\n",
      "        [0, 0, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 0, 0, 0, 1, 1],\n",
      "        [0, 0, 1, 1, 1, 0, 0],\n",
      "        [0, 0, 0, 1, 1, 1, 1],\n",
      "        [0, 1, 1, 0, 1, 1, 0],\n",
      "        [1, 1, 0, 1, 1, 0, 0],\n",
      "        [1, 0, 0, 1, 0, 0, 1],\n",
      "        [1, 0, 1, 1, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 1, 1, 0],\n",
      "        [1, 1, 0, 1, 1, 0, 0],\n",
      "        [1, 0, 0, 1, 0, 0, 1],\n",
      "        [0, 1, 1, 1, 0, 0, 1],\n",
      "        [0, 0, 1, 0, 0, 1, 1],\n",
      "        [0, 0, 1, 0, 0, 1, 1],\n",
      "        [0, 0, 0, 1, 1, 1, 1],\n",
      "        [1, 0, 0, 0, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 1, 0, 0, 1, 1],\n",
      "        [1, 0, 1, 0, 1, 0, 1],\n",
      "        [0, 0, 0, 1, 1, 1, 1],\n",
      "        [1, 1, 0, 1, 1, 0, 0],\n",
      "        [0, 1, 1, 1, 0, 0, 1],\n",
      "        [1, 0, 1, 1, 0, 1, 0],\n",
      "        [0, 1, 1, 1, 0, 0, 1],\n",
      "        [1, 0, 1, 0, 1, 0, 1],\n",
      "        [0, 1, 0, 1, 0, 1, 0],\n",
      "        [1, 0, 1, 0, 1, 0, 1],\n",
      "        [1, 0, 0, 1, 0, 0, 1],\n",
      "        [1, 0, 1, 0, 1, 0, 1],\n",
      "        [1, 1, 0, 0, 0, 1, 1],\n",
      "        [1, 0, 1, 0, 1, 0, 1],\n",
      "        [0, 1, 0, 1, 0, 1, 0],\n",
      "        [0, 0, 1, 0, 0, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 1, 0, 0, 1, 0, 1],\n",
      "        [1, 1, 0, 0, 0, 1, 1],\n",
      "        [0, 0, 0, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 1, 0, 1],\n",
      "        [1, 1, 0, 1, 1, 0, 0],\n",
      "        [0, 1, 0, 0, 1, 0, 1],\n",
      "        [0, 0, 1, 0, 0, 1, 1],\n",
      "        [1, 1, 0, 0, 0, 1, 1],\n",
      "        [0, 0, 1, 0, 0, 1, 1],\n",
      "        [1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 0, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 0, 0, 0, 0]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "encoder = hamming_encode()\n",
    "encoded_codeword = encoder(bits_info)\n",
    "print(encoded_codeword)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T11:25:25.140732Z",
     "start_time": "2023-12-11T11:25:25.123415Z"
    }
   },
   "id": "7e7229a532d19f6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "BPSK Modulator + Noise"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82e4a0c53752581c"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "class bpsk_modulator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Use BPSK to compress the data, which is easily to transmit.\n",
    "\n",
    "    Args:\n",
    "        data: data received from the Hamming(7,4) encoder(Tensor)\n",
    "        symbol_rate: Symbol rate in Hz\n",
    "        carrier_freq: Carrier frequency in Hz\n",
    "        snr_dB: Signal-to-noise ratio in dB\n",
    "\n",
    "    Returns:\n",
    "        time:\n",
    "        data: Tensor contain all data modulated and add noise\n",
    "    \"\"\"\n",
    "        super(bpsk_modulator, self).__init__()\n",
    "        \n",
    "    def forward(self, data, snr_dB):\n",
    "        \n",
    "        data = torch.tensor(data, dtype=float)\n",
    "    \n",
    "        for i in range(data.shape[0]):\n",
    "            bits = data[i]\n",
    "            bits = 2 * bits - 1\n",
    "            # # Time vector\n",
    "            # time = torch.arange(0, len(bits) / symbol_rate, 1 / symbol_rate)\n",
    "            # \n",
    "            # # Generate carrier signal\n",
    "            # carrier = torch.cos(2 * torch.pi * carrier_freq * time)\n",
    "            # \n",
    "            # # Modulate the signal\n",
    "            # modulated_signal = bits * carrier\n",
    "        \n",
    "            # Add Gaussian noise to the signal\n",
    "            noise_power = torch.tensor(10**(snr_dB / 10),dtype=float)\n",
    "            noise = torch.sqrt(1/(2*noise_power)) * torch.randn(len(bits))\n",
    "            noised_signal = bits + noise\n",
    "            # noised_signal = bits\n",
    "            data[i] = noised_signal\n",
    "    \n",
    "       \n",
    "        return noise, data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T11:25:26.048422Z",
     "start_time": "2023-12-11T11:25:26.047579Z"
    }
   },
   "id": "dea8f68cc3a6fb4f"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1356, -1.0319, -1.2670,  0.8640, -0.9235, -0.9398,  1.0116],\n",
      "        [ 1.0726, -1.2415, -1.1227,  0.9281, -1.3855, -0.8948,  1.0067],\n",
      "        [ 0.9800, -1.1354,  0.9820, -1.0719,  1.0190, -0.9455,  1.0727],\n",
      "        [-0.8565, -0.8988, -1.2232, -1.1923, -0.8988, -0.6559, -0.9790],\n",
      "        [ 1.1416,  1.0133, -1.0527, -0.9339, -0.9282,  1.1630,  1.2177],\n",
      "        [-1.0642,  0.9368,  1.0492, -1.0012,  0.9867,  1.0068, -1.0920],\n",
      "        [-0.9671, -1.1181,  0.9164,  0.7962,  0.8515, -1.2860, -0.9307],\n",
      "        [ 0.7492,  1.0158,  0.9771,  1.0294,  1.1220,  0.9667,  1.0257],\n",
      "        [-0.7444,  1.0905, -1.2242, -1.0384,  0.9787, -0.9226,  1.0915],\n",
      "        [ 1.2335, -0.9258, -1.1032, -1.0344,  1.0428,  1.0016, -1.0926],\n",
      "        [ 0.9146, -1.0622,  1.0636,  0.9424, -1.0770,  0.9649, -0.9931],\n",
      "        [ 0.9237, -0.6969,  0.7901, -1.1115,  1.0164, -1.0504,  0.9822],\n",
      "        [ 0.6927, -1.0953,  0.9389, -0.9557,  1.0981, -1.0574,  0.8030],\n",
      "        [ 0.8477,  0.9518, -1.0035,  1.0569,  0.8960, -0.9172, -0.9651],\n",
      "        [-0.9717,  1.0021,  1.0687, -1.0705,  1.0135,  0.9896, -0.7240],\n",
      "        [-0.9707, -0.9209, -0.9971,  0.9409,  1.1406,  0.7652,  1.0452],\n",
      "        [-1.1328,  1.0799, -0.9469,  0.9052, -1.0002,  1.0717, -1.1581],\n",
      "        [ 1.0043, -1.1941, -0.8654,  1.0659, -0.9192, -1.0313,  1.1143],\n",
      "        [-1.1485, -1.0984, -0.9412,  0.9917,  0.9988,  1.1079,  1.1472],\n",
      "        [ 1.1388, -1.1325,  1.0804,  1.1736, -0.9721,  1.0807, -1.0304],\n",
      "        [ 1.0515,  1.0026, -0.9901, -1.1069, -1.2310,  1.0226,  1.0645],\n",
      "        [-1.2303,  0.8323,  1.0057, -1.0069,  0.8692,  1.0420, -1.0437],\n",
      "        [-0.8036, -1.0965,  0.9368,  1.1208,  0.9800, -0.8538, -0.9536],\n",
      "        [ 1.0833,  1.1681,  0.8346,  0.8557,  1.1042,  1.0143,  1.0481],\n",
      "        [ 0.9416,  0.9551, -1.2011,  0.7671,  0.8856, -0.9815, -0.8729],\n",
      "        [ 1.0353, -1.1819, -1.1996,  0.8394, -1.0227, -0.9043,  1.0378],\n",
      "        [ 0.8987, -1.0352, -1.0597,  0.8890, -0.9572, -0.9879,  1.0210],\n",
      "        [ 0.8888, -1.2075, -1.0844,  0.7805, -1.0714, -0.9923,  1.0705],\n",
      "        [ 1.0938,  1.0363, -1.0887, -1.0077, -0.9063,  1.0736,  0.9012],\n",
      "        [ 1.0063,  1.0378, -1.1825,  0.9295,  1.0761, -0.9237, -1.0116],\n",
      "        [-0.8771,  0.7777,  0.9101,  0.8443, -1.0627, -1.1147,  1.0958],\n",
      "        [-0.8762,  1.0968, -1.1845, -1.0430,  0.9975, -1.2777,  0.9502],\n",
      "        [ 0.8613,  0.8866, -1.0741, -1.1204, -1.1622,  1.2022,  0.9745],\n",
      "        [-1.0399, -0.9689, -1.0902, -0.8589, -0.9475, -0.9517, -1.0093],\n",
      "        [-1.1563,  0.9661,  1.2223,  1.1524, -1.0626, -0.9063,  1.0720],\n",
      "        [-0.8267, -0.9701,  0.8446,  1.0279,  1.1232, -0.9175, -0.7660],\n",
      "        [-0.9447,  0.7666,  0.7855, -0.9634,  0.9654,  1.1680, -0.7443],\n",
      "        [ 1.2636, -0.9572,  0.8231,  1.1214, -0.9939,  0.9918, -1.2003],\n",
      "        [ 0.8021,  0.9600,  0.9142, -1.1091, -0.7082, -1.1872, -0.9726],\n",
      "        [ 1.1300, -0.6775,  0.9726,  1.1816, -1.2161,  1.0456, -1.3303],\n",
      "        [-0.9859, -0.8775, -0.8066, -0.9416, -1.0762, -0.9033, -0.9256],\n",
      "        [-0.9267,  0.7726, -0.9051,  1.0256, -1.0027,  1.0071, -0.9096],\n",
      "        [ 1.1888,  0.9462, -0.9182,  1.2200,  0.9776, -0.8944, -1.0119],\n",
      "        [-1.0202, -1.0669, -0.7763, -1.0464, -1.0525, -0.9648, -1.0211],\n",
      "        [ 1.0193,  0.9838, -0.9180,  0.9564,  1.0400, -0.8744, -0.9206],\n",
      "        [ 1.0866,  0.7650, -0.8242, -0.7696, -0.8711,  1.0693,  0.9092],\n",
      "        [-1.1198,  1.1386, -0.9756,  0.9443, -0.9130,  1.0320, -0.8908],\n",
      "        [ 1.2550,  1.0050,  1.0772, -0.9598, -1.0292, -0.9966, -0.9975],\n",
      "        [ 1.0771, -0.8097, -0.9393,  0.7713, -1.0686, -1.2754,  0.9937],\n",
      "        [ 0.9617, -0.8023, -0.8844, -0.8787,  1.0419,  1.1457, -1.2038],\n",
      "        [ 0.8757, -0.9187, -0.8620, -0.9841,  1.0901,  1.0757, -0.9992],\n",
      "        [ 1.0304,  0.9972,  0.9953,  0.9878,  1.0414,  1.0182,  0.9423],\n",
      "        [-1.0588,  0.9337, -0.8007, -1.0610,  1.1803, -1.1041,  1.1860],\n",
      "        [-1.1523, -0.9283,  0.9282,  1.1681,  0.9363, -1.0695, -1.1142],\n",
      "        [ 0.8084,  0.6921, -1.0561, -1.0282, -0.9145,  1.0530,  0.9221],\n",
      "        [-1.2263, -0.8484,  0.9130,  0.7892,  0.9915, -1.1376, -0.9335],\n",
      "        [-0.7555, -0.9842, -1.0311,  0.8509,  0.9599,  1.0749,  1.3363],\n",
      "        [-1.1057,  1.0342,  1.1884, -0.9576,  1.0442,  0.6893, -1.2480],\n",
      "        [ 0.8354,  0.9284, -1.0002,  1.1445,  0.8453, -0.9884, -1.0726],\n",
      "        [ 0.6390, -1.2041, -1.0412,  1.0017, -1.0518, -1.0711,  0.9608],\n",
      "        [ 0.7432, -1.0775,  0.9942,  0.6356, -0.8711,  1.1287, -1.0933],\n",
      "        [ 1.0575, -1.0792, -1.1808, -1.0567,  0.8860,  0.9440, -1.1518],\n",
      "        [ 0.9434,  1.1542, -0.8325,  0.9791,  0.9836, -0.9304, -1.0248],\n",
      "        [ 1.0493, -1.1374, -0.7807,  1.0908, -1.1277, -0.7889,  1.0330],\n",
      "        [-1.0382,  0.8616,  0.9137,  0.9143, -0.9211, -0.9453,  0.9818],\n",
      "        [-1.0067, -0.9097,  0.9680, -1.1947, -1.1798,  1.1227,  1.3595],\n",
      "        [-0.6644, -1.2652,  1.1278, -1.0601, -0.9618,  0.9484,  1.0454],\n",
      "        [-0.9216, -1.1033, -0.9174,  0.8940,  0.9024,  1.0283,  1.1003],\n",
      "        [ 0.9128, -1.2024, -0.9627, -1.1493,  1.1413,  0.8579, -1.0886],\n",
      "        [ 0.7922,  1.1642,  1.2064,  1.1388,  1.1520,  1.3130,  1.0511],\n",
      "        [-1.2687, -0.9756,  1.0715, -1.1999, -0.9672,  0.9035,  0.9105],\n",
      "        [ 0.8457, -0.9366,  1.1004, -1.0423,  0.8922, -0.9643,  0.9847],\n",
      "        [-1.0525, -1.2929, -0.9793,  1.0319,  1.0942,  0.9332,  0.9280],\n",
      "        [ 1.2473,  0.9148, -0.9326,  0.9826,  1.0535, -1.0010, -1.0773],\n",
      "        [-0.9554,  1.0202,  1.0886,  1.0032, -0.9650, -1.1300,  1.1305],\n",
      "        [ 1.1620, -0.9773,  0.7525,  0.6393, -0.9016,  1.1877, -0.7801],\n",
      "        [-1.1211,  0.9574,  1.0453,  0.9138, -0.8065, -1.0238,  1.1617],\n",
      "        [ 1.0345, -1.0811,  0.9084, -0.8666,  0.9940, -1.1257,  0.9611],\n",
      "        [-0.9298,  1.0845, -0.9056,  0.8689, -1.0694,  1.0846, -0.9714],\n",
      "        [ 1.2102, -0.8980,  1.0049, -1.1137,  1.2015, -1.0834,  1.1877],\n",
      "        [ 1.0234, -1.0305, -0.9890,  0.8052, -1.0747, -0.6998,  1.0654],\n",
      "        [ 0.9011, -1.0250,  0.9406, -0.9700,  1.0686, -0.9966,  0.8268],\n",
      "        [ 0.9534,  0.8318, -0.8611, -1.0858, -0.9890,  1.0948,  0.9064],\n",
      "        [ 1.0885, -1.0398,  1.0938, -0.9771,  1.0764, -1.1706,  0.7410],\n",
      "        [-0.8642,  1.0311, -1.1413,  1.0487, -0.9908,  1.1528, -0.8965],\n",
      "        [-1.1490, -0.8390,  0.8740, -1.2917, -1.1130,  0.8063,  0.9237],\n",
      "        [ 1.0723,  0.7922,  0.9880,  1.0424,  0.9178,  1.1196,  1.0766],\n",
      "        [-1.0658,  0.8282, -0.9799, -1.0869,  1.2897, -1.1091,  1.1078],\n",
      "        [ 1.1780,  1.0356, -1.1457, -1.0955, -1.2531,  0.9469,  1.2678],\n",
      "        [-1.0667, -0.9567, -0.9251,  0.8665,  1.1044,  1.2293,  1.0335],\n",
      "        [ 1.0211,  1.0215,  1.1163, -0.9412, -1.1258, -0.7692, -0.9399],\n",
      "        [-1.0818,  0.9591, -0.9951, -1.0598,  1.0426, -0.9557,  0.9098],\n",
      "        [ 0.8295,  1.0507, -0.9373,  1.0875,  1.0552, -1.0761, -1.1339],\n",
      "        [-0.9870,  0.9594, -1.1265, -0.8188,  0.9804, -1.1650,  1.0578],\n",
      "        [-0.7174, -0.9860,  1.0737, -1.1872, -0.9869,  1.0355,  1.2736],\n",
      "        [ 1.1203,  0.9769, -1.0612, -1.0644, -0.9847,  0.8694,  1.0154],\n",
      "        [-0.9442, -0.9191,  1.3903, -1.0318, -0.8294,  0.9170,  0.8643],\n",
      "        [ 0.8535,  1.0780,  0.7213, -1.0585, -0.9164, -0.9318, -1.0661],\n",
      "        [ 0.8092,  0.9561, -1.0183,  0.9415,  1.0191, -0.8888, -1.2381],\n",
      "        [ 1.0570,  0.9304,  0.9816, -1.0191, -0.7590, -0.9394, -1.0335]],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/71/hry96qw555j_rlvg3tfgrh180000gn/T/ipykernel_36982/3378208061.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(data, dtype=float)\n"
     ]
    }
   ],
   "source": [
    "data = encoded_codeword  # Binary data\n",
    "snr_dB = 15  # Signal-to-noise ratio in dB\n",
    "\n",
    "# Modulate the signal\n",
    "modulator = bpsk_modulator()\n",
    "noise, modulated_noise_signal = modulator(data, snr_dB)\n",
    "print(modulated_noise_signal)\n",
    "# print(noise)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T11:25:26.927522Z",
     "start_time": "2023-12-11T11:25:26.905727Z"
    }
   },
   "id": "590464d8549a0582"
  },
  {
   "cell_type": "markdown",
   "source": [
    "LLR Log-likelihood\n",
    "y = s + n\n",
    "Assuming that \\( s \\) is equally likely to be 0 or 1, and \\( n \\) is Gaussian with zero mean and variance \\( N_0/2 \\), where \\( N_0 \\) is the noise power spectral density.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b788f8a37d6c4add"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "def llr(signal, snr):\n",
    "    \"\"\"\n",
    "    Calculate Log Likelihood Ratio (LLR) for a simple binary symmetric channel.\n",
    "\n",
    "    Args:\n",
    "        signal (torch.Tensor): Received signal.\n",
    "        noise_std (float): Standard deviation of the noise.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Log Likelihood Ratio (LLR) values.\n",
    "    \"\"\"\n",
    "    # Assuming Binary Phase Shift Keying (BPSK) modulation\n",
    "    noise_std = torch.sqrt(torch.tensor(10**(snr / 10)))\n",
    "    # likelihood_0 = 2 * (signal - 1) / noise_std**2\n",
    "    # likelihood_1 = 2 * (signal + 1) / noise_std**2\n",
    "\n",
    "    # Calculate the LLR\n",
    "    # llr_values = likelihood_0 / likelihood_1\n",
    "    llr = 2 * signal * noise_std\n",
    "\n",
    "    # return llr_values, llr\n",
    "    return llr\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T11:27:34.156242Z",
     "start_time": "2023-12-11T11:27:34.150032Z"
    }
   },
   "id": "5db7bbc0fe148325"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLR values: tensor([[ 12.7725, -11.6055, -14.2499,   9.7174, -10.3866, -10.5699,  11.3777],\n",
      "        [ 12.0634, -13.9633, -12.6273,  10.4386, -15.5828, -10.0640,  11.3219],\n",
      "        [ 11.0217, -12.7697,  11.0442, -12.0559,  11.4604, -10.6340,  12.0642],\n",
      "        [ -9.6327, -10.1089, -13.7571, -13.4097, -10.1083,  -7.3771, -11.0101],\n",
      "        [ 12.8398,  11.3962, -11.8394, -10.5037, -10.4389,  13.0800,  13.6949],\n",
      "        [-11.9686,  10.5355,  11.8002, -11.2607,  11.0974,  11.3236, -12.2820],\n",
      "        [-10.8770, -12.5749,  10.3061,   8.9551,   9.5768, -14.4636, -10.4674],\n",
      "        [  8.4262,  11.4250,  10.9895,  11.5777,  12.6187,  10.8725,  11.5361],\n",
      "        [ -8.3725,  12.2649, -13.7688, -11.6785,  11.0069, -10.3761,  12.2758],\n",
      "        [ 13.8726, -10.4121, -12.4074, -11.6336,  11.7286,  11.2649, -12.2883],\n",
      "        [ 10.2866, -11.9462,  11.9616,  10.5993, -12.1125,  10.8521, -11.1693],\n",
      "        [ 10.3882,  -7.8379,   8.8864, -12.5006,  11.4310, -11.8141,  11.0461],\n",
      "        [  7.7912, -12.3181,  10.5599, -10.7485,  12.3498, -11.8925,   9.0312],\n",
      "        [  9.5334,  10.7051, -11.2860,  11.8871,  10.0769, -10.3152, -10.8538],\n",
      "        [-10.9281,  11.2706,  12.0192, -12.0401,  11.3990,  11.1295,  -8.1428],\n",
      "        [-10.9177, -10.3577, -11.2142,  10.5825,  12.8283,   8.6063,  11.7553],\n",
      "        [-12.7404,  12.1458, -10.6502,  10.1808, -11.2494,  12.0538, -13.0250],\n",
      "        [ 11.2950, -13.4303,  -9.7327,  11.9876, -10.3382, -11.5988,  12.5326],\n",
      "        [-12.9170, -12.3536, -10.5855,  11.1531,  11.2336,  12.4604,  12.9020],\n",
      "        [ 12.8084, -12.7374,  12.1515,  13.1997, -10.9329,  12.1549, -11.5893],\n",
      "        [ 11.8266,  11.2759, -11.1360, -12.4486, -13.8452,  11.5009,  11.9721],\n",
      "        [-13.8365,   9.3606,  11.3105, -11.3243,   9.7758,  11.7187, -11.7379],\n",
      "        [ -9.0380, -12.3323,  10.5360,  12.6054,  11.0221,  -9.6023, -10.7247],\n",
      "        [ 12.1832,  13.1372,   9.3866,   9.6241,  12.4188,  11.4079,  11.7876],\n",
      "        [ 10.5895,  10.7417, -13.5081,   8.6273,   9.9601, -11.0386,  -9.8178],\n",
      "        [ 11.6435, -13.2921, -13.4914,   9.4405, -11.5020, -10.1702,  11.6716],\n",
      "        [ 10.1077, -11.6432, -11.9187,   9.9989, -10.7652, -11.1113,  11.4826],\n",
      "        [  9.9966, -13.5802, -12.1963,   8.7783, -12.0493, -11.1600,  12.0398],\n",
      "        [ 12.3018,  11.6555, -12.2446, -11.3330, -10.1933,  12.0741,  10.1356],\n",
      "        [ 11.3179,  11.6716, -13.2992,  10.4541,  12.1027, -10.3884, -11.3774],\n",
      "        [ -9.8648,   8.7465,  10.2361,   9.4954, -11.9524, -12.5368,  12.3246],\n",
      "        [ -9.8548,  12.3352, -13.3217, -11.7301,  11.2190, -14.3698,  10.6867],\n",
      "        [  9.6865,   9.9715, -12.0801, -12.6013, -13.0712,  13.5205,  10.9599],\n",
      "        [-11.6960, -10.8966, -12.2618,  -9.6600, -10.6563, -10.7040, -11.3510],\n",
      "        [-13.0042,  10.8659,  13.7472,  12.9610, -11.9511, -10.1934,  12.0563],\n",
      "        [ -9.2973, -10.9103,   9.4990,  11.5604,  12.6324, -10.3186,  -8.6151],\n",
      "        [-10.6250,   8.6222,   8.8348, -10.8354,  10.8577,  13.1363,  -8.3705],\n",
      "        [ 14.2111, -10.7651,   9.2575,  12.6121, -11.1779,  11.1546, -13.4992],\n",
      "        [  9.0205,  10.7975,  10.2818, -12.4740,  -7.9646, -13.3521, -10.9382],\n",
      "        [ 12.7094,  -7.6194,  10.9384,  13.2888, -13.6769,  11.7601, -14.9621],\n",
      "        [-11.0882,  -9.8697,  -9.0718, -10.5899, -12.1042, -10.1594, -10.4101],\n",
      "        [-10.4223,   8.6892, -10.1795,  11.5352, -11.2769,  11.3265, -10.2305],\n",
      "        [ 13.3699,  10.6418, -10.3270,  13.7214,  10.9955, -10.0587, -11.3809],\n",
      "        [-11.4742, -11.9994,  -8.7306, -11.7682, -11.8377, -10.8511, -11.4843],\n",
      "        [ 11.4644,  11.0647, -10.3244,  10.7565,  11.6965,  -9.8345, -10.3542],\n",
      "        [ 12.2204,   8.6034,  -9.2701,  -8.6552,  -9.7965,  12.0259,  10.2251],\n",
      "        [-12.5937,  12.8051, -10.9726,  10.6206, -10.2679,  11.6072, -10.0188],\n",
      "        [ 14.1153,  11.3036,  12.1147, -10.7949, -11.5756, -11.2085, -11.2186],\n",
      "        [ 12.1143,  -9.1069, -10.5647,   8.6747, -12.0180, -14.3443,  11.1759],\n",
      "        [ 10.8164,  -9.0237,  -9.9471,  -9.8828,  11.7181,  12.8856, -13.5385],\n",
      "        [  9.8489, -10.3326,  -9.6944, -11.0683,  12.2598,  12.0977, -11.2376],\n",
      "        [ 11.5882,  11.2158,  11.1942,  11.1099,  11.7123,  11.4515,  10.5984],\n",
      "        [-11.9086,  10.5008,  -9.0058, -11.9325,  13.2746, -12.4181,  13.3385],\n",
      "        [-12.9592, -10.4409,  10.4391,  13.1373,  10.5300, -12.0290, -12.5315],\n",
      "        [  9.0922,   7.7841, -11.8775, -11.5642, -10.2851,  11.8433,  10.3702],\n",
      "        [-13.7922,  -9.5419,  10.2682,   8.8762,  11.1517, -12.7944, -10.4990],\n",
      "        [ -8.4971, -11.0691, -11.5969,   9.5700,  10.7962,  12.0889,  15.0292],\n",
      "        [-12.4359,  11.6311,  13.3661, -10.7702,  11.7442,   7.7521, -14.0360],\n",
      "        [  9.3961,  10.4414, -11.2488,  12.8721,   9.5073, -11.1160, -12.0635],\n",
      "        [  7.1870, -13.5427, -11.7107,  11.2655, -11.8293, -12.0470,  10.8059],\n",
      "        [  8.3590, -12.1189,  11.1815,   7.1484,  -9.7967,  12.6945, -12.2964],\n",
      "        [ 11.8936, -12.1375, -13.2804, -11.8851,   9.9646,  10.6166, -12.9540],\n",
      "        [ 10.6098,  12.9814,  -9.3625,  11.0116,  11.0622, -10.4644, -11.5254],\n",
      "        [ 11.8017, -12.7924,  -8.7806,  12.2681, -12.6835,  -8.8726,  11.6177],\n",
      "        [-11.6761,   9.6903,  10.2761,  10.2828, -10.3590, -10.6314,  11.0419],\n",
      "        [-11.3219, -10.2315,  10.8865, -13.4364, -13.2695,  12.6270,  15.2896],\n",
      "        [ -7.4723, -14.2289,  12.6838, -11.9229, -10.8167,  10.6663,  11.7572],\n",
      "        [-10.3651, -12.4086, -10.3181,  10.0545,  10.1492,  11.5646,  12.3745],\n",
      "        [ 10.2659, -13.5230, -10.8273, -12.9260,  12.8358,   9.6492, -12.2430],\n",
      "        [  8.9092,  13.0935,  13.5676,  12.8075,  12.9568,  14.7668,  11.8217],\n",
      "        [-14.2687, -10.9722,  12.0506, -13.4955, -10.8778,  10.1610,  10.2399],\n",
      "        [  9.5118, -10.5338,  12.3755, -11.7227,  10.0341, -10.8449,  11.0752],\n",
      "        [-11.8369, -14.5405, -11.0143,  11.6059,  12.3067,  10.4956,  10.4376],\n",
      "        [ 14.0280,  10.2889, -10.4889,  11.0516,  11.8487, -11.2584, -12.1162],\n",
      "        [-10.7455,  11.4738,  12.2437,  11.2823, -10.8527, -12.7088,  12.7140],\n",
      "        [ 13.0689, -10.9915,   8.4633,   7.1902, -10.1401,  13.3584,  -8.7739],\n",
      "        [-12.6083,  10.7673,  11.7563,  10.2769,  -9.0705, -11.5146,  13.0655],\n",
      "        [ 11.6351, -12.1587,  10.2169,  -9.7463,  11.1798, -12.6609,  10.8097],\n",
      "        [-10.4576,  12.1968, -10.1854,   9.7729, -12.0268,  12.1981, -10.9257],\n",
      "        [ 13.6114, -10.1001,  11.3017, -12.5257,  13.5126, -12.1847,  13.3577],\n",
      "        [ 11.5100, -11.5897, -11.1231,   9.0556, -12.0868,  -7.8700,  11.9819],\n",
      "        [ 10.1345, -11.5281,  10.5793, -10.9089,  12.0181, -11.2085,   9.2985],\n",
      "        [ 10.7231,   9.3547,  -9.6849, -12.2122, -11.1227,  12.3128,  10.1942],\n",
      "        [ 12.2425, -11.6945,  12.3013, -10.9891,  12.1060, -13.1652,   8.3335],\n",
      "        [ -9.7192,  11.5964, -12.8357,  11.7950, -11.1429,  12.9655, -10.0822],\n",
      "        [-12.9225,  -9.4366,   9.8293, -14.5278, -12.5174,   9.0682,  10.3888],\n",
      "        [ 12.0603,   8.9097,  11.1117,  11.7241,  10.3222,  12.5921,  12.1080],\n",
      "        [-11.9870,   9.3151, -11.0210, -12.2245,  14.5055, -12.4739,  12.4598],\n",
      "        [ 13.2484,  11.6471, -12.8851, -12.3207, -14.0932,  10.6491,  14.2588],\n",
      "        [-11.9972, -10.7596, -10.4040,   9.7455,  12.4214,  13.8259,  11.6237],\n",
      "        [ 11.4846,  11.4890,  12.5550, -10.5858, -12.6621,  -8.6508, -10.5705],\n",
      "        [-12.1665,  10.7869, -11.1918, -11.9196,  11.7262, -10.7482,  10.2321],\n",
      "        [  9.3296,  11.8173, -10.5418,  12.2310,  11.8674, -12.1026, -12.7529],\n",
      "        [-11.1011,  10.7905, -12.6699,  -9.2094,  11.0259, -13.1027,  11.8968],\n",
      "        [ -8.0689, -11.0893,  12.0759, -13.3525, -11.0992,  11.6457,  14.3241],\n",
      "        [ 12.6003,  10.9874, -11.9355, -11.9715, -11.0748,   9.7785,  11.4204],\n",
      "        [-10.6188, -10.3365,  15.6361, -11.6046,  -9.3283,  10.3133,   9.7202],\n",
      "        [  9.5988,  12.1236,   8.1119, -11.9046, -10.3061, -10.4795, -11.9903],\n",
      "        [  9.1010,  10.7525, -11.4525,  10.5887,  11.4621,  -9.9963, -13.9249],\n",
      "        [ 11.8879,  10.4641,  11.0394, -11.4619,  -8.5365, -10.5657, -11.6236]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# received_signal = torch.tensor([2.6811e-01, -7.7690e-01, -3.2614e-01,  1.6319e+00, -1.5100e-01, -3.3976e-01,  8.3065e-01])\n",
    "# LLR values: tensor([0.0170, -0.0491, -0.0206,  0.1032, -0.0096, -0.0215,  0.0525])\n",
    "\n",
    "snr_dB = 15\n",
    "\n",
    "llr_output = llr(modulated_noise_signal, snr_dB)\n",
    "print(\"LLR values:\", llr_output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T11:27:35.648347Z",
     "start_time": "2023-12-11T11:27:35.636028Z"
    }
   },
   "id": "d02cfd5d533e6248"
  },
  {
   "cell_type": "markdown",
   "source": [
    "LDPC Decoder"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73cde4898560777a"
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expand(torch.FloatTensor{[7]}, size=[]): the number of sizes provided (0) must be greater or equal to the number of dimensions in the tensor (1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[146], line 48\u001B[0m\n\u001B[1;32m     46\u001B[0m llr_demodulator_output \u001B[38;5;241m=\u001B[39m llr_output\n\u001B[1;32m     47\u001B[0m ldpc_bp \u001B[38;5;241m=\u001B[39m LDPCBeliefPropagation(H)\n\u001B[0;32m---> 48\u001B[0m estimated_bits \u001B[38;5;241m=\u001B[39m \u001B[43mldpc_bp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mllr_demodulator_output\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLLR Demodulator Output:\u001B[39m\u001B[38;5;124m\"\u001B[39m, llr_demodulator_output)\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEstimated Bits:\u001B[39m\u001B[38;5;124m\"\u001B[39m, estimated_bits)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[146], line 22\u001B[0m, in \u001B[0;36mLDPCBeliefPropagation.forward\u001B[0;34m(self, llr)\u001B[0m\n\u001B[1;32m     20\u001B[0m         product \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mprod(torch\u001B[38;5;241m.\u001B[39mtanh(product0))\n\u001B[1;32m     21\u001B[0m         \u001B[38;5;66;03m# product = torch.prod(torch.tanh(0.5 * self.messages_v_to_c[connected_checks, i]))\u001B[39;00m\n\u001B[0;32m---> 22\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmessages_v_to_c\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mj\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msign(llr[i]) \u001B[38;5;241m*\u001B[39m product\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# Check to variable node messages\u001B[39;00m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_check_nodes):\n",
      "\u001B[0;31mRuntimeError\u001B[0m: expand(torch.FloatTensor{[7]}, size=[]): the number of sizes provided (0) must be greater or equal to the number of dimensions in the tensor (1)"
     ]
    }
   ],
   "source": [
    "class LDPCBeliefPropagation(torch.nn.Module):\n",
    "    def __init__(self, H, max_iter=50):\n",
    "        super(LDPCBeliefPropagation, self).__init__()\n",
    "        self.H = H\n",
    "        self.max_iter = max_iter\n",
    "        self.num_check_nodes, self.num_variable_nodes = H.shape\n",
    "\n",
    "        # Initialize messages\n",
    "        self.messages_v_to_c = torch.ones((self.num_variable_nodes, self.num_check_nodes),dtype=torch.float)\n",
    "        self.messages_c_to_v = torch.zeros((self.num_check_nodes, self.num_variable_nodes),dtype=torch.float)\n",
    "\n",
    "    def forward(self, llr):\n",
    "        for iteration in range(self.max_iter):\n",
    "            # Variable node to check node messages\n",
    "            for i in range(self.num_variable_nodes):\n",
    "                for j in range(self.num_check_nodes):\n",
    "                    # Compute messages from variable to check nodes\n",
    "                    connected_checks = self.H[j, :] == 1\n",
    "                    product0 = 0.5 * self.messages_v_to_c[connected_checks, j]\n",
    "                    product = torch.prod(torch.tanh(product0))\n",
    "                    # product = torch.prod(torch.tanh(0.5 * self.messages_v_to_c[connected_checks, i]))\n",
    "                    self.messages_v_to_c[i, j] = torch.sign(llr[i]) * product\n",
    "\n",
    "            # Check node to variable node messages\n",
    "            for i in range(self.num_check_nodes):\n",
    "                for j in range(self.num_variable_nodes):\n",
    "                    # Compute messages from check to variable nodes\n",
    "                    connected_vars = self.H[:, j] == 1\n",
    "                    sum_msg0 = self.messages_c_to_v[connected_vars, i]\n",
    "                    sum_msgs = torch.sum(sum_msg0) - self.messages_v_to_c[j, i]\n",
    "                    # sum_msgs = torch.sum(self.messages_v_to_c[connected_vars, i]) - self.messages_v_to_c[j, i]\n",
    "                    self.messages_c_to_v[i, j] = 2 * torch.atan(torch.exp(0.5 * sum_msgs))\n",
    "\n",
    "        # Calculate the final estimated bits\n",
    "        estimated_bits = torch.sign(llr) * torch.prod(torch.tanh(0.5 * self.messages_c_to_v), dim=0)\n",
    "        estimated_bits = torch.where(estimated_bits>0, torch.tensor(0), torch.tensor(1))\n",
    "\n",
    "        return estimated_bits\n",
    "    \n",
    "# Define LDPC parameters\n",
    "H = torch.tensor([ [1, 1, 1, 0, 0, 0, 0],\n",
    "                   [0, 0, 1, 1, 1, 0, 0],\n",
    "                   [0, 1, 0, 0, 1, 1, 0],\n",
    "                   [1, 0, 0, 1, 0, 0, 1],])\n",
    "\n",
    "llr_demodulator_output = llr_output\n",
    "ldpc_bp = LDPCBeliefPropagation(H)\n",
    "estimated_bits = ldpc_bp(llr_demodulator_output)\n",
    "\n",
    "print(\"LLR Demodulator Output:\", llr_demodulator_output)\n",
    "print(\"Estimated Bits:\", estimated_bits)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T20:38:42.375603Z",
     "start_time": "2023-12-10T20:38:42.335353Z"
    }
   },
   "id": "43cceb3e29b1f0cb"
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (2525148438.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[130], line 18\u001B[0;36m\u001B[0m\n\u001B[0;31m    ldpc_decoder = LDPCDecoder(H)\u001B[0m\n\u001B[0m                                 ^\u001B[0m\n\u001B[0;31mIndentationError\u001B[0m\u001B[0;31m:\u001B[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# class LDPCDecoder(nn.Module):\n",
    "#     def __init__(self, H, num_iterations=10):\n",
    "#         super(LDPCDecoder, self).__init__()\n",
    "#         self.H = nn.Parameter(H, requires_grad=False)  # Parity-check matrix\n",
    "#         self.num_iterations = num_iterations\n",
    "#         \n",
    "#     def ldpc_decode(self, llr_input):\n",
    "#         # Your LDPC decoding algorithm (e.g., SPA or BP)\n",
    "#         # ...\n",
    "# \n",
    "#         return\n",
    "# \n",
    "#     def forward(self, llr_input):\n",
    "#         # Implement LDPC decoding algorithm\n",
    "#         decoded = self.ldpc_decode(llr_input)\n",
    "#         return decoded\n",
    "# \n",
    "# \n",
    "# \n",
    "# def ldpc_loss(llr_hd, true):\n",
    "#     \n",
    "#     return \n",
    "#     \n",
    "# \n",
    "# num_epochs = 20\n",
    "# \n",
    "# # Set up your dataset (LLR values and corresponding codewords)\n",
    "# # Initialize the LDPCDecoder model\n",
    "# ldpc_decoder = LDPCDecoder(H)\n",
    "# \n",
    "# # Define optimizer and learning rate\n",
    "# optimizer = optim.Adam(ldpc_decoder.parameters(), lr=0.001)\n",
    "# \n",
    "# # Training loop\n",
    "# for epoch in range(num_epochs):\n",
    "#     for llr_input, true_codeword in dataloader:\n",
    "#         optimizer.zero_grad()\n",
    "#         decoded = ldpc_decoder(llr_input)\n",
    "#         loss = ldpc_loss(decoded, true_codeword) #cross entropy\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "# \n",
    "#     # Print or log the loss for monitoring training progress\n",
    "#     print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:50:25.606519Z",
     "start_time": "2023-12-10T18:50:25.600500Z"
    }
   },
   "id": "f4cb7c7d538e47a2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ae247515141049a9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
