{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-10T20:36:20.025968Z",
     "start_time": "2023-12-10T20:36:20.019902Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 1.],\n",
      "        [0., 1., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [1., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [1., 0., 0., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [0., 0., 1., 1.],\n",
      "        [1., 1., 0., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [0., 1., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 1., 1., 0.],\n",
      "        [0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1.],\n",
      "        [0., 1., 0., 1.],\n",
      "        [0., 1., 0., 1.],\n",
      "        [0., 0., 1., 1.],\n",
      "        [1., 0., 1., 0.],\n",
      "        [0., 0., 1., 1.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [1., 0., 0., 1.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 1., 1.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [0., 0., 1., 1.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 1., 1., 1.],\n",
      "        [1., 0., 0., 1.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [1., 1., 0., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [1., 1., 0., 1.],\n",
      "        [1., 0., 0., 1.],\n",
      "        [1., 0., 0., 1.],\n",
      "        [1., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [1., 1., 0., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 1., 0.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [1., 0., 0., 1.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 1., 1., 0.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [0., 1., 1., 1.],\n",
      "        [1., 0., 0., 1.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 0., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 1.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1.],\n",
      "        [1., 0., 1., 0.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 1., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [0., 1., 1., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 1., 0., 1.],\n",
      "        [0., 1., 0., 1.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 1., 0., 1.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 0., 1., 0.],\n",
      "        [1., 0., 0., 1.],\n",
      "        [1., 1., 1., 0.],\n",
      "        [1., 0., 1., 0.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [1., 0., 0., 1.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Code Generation\n",
    "message = \"1101\"  # 4-bit binary message\n",
    "\n",
    "nr_codewords = int(100)\n",
    "bits_info = torch.randint(2, (nr_codewords, 4), dtype=torch.float)\n",
    "\n",
    "print(bits_info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T20:36:20.636486Z",
     "start_time": "2023-12-10T20:36:20.632145Z"
    }
   },
   "id": "7b31da2dd38f4534"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hamming(7,4) Encoder"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "784df2c8e94a416e"
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "class hamming_encode(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "            Use Hamming(7,4) to encode the data.\n",
    "    \n",
    "        Args:\n",
    "            data: data received from the Hamming(7,4) encoder(Tensor)\n",
    "            generator matrix: generate the parity code\n",
    "    \n",
    "        Returns:\n",
    "            encoded data: 4 bits original info with 3 parity code.\n",
    "        \"\"\"\n",
    "        super(hamming_encode, self).__init__()\n",
    "\n",
    "        # Define the generator matrix for Hamming(7,4)\n",
    "        self.generator_matrix = torch.tensor([\n",
    "            [1, 0, 0, 0],\n",
    "            [0, 1, 0, 0],\n",
    "            [0, 0, 1, 0],\n",
    "            [0, 0, 0, 1],\n",
    "            [1, 1, 0, 1],\n",
    "            [1, 0, 1, 1],\n",
    "            [0, 1, 1, 1],\n",
    "        ], dtype=torch.float)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        # Ensure input_data has shape (batch_size, 4)\n",
    "        assert input_data.size(1) == 4, \"Input data must have 4 bits.\"\n",
    "\n",
    "        # Perform matrix multiplication to encode the data\n",
    "        encoded_data = torch.matmul(input_data, self.generator_matrix.t()) % 2\n",
    "\n",
    "        return encoded_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T20:36:22.296550Z",
     "start_time": "2023-12-10T20:36:22.293028Z"
    }
   },
   "id": "134dff35e9552bc9"
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 1., 1., 1., 1.],\n",
      "        [0., 1., 1., 1., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 1., 0., 1., 0., 1.],\n",
      "        [0., 0., 0., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 1., 0., 0., 1.],\n",
      "        [1., 0., 1., 1., 0., 1., 0.],\n",
      "        [1., 1., 0., 0., 0., 1., 1.],\n",
      "        [0., 0., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 0., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 1., 1., 1., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 0., 0., 1.],\n",
      "        [0., 1., 0., 1., 0., 1., 0.],\n",
      "        [0., 1., 0., 1., 0., 1., 0.],\n",
      "        [0., 0., 1., 1., 1., 0., 0.],\n",
      "        [1., 0., 1., 0., 1., 0., 1.],\n",
      "        [0., 0., 1., 1., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 1., 0., 0., 1., 0., 1.],\n",
      "        [1., 0., 1., 1., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 1., 1.],\n",
      "        [1., 0., 0., 1., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 1., 1., 1.],\n",
      "        [0., 0., 1., 1., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 1., 0., 1.],\n",
      "        [1., 1., 0., 0., 0., 1., 1.],\n",
      "        [0., 0., 1., 1., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 1., 1.],\n",
      "        [0., 1., 1., 1., 0., 0., 1.],\n",
      "        [1., 0., 0., 1., 0., 0., 1.],\n",
      "        [1., 1., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 1., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 1., 1., 0., 0.],\n",
      "        [1., 0., 0., 1., 0., 0., 1.],\n",
      "        [1., 0., 0., 1., 0., 0., 1.],\n",
      "        [1., 0., 1., 0., 1., 0., 1.],\n",
      "        [0., 0., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 0., 1., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 1., 1., 0.],\n",
      "        [1., 0., 1., 0., 1., 0., 1.],\n",
      "        [1., 0., 1., 1., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 1., 1., 0.],\n",
      "        [1., 0., 0., 0., 1., 1., 0.],\n",
      "        [1., 1., 0., 0., 0., 1., 1.],\n",
      "        [1., 0., 0., 1., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 1., 1., 1.],\n",
      "        [0., 0., 1., 0., 0., 1., 1.],\n",
      "        [0., 1., 1., 0., 1., 1., 0.],\n",
      "        [1., 1., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 1., 1.],\n",
      "        [0., 1., 1., 1., 0., 0., 1.],\n",
      "        [1., 0., 0., 1., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 1., 1., 1.],\n",
      "        [0., 1., 1., 1., 0., 0., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 0., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 1., 0., 0., 1., 1.],\n",
      "        [1., 0., 0., 0., 1., 1., 0.],\n",
      "        [1., 0., 0., 1., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 1., 0., 1.],\n",
      "        [1., 0., 0., 0., 1., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 1., 1., 1.],\n",
      "        [0., 1., 1., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 1., 0., 0.],\n",
      "        [1., 0., 1., 0., 1., 0., 1.],\n",
      "        [1., 0., 1., 1., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 1., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 1., 1., 0., 0., 1.],\n",
      "        [1., 0., 1., 1., 0., 1., 0.],\n",
      "        [0., 1., 1., 0., 1., 1., 0.],\n",
      "        [0., 1., 0., 0., 1., 0., 1.],\n",
      "        [1., 0., 1., 1., 0., 1., 0.],\n",
      "        [1., 1., 0., 1., 1., 0., 0.],\n",
      "        [0., 1., 0., 1., 0., 1., 0.],\n",
      "        [1., 1., 0., 0., 0., 1., 1.],\n",
      "        [0., 1., 0., 0., 1., 0., 1.],\n",
      "        [1., 1., 0., 1., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 1., 0., 1.],\n",
      "        [1., 0., 1., 0., 1., 0., 1.],\n",
      "        [1., 0., 0., 1., 0., 0., 1.],\n",
      "        [1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 0., 1., 0., 1., 0., 1.],\n",
      "        [1., 0., 1., 1., 0., 1., 0.],\n",
      "        [0., 1., 0., 1., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 1., 0., 0., 1.],\n",
      "        [1., 1., 0., 0., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "encoder = hamming_encode()\n",
    "encoded_codeword = encoder(bits_info)\n",
    "print(encoded_codeword)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T20:36:23.077895Z",
     "start_time": "2023-12-10T20:36:23.071105Z"
    }
   },
   "id": "7e7229a532d19f6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "BPSK Modulator + Noise"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82e4a0c53752581c"
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "class bpsk_modulator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Use BPSK to compress the data, which is easily to transmit.\n",
    "\n",
    "    Args:\n",
    "        data: data received from the Hamming(7,4) encoder(Tensor)\n",
    "        symbol_rate: Symbol rate in Hz\n",
    "        carrier_freq: Carrier frequency in Hz\n",
    "        snr_dB: Signal-to-noise ratio in dB\n",
    "\n",
    "    Returns:\n",
    "        time:\n",
    "        data: Tensor contain all data modulated and add noise\n",
    "    \"\"\"\n",
    "        super(bpsk_modulator, self).__init__()\n",
    "        \n",
    "    def forward(self, data, symbol_rate, carrier_freq, snr_dB):\n",
    "    \n",
    "        for i in range(data.shape[0]):\n",
    "            bits = data[i]\n",
    "            bits = 2 * bits - 1\n",
    "            # Time vector\n",
    "            time = torch.arange(0, len(bits) / symbol_rate, 1 / symbol_rate)\n",
    "        \n",
    "            # Generate carrier signal\n",
    "            carrier = torch.cos(2 * torch.pi * carrier_freq * time)\n",
    "        \n",
    "            # Modulate the signal\n",
    "            modulated_signal = bits * carrier\n",
    "        \n",
    "            # Add Gaussian noise to the signal\n",
    "            noise_power = torch.tensor(10**(-snr_dB / 10))\n",
    "            noise = torch.sqrt(noise_power) * torch.randn(len(modulated_signal))\n",
    "            noised_signal = modulated_signal + noise\n",
    "            data[i] = noised_signal\n",
    "    \n",
    "       \n",
    "        return time, data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T20:36:24.097065Z",
     "start_time": "2023-12-10T20:36:24.092088Z"
    }
   },
   "id": "dea8f68cc3a6fb4f"
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8827,  0.4964,  0.7232,  0.5906, -0.7537, -0.5972,  1.0236],\n",
      "        [-0.7987, -0.0810, -0.3209,  0.9059,  0.5022,  0.4287,  1.2094],\n",
      "        [-0.9483,  0.5755,  0.5501, -0.7671,  0.4955,  0.4826, -0.9976],\n",
      "        [ 0.9938,  0.5471, -0.7266, -0.8027, -0.7998,  0.1525,  0.8638],\n",
      "        [-1.0663,  0.4223,  0.6286,  0.9091, -0.4625, -0.5821,  1.0886],\n",
      "        [-0.9891,  0.5657,  0.1424, -1.2340,  0.3680,  0.6373, -0.8662],\n",
      "        [ 0.6934,  0.2242,  0.4827,  1.3953,  0.9403,  0.4859,  1.1445],\n",
      "        [ 1.0416,  0.4610, -0.3341,  0.7008,  0.8445, -0.5457, -0.9958],\n",
      "        [ 1.0132, -0.5674,  0.6170, -0.9933,  0.2907, -0.5736,  0.8444],\n",
      "        [-1.0914,  0.5416, -0.4055,  1.0905, -0.1583,  0.1635, -0.8897],\n",
      "        [ 1.0795, -0.4579,  0.1993,  0.4445, -0.5880,  0.7793, -0.9635],\n",
      "        [ 1.1160, -0.5191, -0.3674,  0.9393, -0.3261, -0.5959,  1.0605],\n",
      "        [-0.9873, -0.7161, -0.4134,  1.1441,  0.5077,  0.5465,  0.8500],\n",
      "        [-0.8346,  0.4033,  0.4770, -1.2263,  0.2436,  0.6065, -0.8774],\n",
      "        [-1.1249, -0.5298, -0.5899, -0.9652, -0.7608, -0.3300, -1.0377],\n",
      "        [-1.3315, -0.5407, -0.7982, -0.9793, -0.5546, -0.4516, -0.8330],\n",
      "        [-0.9039, -0.5219, -0.8488,  0.9081,  0.4889,  0.2769,  0.9873],\n",
      "        [-1.1133, -0.3456,  0.2748,  0.9214,  0.4640, -0.3899, -0.7680],\n",
      "        [-1.0863, -0.5225,  0.6624,  1.0172,  0.8707, -0.4415, -0.8483],\n",
      "        [-0.8472,  0.5221, -0.6108,  1.1677, -0.3498,  0.7079, -1.2026],\n",
      "        [ 1.3578,  0.7448, -0.5502, -0.9983, -0.6466,  0.8308,  0.9192],\n",
      "        [-0.8057,  0.6710, -0.3105,  1.2113, -0.5291,  0.1684, -0.9325],\n",
      "        [-0.8842,  0.2935, -0.3872, -1.1365,  0.5443, -0.1885,  0.8066],\n",
      "        [ 1.1396, -0.5115, -0.7390,  0.9403, -0.5071, -0.2199,  0.9345],\n",
      "        [-0.8922, -0.3673,  0.6163, -1.0298, -0.4527,  0.3770,  0.9485],\n",
      "        [ 0.8725,  0.3334, -0.1064,  1.0454,  0.5716, -0.3854, -0.7517],\n",
      "        [-0.9011,  0.5134,  0.7703,  0.8986, -0.4276, -0.4743,  1.0390],\n",
      "        [ 1.3489, -0.6692,  0.8826, -1.3711,  0.4136, -0.5924,  1.0942],\n",
      "        [ 1.0572,  0.5323,  0.4566,  1.1807,  0.1975,  0.7015,  0.8876],\n",
      "        [-1.1409,  0.4214,  0.7079,  1.1870, -0.6713, -0.4005,  1.0534],\n",
      "        [-0.8062,  0.3234, -0.1977,  0.9324, -0.4618,  0.8933, -1.3102],\n",
      "        [-0.8839, -0.6638,  0.7235, -0.5452, -0.4574,  0.5706,  0.9748],\n",
      "        [ 0.6982, -0.6502,  0.5361, -1.0235,  0.5200, -0.6476,  0.8401],\n",
      "        [-1.0683,  0.5064, -0.0336,  0.9777, -0.6366,  0.1849, -0.7025],\n",
      "        [-0.7440,  0.3115, -0.3214, -0.8339,  0.5195, -0.5704,  1.5065],\n",
      "        [-0.8008, -0.3814, -0.5194,  1.1125,  0.6024,  0.7796,  0.6546],\n",
      "        [ 1.4357,  0.4175,  0.5300,  1.1919,  0.4057,  0.4469,  1.0692],\n",
      "        [ 0.8711, -0.6410,  0.4421, -1.1291,  0.5749, -0.2609,  1.1531],\n",
      "        [ 1.0740, -0.8589,  0.3866,  0.8797, -0.3780,  0.3819, -1.0911],\n",
      "        [-0.9450,  0.5631,  0.3437, -0.6914,  0.3958,  0.5437, -0.7309],\n",
      "        [ 0.6067, -0.4976,  0.6649,  0.9843, -0.6321,  0.5488, -0.9774],\n",
      "        [ 0.5995,  0.4429,  0.6980,  1.0968,  0.6321,  0.5005,  0.9220],\n",
      "        [ 0.7161,  0.3074,  0.6157,  1.2358,  0.5933,  0.2494,  1.0782],\n",
      "        [ 0.9184,  0.5011, -0.4630, -0.9903, -0.6191,  0.3424,  0.8525],\n",
      "        [-1.1355,  0.6187,  0.4148,  0.8353, -0.3286, -0.4503,  0.5657],\n",
      "        [ 0.9218, -0.2418,  0.7161,  1.2085, -0.4956,  0.4149, -0.9845],\n",
      "        [-1.3155,  0.5006,  0.6216, -0.9649,  0.2868,  0.5030, -0.9592],\n",
      "        [ 1.0336,  0.5030,  0.3143, -1.0239, -0.3501, -0.7707, -1.1231],\n",
      "        [ 0.8013,  0.5155, -0.3867, -1.0502, -0.5257,  0.4336,  0.9994],\n",
      "        [ 1.0191,  0.4401, -0.4305,  0.9559,  0.3940, -0.2308, -1.0726],\n",
      "        [ 1.3509,  0.5807,  0.8557, -0.8392, -0.5251, -0.3264, -0.9537],\n",
      "        [ 1.0739,  0.5063,  0.5909, -1.1110, -0.4620, -0.4522, -0.9520],\n",
      "        [ 1.0270, -0.4428,  0.4465, -1.1480,  0.3002, -0.5267,  0.9208],\n",
      "        [ 0.9107,  0.3616,  0.2727,  1.2244,  0.5466,  0.5336,  1.0035],\n",
      "        [-1.0792,  0.5664,  0.5098,  0.7740, -0.3401, -0.4543,  0.9947],\n",
      "        [-0.8542,  0.6392, -0.3174, -1.3463,  0.7405, -0.3641,  1.0012],\n",
      "        [-1.2230, -0.3645, -0.5094, -1.0803, -0.3631, -0.6767, -1.1736],\n",
      "        [ 0.8472, -0.4259,  0.3255, -1.3047,  0.7294, -0.6954,  1.0025],\n",
      "        [ 0.8313, -0.4097,  0.6272, -1.0438,  0.4319, -0.5622,  0.7782],\n",
      "        [-0.6913, -0.4394, -0.2142,  0.9805,  0.1440,  0.7807,  1.2428],\n",
      "        [ 1.1492,  0.6103,  0.5804,  0.8852,  0.5707,  0.5215,  0.8135],\n",
      "        [-0.9719,  0.9072,  0.1098,  1.1507, -0.1321, -0.4672,  1.0423],\n",
      "        [-1.2190, -0.6927, -0.3785,  0.8455,  0.6185,  0.6609,  1.4305],\n",
      "        [ 0.7872, -0.2315, -0.4792,  0.9368, -0.7170, -0.6996,  0.8928],\n",
      "        [ 0.7421, -0.5365,  0.2695,  0.9808, -0.6542,  0.6095, -1.1635],\n",
      "        [ 0.8378, -0.6294, -0.2281,  0.9068, -0.5234, -0.4610,  0.9712],\n",
      "        [-0.8907,  0.4707, -0.5483, -1.0025,  0.5643, -0.4018,  0.8971],\n",
      "        [ 1.0484,  0.7146,  0.5000, -1.1631, -0.6430, -0.4950, -1.0575],\n",
      "        [ 1.0993,  0.2493,  0.5348,  0.6195,  0.5949,  0.2909,  0.8958],\n",
      "        [-1.0813, -0.6714,  0.3561, -0.8522, -0.5381,  0.1840,  0.7806],\n",
      "        [ 1.0959,  0.4311,  0.3626, -1.0946, -0.3207, -0.2489, -1.4349],\n",
      "        [-1.0547,  0.3389,  0.3808, -1.3678,  0.4626,  0.6940, -1.0870],\n",
      "        [-0.9483,  0.5789,  0.4656,  0.7787, -0.5819, -0.6804,  1.3049],\n",
      "        [-0.9976, -0.3122, -0.5499, -1.0631, -0.4181, -0.2246, -1.1417],\n",
      "        [-1.0556,  0.4903, -0.1989,  0.9081, -0.4978,  0.4922, -1.2873],\n",
      "        [ 0.9673,  0.5095, -0.8872, -0.8348, -0.7178,  0.8079,  0.8487],\n",
      "        [ 1.1865,  0.7788, -0.5494,  0.6823,  0.5532, -0.5102, -1.3104],\n",
      "        [ 1.1224,  0.2892,  0.7323, -0.9436, -0.6666, -0.3826, -1.1111],\n",
      "        [-1.0123,  0.6350,  0.2539, -0.7811,  0.5527,  0.4607, -0.7483],\n",
      "        [-0.7374, -0.1835, -0.6151,  1.0079,  0.3596,  0.4278,  1.0610],\n",
      "        [ 1.2208,  0.6274, -0.4478,  1.1833,  0.3813, -0.3396, -1.0303],\n",
      "        [-1.4102, -0.4498, -0.0140, -0.9868, -0.8698, -0.5082, -1.0594],\n",
      "        [-0.9588, -0.5058,  0.4132, -1.0114, -0.7202,  0.2044,  1.0177],\n",
      "        [ 1.3627,  0.6198, -0.6421,  1.0463,  0.3036, -0.6426, -1.2202],\n",
      "        [ 1.0787, -0.6178,  0.5275,  0.9233, -0.4682,  0.4887, -1.1723],\n",
      "        [-0.9947, -0.5410,  0.4330,  0.8151,  0.4264, -0.5600, -0.9975],\n",
      "        [ 1.0134, -0.3836,  0.6098, -0.9888,  0.5736, -0.2495,  0.7904],\n",
      "        [-1.4501, -0.3946,  0.8490, -0.8283, -0.5552,  0.3098,  1.1766],\n",
      "        [ 0.6270, -0.3455,  0.4656,  1.0901, -0.2350,  0.3348, -1.1803],\n",
      "        [-1.1648, -0.5114,  0.7875, -0.9379, -0.6161,  0.4672,  1.3316],\n",
      "        [ 0.4914,  0.5639, -0.2995, -0.6896, -0.5845,  0.4518,  1.3120],\n",
      "        [ 1.1800,  0.9318,  0.6753,  1.1787,  0.4427,  0.5978,  1.2216],\n",
      "        [ 1.1778, -0.4249, -0.4329, -1.1885,  0.2201,  0.2177, -0.8568],\n",
      "        [ 0.7023,  0.4267, -0.0134, -1.0180, -0.5939,  0.3720,  1.1524],\n",
      "        [ 0.8513,  0.3898, -0.6093,  0.8560,  0.1521, -0.7523, -1.0567],\n",
      "        [-0.7379, -0.4356,  0.5914,  0.9248,  0.5930, -0.4194, -1.0038],\n",
      "        [-1.0921,  0.7612,  0.7384, -1.0123,  0.4939,  0.5258, -0.8946],\n",
      "        [ 0.8608,  0.4044,  0.4039,  1.0241,  0.4214,  0.4681,  1.1548],\n",
      "        [ 1.2272, -0.3622,  0.4112, -1.0477,  0.5765, -0.8516,  0.8220],\n",
      "        [ 1.1724,  0.5007, -0.3691,  0.9413,  0.6340, -0.5817, -0.8599]])\n"
     ]
    }
   ],
   "source": [
    "data = encoded_codeword  # Binary data\n",
    "symbol_rate = 15  # Symbol rate in Hz\n",
    "carrier_freq = 100  # Carrier frequency in Hz\n",
    "snr_dB = 15  # Signal-to-noise ratio in dB\n",
    "\n",
    "# Modulate the signal\n",
    "modulator = bpsk_modulator()\n",
    "time, modulated_noise_signal = modulator(data, symbol_rate, carrier_freq, snr_dB)\n",
    "print(modulated_noise_signal)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T20:36:24.781888Z",
     "start_time": "2023-12-10T20:36:24.765713Z"
    }
   },
   "id": "590464d8549a0582"
  },
  {
   "cell_type": "markdown",
   "source": [
    "LLR Log-likelihood\n",
    "y = s + n\n",
    "Assuming that \\( s \\) is equally likely to be 0 or 1, and \\( n \\) is Gaussian with zero mean and variance \\( N_0/2 \\), where \\( N_0 \\) is the noise power spectral density.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b788f8a37d6c4add"
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "def llr(signal, snr):\n",
    "    \"\"\"\n",
    "    Calculate Log Likelihood Ratio (LLR) for a simple binary symmetric channel.\n",
    "\n",
    "    Args:\n",
    "        signal (torch.Tensor): Received signal.\n",
    "        noise_std (float): Standard deviation of the noise.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Log Likelihood Ratio (LLR) values.\n",
    "    \"\"\"\n",
    "    # Assuming Binary Phase Shift Keying (BPSK) modulation\n",
    "    noise_std = torch.sqrt(torch.tensor(10**(snr / 10)))\n",
    "    # likelihood_0 = 2 * (signal - 1) / noise_std**2\n",
    "    # likelihood_1 = 2 * (signal + 1) / noise_std**2\n",
    "\n",
    "    # Calculate the LLR\n",
    "    # llr_values = likelihood_0 / likelihood_1\n",
    "    llr = 2 * signal / noise_std**2\n",
    "\n",
    "    # return llr_values, llr\n",
    "    return llr\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T20:36:26.363944Z",
     "start_time": "2023-12-10T20:36:26.358044Z"
    }
   },
   "id": "5db7bbc0fe148325"
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLR values: tensor([[-0.0558,  0.0314,  0.0457,  0.0374, -0.0477, -0.0378,  0.0647],\n",
      "        [-0.0505, -0.0051, -0.0203,  0.0573,  0.0318,  0.0271,  0.0765],\n",
      "        [-0.0600,  0.0364,  0.0348, -0.0485,  0.0313,  0.0305, -0.0631],\n",
      "        [ 0.0629,  0.0346, -0.0460, -0.0508, -0.0506,  0.0096,  0.0546],\n",
      "        [-0.0674,  0.0267,  0.0398,  0.0575, -0.0293, -0.0368,  0.0688],\n",
      "        [-0.0626,  0.0358,  0.0090, -0.0780,  0.0233,  0.0403, -0.0548],\n",
      "        [ 0.0439,  0.0142,  0.0305,  0.0882,  0.0595,  0.0307,  0.0724],\n",
      "        [ 0.0659,  0.0292, -0.0211,  0.0443,  0.0534, -0.0345, -0.0630],\n",
      "        [ 0.0641, -0.0359,  0.0390, -0.0628,  0.0184, -0.0363,  0.0534],\n",
      "        [-0.0690,  0.0343, -0.0256,  0.0690, -0.0100,  0.0103, -0.0563],\n",
      "        [ 0.0683, -0.0290,  0.0126,  0.0281, -0.0372,  0.0493, -0.0609],\n",
      "        [ 0.0706, -0.0328, -0.0232,  0.0594, -0.0206, -0.0377,  0.0671],\n",
      "        [-0.0624, -0.0453, -0.0261,  0.0724,  0.0321,  0.0346,  0.0538],\n",
      "        [-0.0528,  0.0255,  0.0302, -0.0776,  0.0154,  0.0384, -0.0555],\n",
      "        [-0.0711, -0.0335, -0.0373, -0.0610, -0.0481, -0.0209, -0.0656],\n",
      "        [-0.0842, -0.0342, -0.0505, -0.0619, -0.0351, -0.0286, -0.0527],\n",
      "        [-0.0572, -0.0330, -0.0537,  0.0574,  0.0309,  0.0175,  0.0624],\n",
      "        [-0.0704, -0.0219,  0.0174,  0.0583,  0.0293, -0.0247, -0.0486],\n",
      "        [-0.0687, -0.0330,  0.0419,  0.0643,  0.0551, -0.0279, -0.0537],\n",
      "        [-0.0536,  0.0330, -0.0386,  0.0738, -0.0221,  0.0448, -0.0761],\n",
      "        [ 0.0859,  0.0471, -0.0348, -0.0631, -0.0409,  0.0525,  0.0581],\n",
      "        [-0.0510,  0.0424, -0.0196,  0.0766, -0.0335,  0.0106, -0.0590],\n",
      "        [-0.0559,  0.0186, -0.0245, -0.0719,  0.0344, -0.0119,  0.0510],\n",
      "        [ 0.0721, -0.0323, -0.0467,  0.0595, -0.0321, -0.0139,  0.0591],\n",
      "        [-0.0564, -0.0232,  0.0390, -0.0651, -0.0286,  0.0238,  0.0600],\n",
      "        [ 0.0552,  0.0211, -0.0067,  0.0661,  0.0362, -0.0244, -0.0475],\n",
      "        [-0.0570,  0.0325,  0.0487,  0.0568, -0.0270, -0.0300,  0.0657],\n",
      "        [ 0.0853, -0.0423,  0.0558, -0.0867,  0.0262, -0.0375,  0.0692],\n",
      "        [ 0.0669,  0.0337,  0.0289,  0.0747,  0.0125,  0.0444,  0.0561],\n",
      "        [-0.0722,  0.0267,  0.0448,  0.0751, -0.0425, -0.0253,  0.0666],\n",
      "        [-0.0510,  0.0205, -0.0125,  0.0590, -0.0292,  0.0565, -0.0829],\n",
      "        [-0.0559, -0.0420,  0.0458, -0.0345, -0.0289,  0.0361,  0.0616],\n",
      "        [ 0.0442, -0.0411,  0.0339, -0.0647,  0.0329, -0.0410,  0.0531],\n",
      "        [-0.0676,  0.0320, -0.0021,  0.0618, -0.0403,  0.0117, -0.0444],\n",
      "        [-0.0471,  0.0197, -0.0203, -0.0527,  0.0329, -0.0361,  0.0953],\n",
      "        [-0.0506, -0.0241, -0.0329,  0.0704,  0.0381,  0.0493,  0.0414],\n",
      "        [ 0.0908,  0.0264,  0.0335,  0.0754,  0.0257,  0.0283,  0.0676],\n",
      "        [ 0.0551, -0.0405,  0.0280, -0.0714,  0.0364, -0.0165,  0.0729],\n",
      "        [ 0.0679, -0.0543,  0.0245,  0.0556, -0.0239,  0.0242, -0.0690],\n",
      "        [-0.0598,  0.0356,  0.0217, -0.0437,  0.0250,  0.0344, -0.0462],\n",
      "        [ 0.0384, -0.0315,  0.0421,  0.0623, -0.0400,  0.0347, -0.0618],\n",
      "        [ 0.0379,  0.0280,  0.0441,  0.0694,  0.0400,  0.0317,  0.0583],\n",
      "        [ 0.0453,  0.0194,  0.0389,  0.0782,  0.0375,  0.0158,  0.0682],\n",
      "        [ 0.0581,  0.0317, -0.0293, -0.0626, -0.0392,  0.0217,  0.0539],\n",
      "        [-0.0718,  0.0391,  0.0262,  0.0528, -0.0208, -0.0285,  0.0358],\n",
      "        [ 0.0583, -0.0153,  0.0453,  0.0764, -0.0313,  0.0262, -0.0623],\n",
      "        [-0.0832,  0.0317,  0.0393, -0.0610,  0.0181,  0.0318, -0.0607],\n",
      "        [ 0.0654,  0.0318,  0.0199, -0.0648, -0.0221, -0.0487, -0.0710],\n",
      "        [ 0.0507,  0.0326, -0.0245, -0.0664, -0.0332,  0.0274,  0.0632],\n",
      "        [ 0.0645,  0.0278, -0.0272,  0.0605,  0.0249, -0.0146, -0.0678],\n",
      "        [ 0.0854,  0.0367,  0.0541, -0.0531, -0.0332, -0.0206, -0.0603],\n",
      "        [ 0.0679,  0.0320,  0.0374, -0.0703, -0.0292, -0.0286, -0.0602],\n",
      "        [ 0.0650, -0.0280,  0.0282, -0.0726,  0.0190, -0.0333,  0.0582],\n",
      "        [ 0.0576,  0.0229,  0.0172,  0.0774,  0.0346,  0.0338,  0.0635],\n",
      "        [-0.0683,  0.0358,  0.0322,  0.0490, -0.0215, -0.0287,  0.0629],\n",
      "        [-0.0540,  0.0404, -0.0201, -0.0851,  0.0468, -0.0230,  0.0633],\n",
      "        [-0.0773, -0.0231, -0.0322, -0.0683, -0.0230, -0.0428, -0.0742],\n",
      "        [ 0.0536, -0.0269,  0.0206, -0.0825,  0.0461, -0.0440,  0.0634],\n",
      "        [ 0.0526, -0.0259,  0.0397, -0.0660,  0.0273, -0.0356,  0.0492],\n",
      "        [-0.0437, -0.0278, -0.0135,  0.0620,  0.0091,  0.0494,  0.0786],\n",
      "        [ 0.0727,  0.0386,  0.0367,  0.0560,  0.0361,  0.0330,  0.0514],\n",
      "        [-0.0615,  0.0574,  0.0069,  0.0728, -0.0084, -0.0295,  0.0659],\n",
      "        [-0.0771, -0.0438, -0.0239,  0.0535,  0.0391,  0.0418,  0.0905],\n",
      "        [ 0.0498, -0.0146, -0.0303,  0.0592, -0.0453, -0.0442,  0.0565],\n",
      "        [ 0.0469, -0.0339,  0.0170,  0.0620, -0.0414,  0.0385, -0.0736],\n",
      "        [ 0.0530, -0.0398, -0.0144,  0.0574, -0.0331, -0.0292,  0.0614],\n",
      "        [-0.0563,  0.0298, -0.0347, -0.0634,  0.0357, -0.0254,  0.0567],\n",
      "        [ 0.0663,  0.0452,  0.0316, -0.0736, -0.0407, -0.0313, -0.0669],\n",
      "        [ 0.0695,  0.0158,  0.0338,  0.0392,  0.0376,  0.0184,  0.0567],\n",
      "        [-0.0684, -0.0425,  0.0225, -0.0539, -0.0340,  0.0116,  0.0494],\n",
      "        [ 0.0693,  0.0273,  0.0229, -0.0692, -0.0203, -0.0157, -0.0908],\n",
      "        [-0.0667,  0.0214,  0.0241, -0.0865,  0.0293,  0.0439, -0.0688],\n",
      "        [-0.0600,  0.0366,  0.0294,  0.0492, -0.0368, -0.0430,  0.0825],\n",
      "        [-0.0631, -0.0197, -0.0348, -0.0672, -0.0264, -0.0142, -0.0722],\n",
      "        [-0.0668,  0.0310, -0.0126,  0.0574, -0.0315,  0.0311, -0.0814],\n",
      "        [ 0.0612,  0.0322, -0.0561, -0.0528, -0.0454,  0.0511,  0.0537],\n",
      "        [ 0.0750,  0.0493, -0.0347,  0.0432,  0.0350, -0.0323, -0.0829],\n",
      "        [ 0.0710,  0.0183,  0.0463, -0.0597, -0.0422, -0.0242, -0.0703],\n",
      "        [-0.0640,  0.0402,  0.0161, -0.0494,  0.0350,  0.0291, -0.0473],\n",
      "        [-0.0466, -0.0116, -0.0389,  0.0637,  0.0227,  0.0271,  0.0671],\n",
      "        [ 0.0772,  0.0397, -0.0283,  0.0748,  0.0241, -0.0215, -0.0652],\n",
      "        [-0.0892, -0.0284, -0.0009, -0.0624, -0.0550, -0.0321, -0.0670],\n",
      "        [-0.0606, -0.0320,  0.0261, -0.0640, -0.0456,  0.0129,  0.0644],\n",
      "        [ 0.0862,  0.0392, -0.0406,  0.0662,  0.0192, -0.0406, -0.0772],\n",
      "        [ 0.0682, -0.0391,  0.0334,  0.0584, -0.0296,  0.0309, -0.0741],\n",
      "        [-0.0629, -0.0342,  0.0274,  0.0516,  0.0270, -0.0354, -0.0631],\n",
      "        [ 0.0641, -0.0243,  0.0386, -0.0625,  0.0363, -0.0158,  0.0500],\n",
      "        [-0.0917, -0.0250,  0.0537, -0.0524, -0.0351,  0.0196,  0.0744],\n",
      "        [ 0.0397, -0.0219,  0.0294,  0.0689, -0.0149,  0.0212, -0.0746],\n",
      "        [-0.0737, -0.0323,  0.0498, -0.0593, -0.0390,  0.0296,  0.0842],\n",
      "        [ 0.0311,  0.0357, -0.0189, -0.0436, -0.0370,  0.0286,  0.0830],\n",
      "        [ 0.0746,  0.0589,  0.0427,  0.0745,  0.0280,  0.0378,  0.0773],\n",
      "        [ 0.0745, -0.0269, -0.0274, -0.0752,  0.0139,  0.0138, -0.0542],\n",
      "        [ 0.0444,  0.0270, -0.0008, -0.0644, -0.0376,  0.0235,  0.0729],\n",
      "        [ 0.0538,  0.0247, -0.0385,  0.0541,  0.0096, -0.0476, -0.0668],\n",
      "        [-0.0467, -0.0276,  0.0374,  0.0585,  0.0375, -0.0265, -0.0635],\n",
      "        [-0.0691,  0.0481,  0.0467, -0.0640,  0.0312,  0.0333, -0.0566],\n",
      "        [ 0.0544,  0.0256,  0.0255,  0.0648,  0.0267,  0.0296,  0.0730],\n",
      "        [ 0.0776, -0.0229,  0.0260, -0.0663,  0.0365, -0.0539,  0.0520],\n",
      "        [ 0.0741,  0.0317, -0.0233,  0.0595,  0.0401, -0.0368, -0.0544]])\n"
     ]
    }
   ],
   "source": [
    "# received_signal = torch.tensor([2.6811e-01, -7.7690e-01, -3.2614e-01,  1.6319e+00, -1.5100e-01, -3.3976e-01,  8.3065e-01])\n",
    "# LLR values: tensor([0.0170, -0.0491, -0.0206,  0.1032, -0.0096, -0.0215,  0.0525])\n",
    "\n",
    "snr_dB = 15\n",
    "\n",
    "llr_output = llr(modulated_noise_signal, snr_dB)\n",
    "print(\"LLR values:\", llr_output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T20:36:27.521931Z",
     "start_time": "2023-12-10T20:36:27.506876Z"
    }
   },
   "id": "d02cfd5d533e6248"
  },
  {
   "cell_type": "markdown",
   "source": [
    "LDPC Decoder"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73cde4898560777a"
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expand(torch.FloatTensor{[7]}, size=[]): the number of sizes provided (0) must be greater or equal to the number of dimensions in the tensor (1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[146], line 48\u001B[0m\n\u001B[1;32m     46\u001B[0m llr_demodulator_output \u001B[38;5;241m=\u001B[39m llr_output\n\u001B[1;32m     47\u001B[0m ldpc_bp \u001B[38;5;241m=\u001B[39m LDPCBeliefPropagation(H)\n\u001B[0;32m---> 48\u001B[0m estimated_bits \u001B[38;5;241m=\u001B[39m \u001B[43mldpc_bp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mllr_demodulator_output\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLLR Demodulator Output:\u001B[39m\u001B[38;5;124m\"\u001B[39m, llr_demodulator_output)\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEstimated Bits:\u001B[39m\u001B[38;5;124m\"\u001B[39m, estimated_bits)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[146], line 22\u001B[0m, in \u001B[0;36mLDPCBeliefPropagation.forward\u001B[0;34m(self, llr)\u001B[0m\n\u001B[1;32m     20\u001B[0m         product \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mprod(torch\u001B[38;5;241m.\u001B[39mtanh(product0))\n\u001B[1;32m     21\u001B[0m         \u001B[38;5;66;03m# product = torch.prod(torch.tanh(0.5 * self.messages_v_to_c[connected_checks, i]))\u001B[39;00m\n\u001B[0;32m---> 22\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmessages_v_to_c\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mj\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msign(llr[i]) \u001B[38;5;241m*\u001B[39m product\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# Check to variable node messages\u001B[39;00m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_check_nodes):\n",
      "\u001B[0;31mRuntimeError\u001B[0m: expand(torch.FloatTensor{[7]}, size=[]): the number of sizes provided (0) must be greater or equal to the number of dimensions in the tensor (1)"
     ]
    }
   ],
   "source": [
    "class LDPCBeliefPropagation(torch.nn.Module):\n",
    "    def __init__(self, H, max_iter=50):\n",
    "        super(LDPCBeliefPropagation, self).__init__()\n",
    "        self.H = H\n",
    "        self.max_iter = max_iter\n",
    "        self.num_check_nodes, self.num_variable_nodes = H.shape\n",
    "\n",
    "        # Initialize messages\n",
    "        self.messages_v_to_c = torch.ones((self.num_variable_nodes, self.num_check_nodes),dtype=torch.float)\n",
    "        self.messages_c_to_v = torch.zeros((self.num_check_nodes, self.num_variable_nodes),dtype=torch.float)\n",
    "\n",
    "    def forward(self, llr):\n",
    "        for iteration in range(self.max_iter):\n",
    "            # Variable node to check node messages\n",
    "            for i in range(self.num_variable_nodes):\n",
    "                for j in range(self.num_check_nodes):\n",
    "                    # Compute messages from variable to check nodes\n",
    "                    connected_checks = self.H[j, :] == 1\n",
    "                    product0 = 0.5 * self.messages_v_to_c[connected_checks, j]\n",
    "                    product = torch.prod(torch.tanh(product0))\n",
    "                    # product = torch.prod(torch.tanh(0.5 * self.messages_v_to_c[connected_checks, i]))\n",
    "                    self.messages_v_to_c[i, j] = torch.sign(llr[i]) * product\n",
    "\n",
    "            # Check node to variable node messages\n",
    "            for i in range(self.num_check_nodes):\n",
    "                for j in range(self.num_variable_nodes):\n",
    "                    # Compute messages from check to variable nodes\n",
    "                    connected_vars = self.H[:, j] == 1\n",
    "                    sum_msg0 = self.messages_c_to_v[connected_vars, i]\n",
    "                    sum_msgs = torch.sum(sum_msg0) - self.messages_v_to_c[j, i]\n",
    "                    # sum_msgs = torch.sum(self.messages_v_to_c[connected_vars, i]) - self.messages_v_to_c[j, i]\n",
    "                    self.messages_c_to_v[i, j] = 2 * torch.atan(torch.exp(0.5 * sum_msgs))\n",
    "\n",
    "        # Calculate the final estimated bits\n",
    "        estimated_bits = torch.sign(llr) * torch.prod(torch.tanh(0.5 * self.messages_c_to_v), dim=0)\n",
    "        estimated_bits = torch.where(estimated_bits>0, torch.tensor(1), torch.tensor(0))\n",
    "\n",
    "        return estimated_bits\n",
    "    \n",
    "# Define LDPC parameters\n",
    "H = torch.tensor([ [1, 1, 1, 0, 0, 0, 0],\n",
    "                   [0, 0, 1, 1, 1, 0, 0],\n",
    "                   [0, 1, 0, 0, 1, 1, 0],\n",
    "                   [1, 0, 0, 1, 0, 0, 1],])\n",
    "\n",
    "llr_demodulator_output = llr_output\n",
    "ldpc_bp = LDPCBeliefPropagation(H)\n",
    "estimated_bits = ldpc_bp(llr_demodulator_output)\n",
    "\n",
    "print(\"LLR Demodulator Output:\", llr_demodulator_output)\n",
    "print(\"Estimated Bits:\", estimated_bits)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T20:38:42.375603Z",
     "start_time": "2023-12-10T20:38:42.335353Z"
    }
   },
   "id": "43cceb3e29b1f0cb"
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (2525148438.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[130], line 18\u001B[0;36m\u001B[0m\n\u001B[0;31m    ldpc_decoder = LDPCDecoder(H)\u001B[0m\n\u001B[0m                                 ^\u001B[0m\n\u001B[0;31mIndentationError\u001B[0m\u001B[0;31m:\u001B[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# class LDPCDecoder(nn.Module):\n",
    "#     def __init__(self, H, num_iterations=10):\n",
    "#         super(LDPCDecoder, self).__init__()\n",
    "#         self.H = nn.Parameter(H, requires_grad=False)  # Parity-check matrix\n",
    "#         self.num_iterations = num_iterations\n",
    "#         \n",
    "#     def ldpc_decode(self, llr_input):\n",
    "#         # Your LDPC decoding algorithm (e.g., SPA or BP)\n",
    "#         # ...\n",
    "# \n",
    "#         return\n",
    "# \n",
    "#     def forward(self, llr_input):\n",
    "#         # Implement LDPC decoding algorithm\n",
    "#         decoded = self.ldpc_decode(llr_input)\n",
    "#         return decoded\n",
    "# \n",
    "# \n",
    "# \n",
    "# def ldpc_loss(llr_hd, true):\n",
    "#     \n",
    "#     return \n",
    "#     \n",
    "# \n",
    "# num_epochs = 20\n",
    "# \n",
    "# # Set up your dataset (LLR values and corresponding codewords)\n",
    "# # Initialize the LDPCDecoder model\n",
    "# ldpc_decoder = LDPCDecoder(H)\n",
    "# \n",
    "# # Define optimizer and learning rate\n",
    "# optimizer = optim.Adam(ldpc_decoder.parameters(), lr=0.001)\n",
    "# \n",
    "# # Training loop\n",
    "# for epoch in range(num_epochs):\n",
    "#     for llr_input, true_codeword in dataloader:\n",
    "#         optimizer.zero_grad()\n",
    "#         decoded = ldpc_decoder(llr_input)\n",
    "#         loss = ldpc_loss(decoded, true_codeword) #cross entropy\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "# \n",
    "#     # Print or log the loss for monitoring training progress\n",
    "#     print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:50:25.606519Z",
     "start_time": "2023-12-10T18:50:25.600500Z"
    }
   },
   "id": "f4cb7c7d538e47a2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ae247515141049a9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
