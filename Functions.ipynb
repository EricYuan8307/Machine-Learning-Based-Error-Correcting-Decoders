{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-21T11:53:00.670246Z",
     "start_time": "2024-02-21T11:52:59.813549Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n        [1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1],\n        [0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0],\n        [0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1],\n        [1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1],\n        [1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0],\n        [1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0],\n        [0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1],\n        [1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0],\n        [0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1],\n        [0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1],\n        [1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1],\n        [0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1],\n        [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1],\n        [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0],\n        [1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1],\n        [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1],\n        [1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1],\n        [0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1]], dtype=torch.int32)"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Original matrix provided by the user\n",
    "matrix = torch.tensor([\n",
    "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0 ,0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0],\n",
    "[0, 1, 0, 0, 0, 0, 0, 0 ,0 ,0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1],\n",
    "[0, 0, 1, 0, 0, 0, 0, 0, 0 ,0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1],\n",
    "[0, 0, 0, 1, 0, 0, 0, 0 ,0 ,0, 0 ,0, 1, 0, 1, 0, 0, 0, 0 ,0 ,1 ,1 ,0 ,1 ,1 ,0 ,1, 1, 1, 0, 1, 0, 1, 0],\n",
    "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0],\n",
    "[0, 0, 0 ,0, 0, 1, 0, 0 ,0 ,0 ,0, 0 ,1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1],\n",
    "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0 ,1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1 ,0 ,1 ,0 ,1 ,1 ,1 ,0 ,1 ,1 ,1],\n",
    "[0, 0, 0, 0 ,0, 0, 0, 1 ,0 ,0 ,0 ,0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0],\n",
    "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0 ,1 ,1, 1, 1, 0, 0 ,1 ,0 ,0, 0, 1, 1, 0],\n",
    "[0, 0, 0, 0, 0 ,0, 0, 0 ,0 ,1 ,0 ,0 ,1 ,1 ,1, 0, 0, 0, 0 ,1 ,1 ,0 ,0 ,0 ,1 ,1 ,0, 1, 1, 1, 0, 1 ,0, 0],\n",
    "[0, 0, 0, 0, 0, 0, 0, 0 ,0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1 ,1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
    "[0, 0, 0, 0, 0, 0 ,0, 0 ,0 ,0 ,0 ,1 ,0 ,1 ,0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1],\n",
    "], dtype=torch.int)\n",
    "\n",
    "\n",
    "# Compute the transpose of the matrix\n",
    "transposed_matrix = matrix.t()\n",
    "\n",
    "transposed_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n         1, 1, 1, 0],\n        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n         1, 0, 1, 1],\n        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n         1, 1, 1, 1],\n        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n         1, 1, 1, 0],\n        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n         0, 1, 1, 0],\n        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n         0, 0, 1, 0],\n        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n         1, 1, 1, 0],\n        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 1, 1],\n        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n         1, 0, 0, 1],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n         0, 1, 0, 1]]),\n tensor([[1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.],\n         [1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.],\n         [1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n          0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n          1., 0., 0., 0., 0., 0., 0., 0.],\n         [1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 1., 0., 0., 0., 0., 0., 0.],\n         [0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 1., 0., 0., 0., 0., 0.],\n         [1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 1., 0., 0., 0., 0.],\n         [0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 1., 0., 0., 0.],\n         [0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 1., 0., 0.],\n         [0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 1., 0.],\n         [0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 1.]]))"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define dimensions\n",
    "k, n = 10, 26\n",
    "r = n - k\n",
    "\n",
    "# Construct G\n",
    "G_identity = np.eye(k, dtype=int)\n",
    "G_parity = np.random.randint(0, 2, size=(k, r))\n",
    "G = np.hstack((G_identity, G_parity))\n",
    "\n",
    "# # Construct H by finding nullspace of G\n",
    "# H = np.linalg.null_space(G.T)\n",
    "\n",
    "G\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T13:03:32.905722Z",
     "start_time": "2024-02-08T13:03:32.895187Z"
    }
   },
   "id": "623c9a045aea3b08",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6f6747a3decaf13d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1 tensor(-4.5343)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "bits = 10\n",
    "encoded = 26\n",
    "test1 = 10 * torch.log10(torch.tensor(bits / encoded, dtype=torch.float)) \n",
    "test1 = test1 - torch.tensor(10/26)\n",
    "\n",
    "print(\"test1\", test1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T06:42:33.350514Z",
     "start_time": "2024-02-16T06:42:33.347735Z"
    }
   },
   "id": "738b066926644aa2",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module BCH:\n",
      "\n",
      "NAME\n",
      "    BCH - BCH Library\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        bchlib.BCH\n",
      "    \n",
      "    class BCH(builtins.object)\n",
      "     |  BCH Encoder/Decoder\n",
      "     |  \n",
      "     |  __init__(t, poly=None, m=None, swap_bits=False) → bch\n",
      "     |      Constructor creates a BCH object with given 't' bit strength.  At\n",
      "     |      least one of 'poly' and/or 'm' must be provided.  If 'poly' is\n",
      "     |      provided but 'm' (Galois field order) is not, 'm' will be\n",
      "     |      calculated automatically.  If 'm' between 5 and 15 inclusive is'\n",
      "     |      provided, 'polywill be selected automatically.  The 'swap_bits'\n",
      "     |      parameter will reverse the bit order within data and syndrome\n",
      "     |      bytes.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  compute_even_syn(...)\n",
      "     |    compute_even_syn(syn) → syn\n",
      "     |      Computes even syndromes from odd ones.  Takes a sequence of\n",
      "     |      2*t values and returns a tuple of 2*t elements.\n",
      "     |  \n",
      "     |  correct(...)\n",
      "     |    correct(data=None, ecc=None) → None\n",
      "     |      Corrects 'data' and 'ecc' if provided.  Buffers must not be\n",
      "     |      readonly.\n",
      "     |  \n",
      "     |  decode(...)\n",
      "     |    decode(data=None, recv_ecc=None, calc_ecc=None, syn=None) → nerr\n",
      "     |      Calculates error locations and returns the number of errors found\n",
      "     |      or negative if decoding failed.\n",
      "     |      \n",
      "     |      There are four ways that 'decode' can function by providing\n",
      "     |      different input parameters:\n",
      "     |      \n",
      "     |          'data' and 'recv_ecc'\n",
      "     |          'recv_ecc' and 'calc_ecc'\n",
      "     |          'calc_ecc' (as recv_ecc XOR calc_ecc)\n",
      "     |          'syn' (a sequence of 2*t values)\n",
      "     |      \n",
      "     |      'data_len' SHOULD be set before calling this function.\n",
      "     |  \n",
      "     |  encode(...)\n",
      "     |    encode(data[, ecc]) → ecc\n",
      "     |      Encodes 'data' with an optional starting 'ecc'.  Returns the\n",
      "     |      calculated ecc.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  data_len\n",
      "     |      Read/write; decode data length in bytes.  Set this value before\n",
      "     |      decoding.\n",
      "     |  \n",
      "     |  ecc_bits\n",
      "     |      Readonly; number of ecc bits.\n",
      "     |  \n",
      "     |  ecc_bytes\n",
      "     |      Readonly; number of ecc bytes.\n",
      "     |  \n",
      "     |  errloc\n",
      "     |      Readonly; tuple of error bit locations.\n",
      "     |  \n",
      "     |  m\n",
      "     |      Readonly; Galois field order.\n",
      "     |  \n",
      "     |  n\n",
      "     |      Readonly; maximum codeword size in bits.\n",
      "     |  \n",
      "     |  prim_poly\n",
      "     |      Readonly; primitive polynomial for bch operations.\n",
      "     |  \n",
      "     |  syn\n",
      "     |      Readonly; a tuple of syndromes after performing a decode().\n",
      "     |  \n",
      "     |  t\n",
      "     |      Readonly; the number of bit errors that can be corrected.\n",
      "\n",
      "FILE\n",
      "    /opt/homebrew/Caskroom/miniforge/base/envs/thesis/lib/python3.9/site-packages/bchlib.cpython-39-darwin.so\n"
     ]
    }
   ],
   "source": [
    "import bchlib\n",
    "help(bchlib)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T08:01:12.293585Z",
     "start_time": "2024-02-16T08:01:12.227579Z"
    }
   },
   "id": "acfae60b40662eac",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (7) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 22\u001B[0m\n\u001B[1;32m     11\u001B[0m tensor2_reshaped \u001B[38;5;241m=\u001B[39m tensor2\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# Broadcast tensor2 across the rows of tensor1 and perform element-wise division\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# Note: tensor1 needs to be divided in a manner that matches your description, which seems to have a misunderstanding.\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# If you intend to divide each column by a single value, tensor2 should represent a value per column, not per row.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     20\u001B[0m \n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# Perform the division\u001B[39;00m\n\u001B[0;32m---> 22\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mtensor1\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtensor2_reshaped\u001B[49m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mResulting Tensor:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, result)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: The size of tensor a (7) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Your first tensor\n",
    "tensor1 = torch.tensor([[0.1582, 0.2170, 0.1495, 0.3974, 0.4741, 0.2054, 0.7275],\n",
    "                        [0.8117, 0.4013, 0.1386, 0.2082, 0.2137, 0.1977, 0.0406]])\n",
    "\n",
    "# Your second tensor, which seems to be intended as a per-column property\n",
    "tensor2 = torch.tensor([2.3291, 2.0119])\n",
    "\n",
    "# Reshape tensor2 from [2] to [1, 2] for proper broadcasting\n",
    "tensor2_reshaped = tensor2.view(1, -1)\n",
    "\n",
    "# Broadcast tensor2 across the rows of tensor1 and perform element-wise division\n",
    "# Note: tensor1 needs to be divided in a manner that matches your description, which seems to have a misunderstanding.\n",
    "# If you intend to divide each column by a single value, tensor2 should represent a value per column, not per row.\n",
    "# Assuming a correction, where tensor2 represents column-wise properties and has shape [7], here's a corrected approach:\n",
    "\n",
    "# Corrected tensor2 for column-wise properties\n",
    "# tensor2_corrected = torch.tensor([2.3291, 2.0119])  # Placeholder, replace with actual column-wise values\n",
    "\n",
    "# Perform the division\n",
    "result = tensor1 / tensor2_reshaped\n",
    "\n",
    "print(\"Resulting Tensor:\\n\", result)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T05:03:06.522649Z",
     "start_time": "2024-02-22T05:03:06.499Z"
    }
   },
   "id": "fe1d9a51737f0658",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3689e2ad851715ef"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
