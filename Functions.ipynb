{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-25T16:08:07.783008Z",
     "start_time": "2024-04-25T16:08:04.036333Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "# Original matrix provided by the user\n",
    "matrix = torch.tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                          [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                          [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "                                          [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "                                          [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "                                          [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "                                          [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "                                          [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "                                          [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "                                          [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "                                          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                                          [1, 0, 0, 0, 1, 0, 1, 0, 0, 1],\n",
    "                                          [0, 0, 1, 1, 0, 1, 1, 1, 0, 1],\n",
    "                                          [0, 0, 1, 0, 1, 0, 0, 1, 1, 0],\n",
    "                                          [1, 1, 0, 0, 0, 0, 1, 1, 1, 0],\n",
    "                                          [1, 0, 1, 0, 1, 0, 1, 1, 0, 0],\n",
    "                                          [1, 0, 0, 0, 1, 0, 1, 0, 1, 0],\n",
    "                                          [0, 0, 1, 0, 1, 1, 0, 1, 0, 1],\n",
    "                                          [1, 1, 1, 1, 1, 0, 0, 1, 0, 1],\n",
    "                                          [1, 1, 1, 1, 1, 1, 0, 0, 1, 0],\n",
    "                                          [0, 1, 0, 0, 1, 1, 1, 0, 1, 0],\n",
    "                                          [0, 1, 1, 1, 0, 0, 1, 1, 1, 0],\n",
    "                                          [1, 0, 1, 1, 0, 0, 0, 0, 1, 1],\n",
    "                                          [0, 1, 1, 0, 1, 0, 1, 0, 0, 1]]\n",
    "                                         )  # Matrix from author\n",
    "\n",
    "\n",
    "# Compute the transpose of the matrix\n",
    "transposed_matrix = matrix.t()\n",
    "\n",
    "transposed_matrix\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n        [1, 1, 0, 0, 0, 0, 1, 0, 0, 0],\n        [0, 1, 1, 0, 0, 0, 0, 1, 0, 0],\n        [0, 0, 1, 1, 0, 0, 0, 0, 1, 0],\n        [0, 0, 0, 1, 1, 0, 0, 0, 0, 1]], dtype=torch.int32)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Given generator matrix G\n",
    "G = torch.tensor([[1, 0, 0, 0, 0, 1, 1, 0, 0, 0],\n",
    "        [0, 1, 0, 0, 0, 0, 1, 1, 0, 0],\n",
    "        [0, 0, 1, 0, 0, 0, 0, 1, 1, 0],\n",
    "        [0, 0, 0, 1, 0, 0, 0, 0, 1, 1],\n",
    "        [0, 0, 0, 0, 1, 1, 0, 0, 0, 1]], dtype=torch.int32)\n",
    "\n",
    "\n",
    "r = G.shape[1] - G.shape[0]\n",
    "\n",
    "# Extracting P from G\n",
    "P = G[:, G.shape[0]:]  # G is [I|P], so P starts from the n th column\n",
    "\n",
    "# Constructing H = [P^T|I]\n",
    "P_T = P.T  # Transpose of P\n",
    "I_n = torch.eye(r, dtype=torch.int)  # 13x13 Identity matrix\n",
    "\n",
    "# Concatenating P^T and I to form H\n",
    "H = torch.cat((P_T, I_n), dim=1)\n",
    "\n",
    "H\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T19:02:48.347305Z",
     "start_time": "2024-03-24T19:02:48.339663Z"
    }
   },
   "id": "534742e83a22cf71",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate values: tensor([0.0141, 0.0192, 0.0278, 0.0400, 0.0535], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/71/hry96qw555j_rlvg3tfgrh180000gn/T/ipykernel_12621/3611571557.py:139: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tensor = torch.tensor(input_tensor)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Your input tensor\n",
    "input_tensor = torch.tensor([[3.0083e-03, 3.1616e-03, 6.0675e-03, 6.5333e-03, 8.2441e-03, 1.2584e-02,\n",
    "         1.3155e-02, 1.5488e-02, 2.0086e-02, 3.0269e-02, 3.1004e-02, 3.2125e-02,\n",
    "         3.7569e-02, 3.8728e-02, 3.9285e-02, 3.9689e-02, 5.3265e-02, 5.6493e-02,\n",
    "         5.7378e-02, 6.0600e-02, 6.4743e-02, 6.4995e-02, 6.6715e-02, 7.5484e-02,\n",
    "         1.0691e-01, 1.0903e-01],\n",
    "        [1.3221e-03, 7.3268e-03, 9.4341e-03, 1.1033e-02, 1.1468e-02, 1.4629e-02,\n",
    "         1.7105e-02, 2.3350e-02, 2.5700e-02, 2.5911e-02, 2.6873e-02, 2.7617e-02,\n",
    "         2.9114e-02, 3.4703e-02, 3.8042e-02, 3.8977e-02, 4.0865e-02, 5.2903e-02,\n",
    "         5.7285e-02, 6.3002e-02, 6.5316e-02, 6.6833e-02, 7.0900e-02, 7.1274e-02,\n",
    "         9.7959e-02, 1.1412e-01],\n",
    "        [7.1283e-03, 1.0611e-02, 1.7992e-02, 1.9297e-02, 2.5916e-02, 2.8985e-02,\n",
    "         3.0291e-02, 3.2495e-02, 3.2541e-02, 3.3002e-02, 3.5224e-02, 3.6713e-02,\n",
    "         3.7401e-02, 3.9775e-02, 4.0491e-02, 4.2596e-02, 4.4214e-02, 4.4239e-02,\n",
    "         5.0540e-02, 5.1263e-02, 5.2231e-02, 5.7817e-02, 6.6235e-02, 8.6738e-02,\n",
    "         8.7009e-02, 9.2442e-02],\n",
    "        [4.2484e-03, 6.8425e-03, 6.8973e-03, 7.7753e-03, 7.8265e-03, 1.0208e-02,\n",
    "         1.0395e-02, 1.2935e-02, 1.3802e-02, 1.5797e-02, 1.6999e-02, 1.7254e-02,\n",
    "         1.8226e-02, 1.9985e-02, 2.2561e-02, 2.3862e-02, 3.3080e-02, 3.7970e-02,\n",
    "         3.8100e-02, 3.8329e-02, 4.9399e-02, 5.1777e-02, 7.9807e-02, 9.2622e-02,\n",
    "         1.1873e-01, 1.5848e-01],\n",
    "        [5.5660e-04, 2.0125e-03, 2.6594e-03, 3.3595e-03, 1.2656e-02, 1.3436e-02,\n",
    "         1.4226e-02, 1.6788e-02, 1.9201e-02, 2.0358e-02, 2.0744e-02, 2.1197e-02,\n",
    "         2.5366e-02, 2.6925e-02, 3.2557e-02, 3.6414e-02, 3.6679e-02, 4.1321e-02,\n",
    "         5.3347e-02, 5.3581e-02, 5.7032e-02, 6.5023e-02, 6.8422e-02, 6.9262e-02,\n",
    "         7.6953e-02, 1.3839e-01],\n",
    "        [2.0801e-03, 2.4136e-03, 3.5727e-03, 1.1300e-02, 1.5775e-02, 1.8220e-02,\n",
    "         2.0900e-02, 2.1705e-02, 2.4711e-02, 2.6681e-02, 2.8186e-02, 3.8356e-02,\n",
    "         3.9045e-02, 3.9966e-02, 4.3487e-02, 4.8293e-02, 5.3541e-02, 5.6416e-02,\n",
    "         5.9791e-02, 6.1492e-02, 6.3674e-02, 6.7850e-02, 6.9201e-02, 7.5795e-02,\n",
    "         7.8803e-02, 1.1959e-01],\n",
    "        [5.3599e-03, 6.4482e-03, 8.6390e-03, 1.7177e-02, 1.9497e-02, 2.3202e-02,\n",
    "         2.3741e-02, 2.5302e-02, 2.6895e-02, 3.1258e-02, 3.3266e-02, 3.5806e-02,\n",
    "         3.8859e-02, 3.9430e-02, 4.0835e-02, 4.2538e-02, 4.2570e-02, 4.4366e-02,\n",
    "         4.4873e-02, 4.5408e-02, 5.3087e-02, 6.5003e-02, 8.4035e-02, 8.6620e-02,\n",
    "         9.7284e-02, 1.0101e-01],\n",
    "        [3.0335e-04, 8.9654e-04, 2.2724e-03, 3.1344e-03, 7.3746e-03, 9.2980e-03,\n",
    "         1.6408e-02, 1.7313e-02, 1.8462e-02, 1.9998e-02, 2.1239e-02, 2.6938e-02,\n",
    "         3.0755e-02, 3.5165e-02, 3.6434e-02, 4.9490e-02, 5.0804e-02, 5.4259e-02,\n",
    "         5.6295e-02, 6.0879e-02, 6.2961e-02, 6.4877e-02, 7.3881e-02, 7.4717e-02,\n",
    "         8.7457e-02, 9.6392e-02],\n",
    "        [1.5611e-03, 6.7562e-03, 1.4590e-02, 1.5814e-02, 1.6602e-02, 1.8785e-02,\n",
    "         1.9021e-02, 1.9201e-02, 1.9506e-02, 2.2445e-02, 2.5811e-02, 3.2622e-02,\n",
    "         3.9289e-02, 4.0257e-02, 4.0880e-02, 4.2875e-02, 4.3069e-02, 4.3545e-02,\n",
    "         5.0287e-02, 5.8044e-02, 5.8070e-02, 7.3728e-02, 7.6429e-02, 8.0666e-02,\n",
    "         9.2495e-02, 1.1224e-01],\n",
    "        [1.5056e-03, 8.2564e-03, 1.5047e-02, 1.9042e-02, 2.1474e-02, 2.2377e-02,\n",
    "         2.3036e-02, 2.3081e-02, 2.7866e-02, 3.2072e-02, 3.8713e-02, 4.0300e-02,\n",
    "         4.3683e-02, 4.4202e-02, 4.4431e-02, 4.5672e-02, 4.6683e-02, 5.2054e-02,\n",
    "         5.2082e-02, 5.3192e-02, 5.7142e-02, 5.7429e-02, 5.9814e-02, 6.6319e-02,\n",
    "         8.6178e-02, 1.0817e-01],\n",
    "        [2.2940e-03, 2.9243e-03, 9.6910e-03, 1.5851e-02, 1.7700e-02, 1.8841e-02,\n",
    "         2.1730e-02, 2.8473e-02, 3.0124e-02, 3.0139e-02, 3.1092e-02, 3.1341e-02,\n",
    "         3.2037e-02, 3.5747e-02, 3.6365e-02, 3.6567e-02, 3.9741e-02, 4.2507e-02,\n",
    "         4.7135e-02, 5.4287e-02, 5.7296e-02, 6.2911e-02, 7.0069e-02, 7.3890e-02,\n",
    "         7.9534e-02, 1.3303e-01],\n",
    "        [4.3359e-03, 5.8434e-03, 5.9073e-03, 8.5502e-03, 9.2095e-03, 1.2603e-02,\n",
    "         1.6521e-02, 1.6858e-02, 1.6983e-02, 2.3689e-02, 2.6244e-02, 3.5347e-02,\n",
    "         3.7151e-02, 3.8105e-02, 3.9748e-02, 3.9767e-02, 4.0293e-02, 4.9197e-02,\n",
    "         5.3958e-02, 5.5036e-02, 5.7348e-02, 6.1878e-02, 6.2973e-02, 7.2877e-02,\n",
    "         1.0066e-01, 1.2330e-01],\n",
    "        [1.5250e-03, 4.5488e-03, 7.9060e-03, 1.0252e-02, 1.7037e-02, 2.2032e-02,\n",
    "         2.4149e-02, 2.7349e-02, 2.7782e-02, 2.8282e-02, 2.8309e-02, 3.2108e-02,\n",
    "         3.2990e-02, 3.3622e-02, 3.5649e-02, 3.7887e-02, 3.9154e-02, 3.9317e-02,\n",
    "         4.0458e-02, 6.2671e-02, 6.3598e-02, 6.8723e-02, 7.3105e-02, 7.9279e-02,\n",
    "         8.0859e-02, 1.0340e-01],\n",
    "        [1.5792e-04, 6.3351e-04, 4.6877e-03, 5.2788e-03, 9.2323e-03, 1.0821e-02,\n",
    "         1.1623e-02, 1.8477e-02, 1.8722e-02, 1.8862e-02, 2.3055e-02, 2.3696e-02,\n",
    "         2.4524e-02, 2.6848e-02, 3.8011e-02, 3.9438e-02, 4.7112e-02, 5.7752e-02,\n",
    "         6.2822e-02, 6.3579e-02, 6.3979e-02, 6.8528e-02, 7.0309e-02, 8.4402e-02,\n",
    "         8.4945e-02, 1.2654e-01],\n",
    "        [2.4943e-03, 6.3642e-03, 8.7909e-03, 9.4770e-03, 1.1173e-02, 1.3833e-02,\n",
    "         1.4052e-02, 1.5155e-02, 1.7391e-02, 2.2566e-02, 2.3308e-02, 2.7782e-02,\n",
    "         2.9756e-02, 3.1007e-02, 3.6429e-02, 3.6844e-02, 3.7610e-02, 3.7920e-02,\n",
    "         4.2593e-02, 4.7572e-02, 5.8431e-02, 6.3359e-02, 6.5714e-02, 6.9379e-02,\n",
    "         7.5829e-02, 1.6625e-01],\n",
    "        [1.0302e-03, 4.8205e-03, 6.7405e-03, 1.0314e-02, 1.0922e-02, 1.2832e-02,\n",
    "         1.3931e-02, 1.5088e-02, 1.5166e-02, 1.5863e-02, 1.6168e-02, 1.6226e-02,\n",
    "         2.4997e-02, 2.8329e-02, 2.8529e-02, 3.1832e-02, 3.5885e-02, 3.7867e-02,\n",
    "         3.9703e-02, 4.3035e-02, 5.3156e-02, 5.4155e-02, 5.9132e-02, 6.9235e-02,\n",
    "         8.1260e-02, 1.7775e-01],\n",
    "        [1.6537e-03, 8.3804e-03, 1.2032e-02, 1.2058e-02, 1.2391e-02, 1.3463e-02,\n",
    "         1.6592e-02, 1.7380e-02, 2.0059e-02, 2.1076e-02, 2.4160e-02, 2.8462e-02,\n",
    "         3.1169e-02, 3.3328e-02, 3.7480e-02, 3.8598e-02, 4.0849e-02, 4.3690e-02,\n",
    "         4.7401e-02, 4.8153e-02, 5.0227e-02, 5.1004e-02, 5.6740e-02, 6.8253e-02,\n",
    "         1.3132e-01, 1.4083e-01],\n",
    "        [4.6497e-04, 1.0819e-03, 1.9085e-03, 3.4252e-03, 5.6628e-03, 9.9311e-03,\n",
    "         1.2732e-02, 1.4344e-02, 1.9206e-02, 2.0107e-02, 2.2409e-02, 2.2667e-02,\n",
    "         2.3964e-02, 3.0381e-02, 3.3097e-02, 3.7553e-02, 3.8870e-02, 3.9910e-02,\n",
    "         3.9966e-02, 4.4776e-02, 4.5153e-02, 4.7358e-02, 6.5089e-02, 8.6776e-02,\n",
    "         1.1309e-01, 1.2710e-01],\n",
    "        [2.5377e-03, 6.4902e-03, 7.0994e-03, 1.7103e-02, 1.7145e-02, 1.8695e-02,\n",
    "         1.8853e-02, 2.0173e-02, 2.0884e-02, 2.2178e-02, 2.3601e-02, 2.8923e-02,\n",
    "         3.0899e-02, 3.8024e-02, 3.8566e-02, 3.9190e-02, 3.9304e-02, 4.1436e-02,\n",
    "         4.8227e-02, 4.9852e-02, 6.0789e-02, 6.1254e-02, 6.1989e-02, 7.6401e-02,\n",
    "         1.1984e-01, 1.2893e-01],\n",
    "        [1.6138e-05, 4.5591e-03, 5.6214e-03, 9.2112e-03, 9.2723e-03, 1.0368e-02,\n",
    "         1.3537e-02, 1.7402e-02, 1.8148e-02, 1.8997e-02, 2.0159e-02, 2.7763e-02,\n",
    "         2.7960e-02, 2.8881e-02, 3.0631e-02, 3.7769e-02, 3.8571e-02, 4.5839e-02,\n",
    "         4.8914e-02, 5.1470e-02, 5.3732e-02, 5.3989e-02, 6.0621e-02, 8.3376e-02,\n",
    "         1.0961e-01, 1.3176e-01],\n",
    "        [1.4028e-03, 2.5876e-03, 7.6306e-03, 8.5851e-03, 8.8311e-03, 9.7975e-03,\n",
    "         1.1255e-02, 1.4052e-02, 1.5694e-02, 1.7409e-02, 1.7645e-02, 1.8543e-02,\n",
    "         2.2503e-02, 2.2540e-02, 2.4129e-02, 2.6356e-02, 3.6451e-02, 3.7318e-02,\n",
    "         3.7359e-02, 3.7456e-02, 4.2406e-02, 5.1048e-02, 5.1249e-02, 6.4312e-02,\n",
    "         7.8132e-02, 2.2206e-01],\n",
    "        [2.0189e-03, 5.4862e-03, 6.2580e-03, 1.2696e-02, 1.4789e-02, 1.5065e-02,\n",
    "         1.7026e-02, 1.8809e-02, 2.0607e-02, 2.7080e-02, 3.0410e-02, 3.3212e-02,\n",
    "         3.4335e-02, 3.4497e-02, 3.5698e-02, 3.8943e-02, 3.9133e-02, 3.9808e-02,\n",
    "         4.0838e-02, 4.2480e-02, 4.9412e-02, 5.6415e-02, 7.4381e-02, 9.5056e-02,\n",
    "         1.0251e-01, 1.0950e-01],\n",
    "        [3.2703e-03, 4.8010e-03, 6.3467e-03, 7.9069e-03, 1.1444e-02, 1.4132e-02,\n",
    "         1.5917e-02, 1.8622e-02, 1.9777e-02, 2.1000e-02, 2.1346e-02, 2.1693e-02,\n",
    "         2.2720e-02, 2.4757e-02, 2.5678e-02, 2.5732e-02, 2.9713e-02, 3.4565e-02,\n",
    "         3.7677e-02, 3.7737e-02, 3.8707e-02, 4.1704e-02, 4.9912e-02, 5.1611e-02,\n",
    "         1.0163e-01, 2.2377e-01],\n",
    "        [1.7870e-03, 2.3936e-03, 3.9603e-03, 5.0227e-03, 1.5789e-02, 1.9671e-02,\n",
    "         2.0066e-02, 2.2187e-02, 2.4171e-02, 2.5010e-02, 2.9144e-02, 3.2942e-02,\n",
    "         3.8171e-02, 3.8187e-02, 3.8275e-02, 3.9156e-02, 4.0700e-02, 4.1194e-02,\n",
    "         4.1989e-02, 5.5181e-02, 5.8714e-02, 6.2111e-02, 6.3314e-02, 8.6176e-02,\n",
    "         1.0240e-01, 1.1871e-01],\n",
    "        [3.6933e-04, 1.5764e-03, 4.1934e-03, 5.9426e-03, 8.4030e-03, 1.3478e-02,\n",
    "         1.4469e-02, 1.6638e-02, 2.2701e-02, 2.4571e-02, 2.4652e-02, 2.6133e-02,\n",
    "         3.3755e-02, 3.5226e-02, 3.6325e-02, 3.9047e-02, 3.9368e-02, 4.2097e-02,\n",
    "         4.6810e-02, 4.7048e-02, 5.3541e-02, 5.4440e-02, 9.4555e-02, 1.0012e-01,\n",
    "         1.0536e-01, 1.1463e-01],\n",
    "        [8.5733e-04, 4.0885e-03, 1.0012e-02, 1.2415e-02, 1.2829e-02, 1.3480e-02,\n",
    "         1.5628e-02, 1.7189e-02, 2.0365e-02, 2.1681e-02, 2.2652e-02, 2.5738e-02,\n",
    "         3.2399e-02, 3.3686e-02, 3.4928e-02, 3.5160e-02, 3.5714e-02, 3.5844e-02,\n",
    "         3.6584e-02, 3.6623e-02, 4.3504e-02, 4.8736e-02, 6.5366e-02, 8.3090e-02,\n",
    "         9.7509e-02, 1.6255e-01]], dtype=torch.float64)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convert to a tensor for processing\n",
    "tensor = torch.tensor(input_tensor)\n",
    "\n",
    "# Find unique values and their counts\n",
    "unique_values, counts = tensor.unique(return_counts=True)\n",
    "\n",
    "# Filter out values that occur more than once\n",
    "duplicate_values = unique_values[counts > 1]\n",
    "\n",
    "# Print duplicate values if any\n",
    "if len(duplicate_values) > 0:\n",
    "    print(\"Duplicate values:\", duplicate_values)\n",
    "else:\n",
    "    print(\"No duplicate values.\")\n",
    "\n",
    "# # Apply thresholding operation\n",
    "# output_tensor = torch.where(input_tensor != 0, torch.tensor(1), torch.tensor(0))\n",
    "# print(output_tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T21:26:00.319335Z",
     "start_time": "2024-03-27T21:26:00.301881Z"
    }
   },
   "id": "1e5a8d41c954f6ee",
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model_pth = \"Result/Model/Parity26_10/SLNN_deleted_cpu/SLNN_24_deleted573.pth\"\n",
    "model = torch.load(model_pth)\n",
    "# print(model['hidden.weight'])\n",
    "mask = (model['hidden.weight'] != 0).int()\n",
    "# print(mask)\n",
    "columns_all_zeros = (mask.sum(dim=1) == 0).nonzero().squeeze()\n",
    "print(columns_all_zeros)\n",
    "\n",
    "# num_zeros = (mask == 0).sum().item()\n",
    "# print(num_zeros)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T21:19:11.736804Z",
     "start_time": "2024-03-27T21:19:11.730761Z"
    }
   },
   "id": "768ea810a7a0c3f7",
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "model_pth = \"Result/Model/Hamming7_4/MLNN_cpu/MLNN_hiddenlayer16.pth\"\n",
    "model = torch.load(model_pth)\n",
    "# print(model['hidden.weight'])\n",
    "mask = (model['hidden.weight'] != 0).int()\n",
    "print(mask)\n",
    "# columns_all_zeros = (mask.sum(dim=1) == 0).nonzero().squeeze()\n",
    "# print(columns_all_zeros)\n",
    "\n",
    "# num_zeros = (mask == 0).sum().item()\n",
    "# print(num_zeros)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T13:18:16.729079Z",
     "start_time": "2024-04-18T13:18:16.720329Z"
    }
   },
   "id": "114da962bda378a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1]], dtype=torch.int32)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "model_pth = \"Result/Model/Hamming7_4/MLNN_cpu/MLNN_hiddenlayer16.pth\"\n",
    "model = torch.load(model_pth)\n",
    "weight = model['output.weight']\n",
    "print(\"weight:\",weight)\n",
    "\n",
    "normalized = torch.div(torch.abs(weight), torch.sum(torch.abs(weight), dim=1).unsqueeze(1))\n",
    "print(\"normalized:\",normalized)\n",
    "\n",
    "\n",
    "# weight = weight.reshape(-1)\n",
    "# for i in range(len(weight)):\n",
    "#     if weight[i] != 0:\n",
    "#         print(weight[i]) \n",
    "\n",
    "# mask = (model['hidden.weight'] != 0).int()\n",
    "# print(mask)\n",
    "\n",
    "# num_zeros = (mask == 0).sum().item()\n",
    "# print(num_zeros)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T12:00:02.216450Z",
     "start_time": "2024-04-18T12:00:02.207735Z"
    }
   },
   "id": "a8035ad431850992",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight: tensor([[-7.1434,  5.9491, -7.1838,  5.8777,  5.8976,  6.1248, -7.1393,  5.9942,\n",
      "          5.8656, -7.0526, -7.0469, -7.0384, -7.1566,  5.9064, -7.0496,  5.8176],\n",
      "        [ 7.3323, -5.7271,  7.4295, -5.8209,  7.4251, -5.8191, -5.7556,  7.2846,\n",
      "         -5.5899, -5.6120,  7.2219,  7.2154, -5.8123,  7.3695, -5.7519,  7.2174],\n",
      "        [ 6.7461,  6.7691, -6.3508, -6.1946, -6.2861,  6.8503, -6.2095, -6.2085,\n",
      "         -6.1618,  6.6891,  6.7193, -6.1740, -6.3354,  6.7960,  6.7642,  6.6077],\n",
      "        [ 6.4052, -6.4655, -6.4160,  6.4618, -6.3661,  6.5253, -6.3919,  6.4501,\n",
      "         -6.2676,  6.4047, -6.2696,  6.3432,  6.5044, -6.4794, -6.3447,  6.3427]])\n",
      "normalized: tensor([[0.0685, 0.0571, 0.0689, 0.0564, 0.0566, 0.0588, 0.0685, 0.0575, 0.0563,\n",
      "         0.0677, 0.0676, 0.0675, 0.0687, 0.0567, 0.0676, 0.0558],\n",
      "        [0.0702, 0.0549, 0.0712, 0.0558, 0.0711, 0.0557, 0.0551, 0.0698, 0.0536,\n",
      "         0.0538, 0.0692, 0.0691, 0.0557, 0.0706, 0.0551, 0.0691],\n",
      "        [0.0650, 0.0652, 0.0611, 0.0596, 0.0605, 0.0660, 0.0598, 0.0598, 0.0593,\n",
      "         0.0644, 0.0647, 0.0594, 0.0610, 0.0654, 0.0651, 0.0636],\n",
      "        [0.0625, 0.0631, 0.0626, 0.0631, 0.0621, 0.0637, 0.0624, 0.0630, 0.0612,\n",
      "         0.0625, 0.0612, 0.0619, 0.0635, 0.0633, 0.0619, 0.0619]])\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T12:06:13.730270Z",
     "start_time": "2024-04-18T12:06:13.724247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "data = torch.tensor([0.0685, 0.0571, 0.0689, 0.0564, 0.0566, 0.0588, 0.0685, 0.0575, 0.0563,\n",
    "         0.0677, 0.0676, 0.0675, 0.0687, 0.0567, 0.0676, 0.0558,\n",
    "        0.0702, 0.0549, 0.0712, 0.0558, 0.0711, 0.0557, 0.0551, 0.0698, 0.0536,\n",
    "         0.0538, 0.0692, 0.0691, 0.0557, 0.0706, 0.0551, 0.0691,\n",
    "        0.0650, 0.0652, 0.0611, 0.0596, 0.0605, 0.0660, 0.0598, 0.0598, 0.0593,\n",
    "         0.0644, 0.0647, 0.0594, 0.0610, 0.0654, 0.0651, 0.0636,\n",
    "        0.0625, 0.0631, 0.0626, 0.0631, 0.0621, 0.0637, 0.0624, 0.0630, 0.0612,\n",
    "         0.0625, 0.0612, 0.0619, 0.0635, 0.0633, 0.0619, 0.0619])\n",
    "order = torch.sort(data, dim=0, descending=False)\n",
    "print(order)"
   ],
   "id": "855102bd4d94896b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.sort(\n",
      "values=tensor([0.0536, 0.0538, 0.0549, 0.0551, 0.0551, 0.0557, 0.0557, 0.0558, 0.0558,\n",
      "        0.0563, 0.0564, 0.0566, 0.0567, 0.0571, 0.0575, 0.0588, 0.0593, 0.0594,\n",
      "        0.0596, 0.0598, 0.0598, 0.0605, 0.0610, 0.0611, 0.0612, 0.0612, 0.0619,\n",
      "        0.0619, 0.0619, 0.0621, 0.0624, 0.0625, 0.0625, 0.0626, 0.0630, 0.0631,\n",
      "        0.0631, 0.0633, 0.0635, 0.0636, 0.0637, 0.0644, 0.0647, 0.0650, 0.0651,\n",
      "        0.0652, 0.0654, 0.0660, 0.0675, 0.0676, 0.0676, 0.0677, 0.0685, 0.0685,\n",
      "        0.0687, 0.0689, 0.0691, 0.0691, 0.0692, 0.0698, 0.0702, 0.0706, 0.0711,\n",
      "        0.0712]),\n",
      "indices=tensor([24, 25, 17, 22, 30, 21, 28, 19, 15,  8,  3,  4, 13,  1,  7,  5, 40, 43,\n",
      "        35, 39, 38, 36, 44, 34, 56, 58, 63, 59, 62, 52, 54, 48, 57, 50, 55, 51,\n",
      "        49, 61, 60, 47, 53, 41, 42, 32, 46, 33, 45, 37, 11, 10, 14,  9,  0,  6,\n",
      "        12,  2, 27, 31, 26, 23, 16, 29, 20, 18]))\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "device = \"cpu\"\n",
    "num = int(2e7)\n",
    "bits = 10\n",
    "encoded = 26\n",
    "encoding_method = \"Parity\"\n",
    "NN_type = \"SLNN\"\n",
    "batch_size = int(1e4)\n",
    "SLNN_hidden_size = 26\n",
    "edge_delete_range = np.arange(0, 26*26+1, 1)\n",
    "result_all = np.array([])\n",
    "\n",
    "for i in range(0, len(edge_delete_range)):\n",
    "    model_pth = f\"Result/Model/{encoding_method}{encoded}_{bits}/{NN_type}_{SLNN_hidden_size}_deleted_{device}/{NN_type}_deleted{edge_delete_range[i]}.pth\"\n",
    "    if not os.path.exists(model_pth):\n",
    "        continue\n",
    "    result_all = np.append(result_all, edge_delete_range[i])\n",
    "\n",
    "    \n",
    "directory_path = f\"Result/\"\n",
    "\n",
    "if not os.path.exists(directory_path):\n",
    "    os.makedirs(directory_path)\n",
    "\n",
    "csv_filename = f\"{NN_type}_{SLNN_hidden_size}_deleted.txt\"\n",
    "full_csv_path = os.path.join(directory_path, csv_filename)\n",
    "\n",
    "# Ensure result_all is reshaped to have one column for correct .csv formatting\n",
    "result_all = result_all.reshape(-1, 1)\n",
    "np.savetxt(full_csv_path, result_all, delimiter=',', fmt='%d')  # Assuming edge_delete_range consists of integers\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T21:02:43.212346Z",
     "start_time": "2024-04-01T21:02:43.191342Z"
    }
   },
   "id": "15df8dfda07406be",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "mask = torch.tensor([[1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1]], dtype=torch.int32)\n",
    "\n",
    "one_positions = (mask == 1).nonzero()\n",
    "\n",
    "print(one_positions)\n",
    "# # Set the specific positions where 1 is found to 0\n",
    "# for position in one_positions:\n",
    "#     mask[position[0], position[1]] = 0\n",
    "#     \n",
    "# print(mask)\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T13:18:45.729205Z",
     "start_time": "2024-04-18T13:18:45.721381Z"
    }
   },
   "id": "ea844061c7080ccb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  0],\n",
      "        [ 0,  1],\n",
      "        [ 0,  2],\n",
      "        [ 0,  3],\n",
      "        [ 0,  4],\n",
      "        [ 0,  5],\n",
      "        [ 0,  6],\n",
      "        [ 1,  0],\n",
      "        [ 1,  1],\n",
      "        [ 1,  2],\n",
      "        [ 1,  3],\n",
      "        [ 1,  4],\n",
      "        [ 1,  5],\n",
      "        [ 1,  6],\n",
      "        [ 2,  0],\n",
      "        [ 2,  1],\n",
      "        [ 2,  2],\n",
      "        [ 2,  3],\n",
      "        [ 2,  4],\n",
      "        [ 2,  5],\n",
      "        [ 2,  6],\n",
      "        [ 3,  0],\n",
      "        [ 3,  1],\n",
      "        [ 3,  2],\n",
      "        [ 3,  3],\n",
      "        [ 3,  4],\n",
      "        [ 3,  5],\n",
      "        [ 3,  6],\n",
      "        [ 4,  0],\n",
      "        [ 4,  1],\n",
      "        [ 4,  2],\n",
      "        [ 4,  3],\n",
      "        [ 4,  4],\n",
      "        [ 4,  5],\n",
      "        [ 4,  6],\n",
      "        [ 5,  0],\n",
      "        [ 5,  1],\n",
      "        [ 5,  2],\n",
      "        [ 5,  3],\n",
      "        [ 5,  4],\n",
      "        [ 5,  5],\n",
      "        [ 5,  6],\n",
      "        [ 6,  0],\n",
      "        [ 6,  1],\n",
      "        [ 6,  2],\n",
      "        [ 6,  3],\n",
      "        [ 6,  4],\n",
      "        [ 6,  5],\n",
      "        [ 6,  6],\n",
      "        [ 7,  0],\n",
      "        [ 7,  1],\n",
      "        [ 7,  2],\n",
      "        [ 7,  3],\n",
      "        [ 7,  4],\n",
      "        [ 7,  5],\n",
      "        [ 7,  6],\n",
      "        [ 8,  0],\n",
      "        [ 8,  1],\n",
      "        [ 8,  2],\n",
      "        [ 8,  3],\n",
      "        [ 8,  4],\n",
      "        [ 8,  5],\n",
      "        [ 8,  6],\n",
      "        [ 9,  0],\n",
      "        [ 9,  1],\n",
      "        [ 9,  2],\n",
      "        [ 9,  3],\n",
      "        [ 9,  4],\n",
      "        [ 9,  5],\n",
      "        [ 9,  6],\n",
      "        [10,  0],\n",
      "        [10,  1],\n",
      "        [10,  2],\n",
      "        [10,  3],\n",
      "        [10,  4],\n",
      "        [10,  5],\n",
      "        [10,  6],\n",
      "        [11,  0],\n",
      "        [11,  1],\n",
      "        [11,  2],\n",
      "        [11,  3],\n",
      "        [11,  4],\n",
      "        [11,  5],\n",
      "        [11,  6],\n",
      "        [12,  0],\n",
      "        [12,  1],\n",
      "        [12,  2],\n",
      "        [12,  3],\n",
      "        [12,  4],\n",
      "        [12,  5],\n",
      "        [12,  6],\n",
      "        [13,  0],\n",
      "        [13,  1],\n",
      "        [13,  2],\n",
      "        [13,  3],\n",
      "        [13,  4],\n",
      "        [13,  5],\n",
      "        [13,  6],\n",
      "        [14,  0],\n",
      "        [14,  1],\n",
      "        [14,  2],\n",
      "        [14,  3],\n",
      "        [14,  4],\n",
      "        [14,  5],\n",
      "        [14,  6],\n",
      "        [15,  0],\n",
      "        [15,  1],\n",
      "        [15,  2],\n",
      "        [15,  3],\n",
      "        [15,  4],\n",
      "        [15,  5],\n",
      "        [15,  6]])\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
