{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-21T19:54:55.783094Z",
     "start_time": "2024-03-21T19:54:52.640717Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n        [1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1],\n        [1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1],\n        [1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1],\n        [1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0],\n        [1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1],\n        [0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1],\n        [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n        [1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0],\n        [1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0],\n        [1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0]], dtype=torch.int32)"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Original matrix provided by the user\n",
    "matrix = torch.tensor([\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1],\n",
    "    [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0],\n",
    "    [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1],\n",
    "    [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1],\n",
    "    [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
    "    [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1],\n",
    "    [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0]\n",
    "], dtype=torch.int)\n",
    "\n",
    "\n",
    "# Compute the transpose of the matrix\n",
    "transposed_matrix = matrix.t()\n",
    "\n",
    "transposed_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to create tensor with negative dimension -5: [-5, 5]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 26\u001B[0m\n\u001B[1;32m      9\u001B[0m n, k \u001B[38;5;241m=\u001B[39m matrix\u001B[38;5;241m.\u001B[39mshape\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# Create an identity matrix of size n-k x n-k, and append it to a zero matrix of size n-k x k\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# to form the basic structure of H. This step needs to be adjusted based on the specific requirements\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# and properties of the provided G matrix, as the direct approach might not apply.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     24\u001B[0m \n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# Placeholder H matrix generation (illustrative and needs adjustment)\u001B[39;00m\n\u001B[0;32m---> 26\u001B[0m H \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mzeros\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     27\u001B[0m H[:, k:] \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39meye(n\u001B[38;5;241m-\u001B[39mk)\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m# Print the placeholder H matrix (this is not the final H for the provided G without further adjustments)\u001B[39;00m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Trying to create tensor with negative dimension -5: [-5, 5]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "matrix = torch.tensor([[1, 0, 0, 0, 0, 1, 1, 0, 0, 0],\n",
    "        [0, 1, 0, 0, 0, 0, 1, 1, 0, 0],\n",
    "        [0, 0, 1, 0, 0, 0, 0, 1, 1, 0],\n",
    "        [0, 0, 0, 1, 0, 0, 0, 0, 1, 1],\n",
    "        [0, 0, 0, 0, 1, 1, 0, 0, 0, 1]], dtype=torch.int)\n",
    "# Number of rows and columns in G\n",
    "n, k = matrix.shape\n",
    "\n",
    "# Create an identity matrix of size n-k x n-k, and append it to a zero matrix of size n-k x k\n",
    "# to form the basic structure of H. This step needs to be adjusted based on the specific requirements\n",
    "# and properties of the provided G matrix, as the direct approach might not apply.\n",
    "# Here, we're creating a simple placeholder for H to illustrate the approach.\n",
    "# This will not directly result in a valid H for the provided G without further adjustments.\n",
    "\n",
    "# Determine the size for the parity part (n-k) and message part (k) based on G's structure\n",
    "# Assuming n = 7 (from the structure of G), but we need to define k correctly based on your specific code structure.\n",
    "# For the sake of an example, we'll proceed with a placeholder approach.\n",
    "\n",
    "# This is a simplified and not directly applicable method since the exact structure and properties of G\n",
    "# (like whether it's systematic or not) are not entirely clear from the question.\n",
    "# Adjustments based on the specific code and its properties are necessary.\n",
    "\n",
    "# Placeholder H matrix generation (illustrative and needs adjustment)\n",
    "H = torch.zeros((n-k, n), dtype=torch.float)\n",
    "H[:, k:] = torch.eye(n-k)\n",
    "\n",
    "# Print the placeholder H matrix (this is not the final H for the provided G without further adjustments)\n",
    "print(H.to(torch.int))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T15:29:14.686483Z",
     "start_time": "2024-03-18T15:29:14.642271Z"
    }
   },
   "id": "96966ee2f38b0fce",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "order = 10\n",
    "# modified_model_pth = f\"Hamming74/Result/Model/SLNN_decrease_hidden.weight_cpu/SLNN_model_hiddenlayer{threshold}_BER0.pth\"\n",
    "modified_model_pth = \"Hamming74/Result/Model/SLNN_edgedeleted43_output.weight_cpu/SLNN7_edgedeleted43_order55.pth\"\n",
    "print(\"modified model:\", torch.load(modified_model_pth))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db24212b32807a23"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 1, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Your input tensor\n",
    "input_tensor = torch.tensor([[ 0.0000,  0.0000,  0.7195,  0.0000,  0.0000,  0.7038,  0.0000],\n",
    "        [ 0.0000,  0.0000,  0.0000,  0.7659,  0.0000,  0.7190,  0.0000],\n",
    "        [ 0.0000,  0.0000,  0.0000,  0.0000, -1.1143,  0.0000,  0.0000],\n",
    "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.8998],\n",
    "        [ 0.0000,  1.2054,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
    "        [ 0.6529,  0.0000,  0.6603,  0.0000,  0.0000,  0.0000,  0.0000],\n",
    "        [-0.6563,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
    "\n",
    "# Apply thresholding operation\n",
    "output_tensor = torch.where(input_tensor != 0, torch.tensor(1), torch.tensor(0))\n",
    "print(output_tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T17:16:32.065665Z",
     "start_time": "2024-02-28T17:16:32.055763Z"
    }
   },
   "id": "68f0ffc4c3f39ba6",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.1078, 0.1085, 0.1102, 0.1127, 0.1129, 0.1130, 0.1135, 0.1142, 0.1149,\n        0.1151, 0.1153, 0.1165, 0.1183, 0.1185, 0.1190, 0.1202, 0.1210, 0.1211,\n        0.1218, 0.1238, 0.1240, 0.1242, 0.1247, 0.1255, 0.1261, 0.1266, 0.1269,\n        0.1281, 0.1303, 0.1310, 0.1327, 0.1337, 0.1356, 0.1365, 0.1369, 0.1379,\n        0.1383, 0.1388, 0.1389, 0.1400, 0.1403, 0.1407, 0.1415, 0.1423, 0.1426,\n        0.1427, 0.1435, 0.1435, 0.1439, 0.1444, 0.1448, 0.1450, 0.1451, 0.1452,\n        0.1461, 0.1461, 0.1467, 0.1468, 0.1469, 0.1471, 0.1473, 0.1475, 0.1476,\n        0.1478, 0.1479, 0.1480, 0.1480, 0.1487, 0.1489, 0.1490, 0.1490, 0.1502,\n        0.1502, 0.1505, 0.1509, 0.1510, 0.1515, 0.1522, 0.1523, 0.1529, 0.1533,\n        0.1534, 0.1538, 0.1538, 0.1539, 0.1541, 0.1544, 0.1553, 0.1555, 0.1558,\n        0.1563, 0.1565, 0.1567, 0.1572, 0.1582, 0.1586, 0.1587, 0.1598, 0.1604,\n        0.1606, 0.1611, 0.1619, 0.1637, 0.1669, 0.1674, 0.1678, 0.1696, 0.1711,\n        0.1742, 0.1779, 0.1784, 0.1823])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 定义张量\n",
    "tensor = torch.tensor(\n",
    "    [0.1238, 0.1448, 0.1637, 0.1490, 0.1587, 0.1085, 0.1515,\n",
    "        0.1369, 0.1183, 0.1619, 0.1586, 0.1598, 0.1078, 0.1567,\n",
    "        0.1310, 0.1190, 0.1678, 0.1502, 0.1563, 0.1185, 0.1572,\n",
    "        0.1337, 0.1403, 0.1611, 0.1539, 0.1502, 0.1129, 0.1480,\n",
    "        0.1266, 0.1135, 0.1823, 0.1553, 0.1538, 0.1127, 0.1558,\n",
    "        0.1240, 0.1415, 0.1696, 0.1538, 0.1533, 0.1102, 0.1476,\n",
    "        0.1261, 0.1356, 0.1779, 0.1461, 0.1490, 0.1142, 0.1510,\n",
    "        0.1255, 0.1149, 0.1784, 0.1604, 0.1534, 0.1151, 0.1523,\n",
    "        0.1218, 0.1400, 0.1565, 0.1473, 0.1423, 0.1471, 0.1451,\n",
    "        0.1303, 0.1165, 0.1582, 0.1541, 0.1452, 0.1489, 0.1468,\n",
    "        0.1247, 0.1202, 0.1606, 0.1487, 0.1479, 0.1435, 0.1544,\n",
    "        0.1281, 0.1388, 0.1555, 0.1509, 0.1461, 0.1379, 0.1427,\n",
    "        0.1269, 0.1130, 0.1711, 0.1450, 0.1505, 0.1469, 0.1467,\n",
    "        0.1210, 0.1327, 0.1669, 0.1475, 0.1435, 0.1439, 0.1444,\n",
    "        0.1242, 0.1407, 0.1674, 0.1389, 0.1480, 0.1383, 0.1426,\n",
    "        0.1211, 0.1153, 0.1742, 0.1522, 0.1529, 0.1365, 0.1478])\n",
    "\n",
    "sorted_tensor, indices = tensor.sort()\n",
    "\n",
    "sorted_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T14:25:37.374489Z",
     "start_time": "2024-03-09T14:25:37.365005Z"
    }
   },
   "id": "d026bf1fcce61c25",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[htbp]\n",
      "    \\centering\n",
      "    \\begin{tabular}{|c|c|c|c|c|c|c|c|}\n",
      "        \\hline\n",
      "        \\textbf{Input Layer Neurons} & \\textbf{} & \\textbf{} & \\textbf{} & \\textbf{} & \\textbf{} & \\textbf{} & \\textbf{}\\\\\n",
      "        \\hline\n",
      "        1 & 0.5807 & 0.0 & 0.7195 & -0.5115 & -0.1748 & 0.7038 & -0.1317 \\\\\n",
      "        \\hline\n",
      "        2 & 0.1696 & 0.0 & -0.0854 & 0.7659 & -0.4676 & 0.719 & 0.343 \\\\\n",
      "        \\hline\n",
      "        3 & 0.0835 & 0.0884 & 0.1289 & -0.2663 & -1.1143 & -0.3482 & 0.3153 \\\\\n",
      "        \\hline\n",
      "        4 & 0.497 & 0.0 & -0.4501 & 0.0 & -0.3754 & 0.0885 & -0.8998 \\\\\n",
      "        \\hline\n",
      "        5 & 0.0 & 1.2054 & 0.1353 & 0.1299 & -0.1366 & 0.0732 & -0.0926 \\\\\n",
      "        \\hline\n",
      "        6 & 0.6529 & 0.0 & 0.6603 & 0.608 & -0.0896 & -0.5479 & 0.0 \\\\\n",
      "        \\hline\n",
      "        7 & -0.6563 & -0.0928 & 0.5427 & 0.294 & -0.3917 & 0.2601 & -0.624 \\\\\n",
      "        \\hline\n",
      "    \\end{tabular}\n",
      "    \\caption{SLNN, N = 7, normalized absolute weights}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "# 数据列表\n",
    "data = [[ 0.5807,  0.0000,  0.7195, -0.5115, -0.1748,  0.7038, -0.1317],\n",
    "        [ 0.1696,  0.0000, -0.0854,  0.7659, -0.4676,  0.7190,  0.3430],\n",
    "        [ 0.0835,  0.0884,  0.1289, -0.2663, -1.1143, -0.3482,  0.3153],\n",
    "        [ 0.4970,  0.0000, -0.4501,  0.0000, -0.3754,  0.0885, -0.8998],\n",
    "        [ 0.0000,  1.2054,  0.1353,  0.1299, -0.1366,  0.0732, -0.0926],\n",
    "        [ 0.6529,  0.0000,  0.6603,  0.6080, -0.0896, -0.5479,  0.0000],\n",
    "        [-0.6563, -0.0928,  0.5427,  0.2940, -0.3917,  0.2601, -0.6240]]\n",
    "\n",
    "# 生成 LaTeX 代码\n",
    "latex_code = \"\\\\begin{table}[htbp]\\n\" \\\n",
    "             \"    \\\\centering\\n\" \\\n",
    "             \"    \\\\begin{tabular}{|c|c|c|c|c|c|c|c|}\\n\" \\\n",
    "             \"        \\\\hline\\n\" \\\n",
    "             \"        \\\\textbf{Input Layer Neurons} & \\\\textbf{} & \\\\textbf{} & \\\\textbf{} & \\\\textbf{} & \" \\\n",
    "             \"\\\\textbf{} & \\\\textbf{} & \\\\textbf{}\\\\\\\\\\n\" \\\n",
    "             \"        \\\\hline\\n\"\n",
    "\n",
    "# 遍历数据列表并生成表格行\n",
    "for i, row in enumerate(data):\n",
    "    latex_code += f\"        {i+1} & {' & '.join(map(str, row))} \\\\\\\\\\n\"\n",
    "    latex_code += \"        \\\\hline\\n\"\n",
    "\n",
    "# 添加表格结尾\n",
    "latex_code += \"    \\\\end{tabular}\\n\" \\\n",
    "              \"    \\\\caption{SLNN, N = 7, normalized absolute weights}\\n\" \\\n",
    "              \"\\\\end{table}\"\n",
    "\n",
    "# 输出 LaTeX 代码\n",
    "print(latex_code)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T14:39:55.995288Z",
     "start_time": "2024-02-25T14:39:55.990206Z"
    }
   },
   "id": "8972d4756cfb0b28",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snr 0\n",
      "order tensor(1, dtype=torch.int32)\n",
      "order tensor(2, dtype=torch.int32)\n",
      "order tensor(3, dtype=torch.int32)\n",
      "order tensor(4, dtype=torch.int32)\n",
      "order tensor(5, dtype=torch.int32)\n",
      "order tensor(6, dtype=torch.int32)\n",
      "order tensor(7, dtype=torch.int32)\n",
      "snr 8\n",
      "order tensor(1, dtype=torch.int32)\n",
      "order tensor(2, dtype=torch.int32)\n",
      "order tensor(3, dtype=torch.int32)\n",
      "order tensor(4, dtype=torch.int32)\n",
      "order tensor(5, dtype=torch.int32)\n",
      "order tensor(6, dtype=torch.int32)\n",
      "order tensor(7, dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "order = torch.arange(1, 8, 1).to(torch.int)\n",
    "\n",
    "snr = [0, 8]\n",
    "for i in range(len(snr)):\n",
    "    print(\"snr\", snr[i])\n",
    "\n",
    "    for j in range(len(order)):\n",
    "        print(\"order\", order[j])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T13:48:28.919075Z",
     "start_time": "2024-03-08T13:48:27.832748Z"
    }
   },
   "id": "e40424615971445",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 255)\n"
     ]
    }
   ],
   "source": [
    "import galois\n",
    "\n",
    "# Initialize your BCH code\n",
    "bch = galois.BCH(255, 239)\n",
    "print(bch.H.shape)\n",
    "\n",
    "# # Convert the generator polynomial to a list of integers (for compatibility with the join method)\n",
    "# # and then convert each integer to a string.\n",
    "# generator_polynomial_as_strings = list(map(str, bch.G))\n",
    "# \n",
    "# # Join the string representations with commas to create a single string that is CSV-friendly\n",
    "# csv_content = ','.join(generator_polynomial_as_strings)\n",
    "# \n",
    "# # Write the CSV content to a file\n",
    "# with open('BCH255_239.csv', 'w') as file:\n",
    "#     file.write(csv_content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T17:39:47.741303Z",
     "start_time": "2024-03-15T17:39:47.685144Z"
    }
   },
   "id": "d3e913a7fa25ba6e",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 10\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m SLNN_hidden_size \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m24\u001B[39m, \u001B[38;5;241m25\u001B[39m, \u001B[38;5;241m26\u001B[39m, \u001B[38;5;241m27\u001B[39m, \u001B[38;5;241m28\u001B[39m, [\u001B[38;5;241m25\u001B[39m, \u001B[38;5;241m25\u001B[39m], [\u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m20\u001B[39m], [\u001B[38;5;241m20\u001B[39m, \u001B[38;5;241m100\u001B[39m], [\u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m25\u001B[39m], [\u001B[38;5;241m25\u001B[39m, \u001B[38;5;241m100\u001B[39m]]\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;28mlen\u001B[39m(SLNN_hidden_size))\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m2\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mSLNN_hidden_size\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[0;31mTypeError\u001B[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "SLNN_hidden_size = [24, 25, 26, 27, 28, [25, 25], [100, 20], [20, 100], [100, 25], [25, 100]]\n",
    "print(\"1\",len(SLNN_hidden_size))\n",
    "print(\"2\",len(SLNN_hidden_size[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T15:23:42.764106Z",
     "start_time": "2024-03-19T15:23:42.644526Z"
    }
   },
   "id": "1145f2ea05f18c8b",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m SLNN_hidden_size1 \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m24\u001B[39m, \u001B[38;5;241m25\u001B[39m, \u001B[38;5;241m26\u001B[39m, \u001B[38;5;241m27\u001B[39m, \u001B[38;5;241m28\u001B[39m, [\u001B[38;5;241m25\u001B[39m, \u001B[38;5;241m25\u001B[39m], [\u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m20\u001B[39m], [\u001B[38;5;241m20\u001B[39m, \u001B[38;5;241m100\u001B[39m], [\u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m25\u001B[39m], [\u001B[38;5;241m25\u001B[39m, \u001B[38;5;241m100\u001B[39m]]\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m SLNN_hidden_size1:\n\u001B[0;32m----> 3\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[43mi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'int' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "SLNN_hidden_size1 = [24, 25, 26, 27, 28, [25, 25], [100, 20], [20, 100], [100, 25], [25, 100]]\n",
    "for i in SLNN_hidden_size1:\n",
    "    print(i.shape)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T21:17:34.788058Z",
     "start_time": "2024-03-20T21:17:34.757248Z"
    }
   },
   "id": "a6adae8bcb8aa6bd",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e134a8d8c5e2061c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
