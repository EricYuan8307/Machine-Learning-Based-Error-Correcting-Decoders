{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-01T10:55:02.436144Z",
     "start_time": "2024-03-01T10:55:01.285661Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 1, 1, 0, 0, 0, 0],\n        [1, 0, 0, 1, 1, 0, 0],\n        [0, 1, 0, 1, 0, 1, 0],\n        [1, 1, 0, 1, 0, 0, 1]], dtype=torch.int32)"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Original matrix provided by the user\n",
    "matrix = torch.tensor([[1, 1, 0, 1],\n",
    "                                          [1, 0, 1, 1],\n",
    "                                          [1, 0, 0, 0],\n",
    "                                          [0, 1, 1, 1],\n",
    "                                          [0, 1, 0, 0],\n",
    "                                          [0, 0, 1, 0],\n",
    "                                          [0, 0, 0, 1]], dtype=torch.int)\n",
    "\n",
    "\n",
    "# Compute the transpose of the matrix\n",
    "transposed_matrix = matrix.t()\n",
    "\n",
    "transposed_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "matrix = torch.tensor([[1, 1, 0, 1],\n",
    "                      [1, 0, 1, 1],\n",
    "                      [1, 0, 0, 0],\n",
    "                      [0, 1, 1, 1],\n",
    "                      [0, 1, 0, 0],\n",
    "                      [0, 0, 1, 0],\n",
    "                      [0, 0, 0, 1]], dtype=torch.int)\n",
    "# Number of rows and columns in G\n",
    "n, k = matrix.shape\n",
    "\n",
    "# Create an identity matrix of size n-k x n-k, and append it to a zero matrix of size n-k x k\n",
    "# to form the basic structure of H. This step needs to be adjusted based on the specific requirements\n",
    "# and properties of the provided G matrix, as the direct approach might not apply.\n",
    "# Here, we're creating a simple placeholder for H to illustrate the approach.\n",
    "# This will not directly result in a valid H for the provided G without further adjustments.\n",
    "\n",
    "# Determine the size for the parity part (n-k) and message part (k) based on G's structure\n",
    "# Assuming n = 7 (from the structure of G), but we need to define k correctly based on your specific code structure.\n",
    "# For the sake of an example, we'll proceed with a placeholder approach.\n",
    "\n",
    "# This is a simplified and not directly applicable method since the exact structure and properties of G\n",
    "# (like whether it's systematic or not) are not entirely clear from the question.\n",
    "# Adjustments based on the specific code and its properties are necessary.\n",
    "\n",
    "# Placeholder H matrix generation (illustrative and needs adjustment)\n",
    "H = torch.zeros((n-k, n), dtype=torch.float)\n",
    "H[:, k:] = torch.eye(n-k)\n",
    "\n",
    "# Print the placeholder H matrix (this is not the final H for the provided G without further adjustments)\n",
    "print(H)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96966ee2f38b0fce"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "order = 10\n",
    "# modified_model_pth = f\"Hamming74/Result/Model/SLNN_decrease_hidden.weight_cpu/SLNN_model_hiddenlayer{threshold}_BER0.pth\"\n",
    "modified_model_pth = \"Hamming74/Result/Model/SLNN_edgedeleted43_output.weight_cpu/SLNN7_edgedeleted43_order55.pth\"\n",
    "print(\"modified model:\", torch.load(modified_model_pth))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db24212b32807a23"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 1, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Your input tensor\n",
    "input_tensor = torch.tensor([[ 0.0000,  0.0000,  0.7195,  0.0000,  0.0000,  0.7038,  0.0000],\n",
    "        [ 0.0000,  0.0000,  0.0000,  0.7659,  0.0000,  0.7190,  0.0000],\n",
    "        [ 0.0000,  0.0000,  0.0000,  0.0000, -1.1143,  0.0000,  0.0000],\n",
    "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.8998],\n",
    "        [ 0.0000,  1.2054,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
    "        [ 0.6529,  0.0000,  0.6603,  0.0000,  0.0000,  0.0000,  0.0000],\n",
    "        [-0.6563,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
    "\n",
    "# Apply thresholding operation\n",
    "output_tensor = torch.where(input_tensor != 0, torch.tensor(1), torch.tensor(0))\n",
    "print(output_tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T17:16:32.065665Z",
     "start_time": "2024-02-28T17:16:32.055763Z"
    }
   },
   "id": "68f0ffc4c3f39ba6",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.1078, 0.1085, 0.1102, 0.1127, 0.1129, 0.1130, 0.1135, 0.1142, 0.1149,\n        0.1151, 0.1153, 0.1165, 0.1183, 0.1185, 0.1190, 0.1202, 0.1210, 0.1211,\n        0.1218, 0.1238, 0.1240, 0.1242, 0.1247, 0.1255, 0.1261, 0.1266, 0.1269,\n        0.1281, 0.1303, 0.1310, 0.1327, 0.1337, 0.1356, 0.1365, 0.1369, 0.1379,\n        0.1383, 0.1388, 0.1389, 0.1400, 0.1403, 0.1407, 0.1415, 0.1423, 0.1426,\n        0.1427, 0.1435, 0.1435, 0.1439, 0.1444, 0.1448, 0.1450, 0.1451, 0.1452,\n        0.1461, 0.1461, 0.1467, 0.1468, 0.1469, 0.1471, 0.1473, 0.1475, 0.1476,\n        0.1478, 0.1479, 0.1480, 0.1480, 0.1487, 0.1489, 0.1490, 0.1490, 0.1502,\n        0.1502, 0.1505, 0.1509, 0.1510, 0.1515, 0.1522, 0.1523, 0.1529, 0.1533,\n        0.1534, 0.1538, 0.1538, 0.1539, 0.1541, 0.1544, 0.1553, 0.1555, 0.1558,\n        0.1563, 0.1565, 0.1567, 0.1572, 0.1582, 0.1586, 0.1587, 0.1598, 0.1604,\n        0.1606, 0.1611, 0.1619, 0.1637, 0.1669, 0.1674, 0.1678, 0.1696, 0.1711,\n        0.1742, 0.1779, 0.1784, 0.1823])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 定义张量\n",
    "tensor = torch.tensor(\n",
    "    [0.1238, 0.1448, 0.1637, 0.1490, 0.1587, 0.1085, 0.1515,\n",
    "        0.1369, 0.1183, 0.1619, 0.1586, 0.1598, 0.1078, 0.1567,\n",
    "        0.1310, 0.1190, 0.1678, 0.1502, 0.1563, 0.1185, 0.1572,\n",
    "        0.1337, 0.1403, 0.1611, 0.1539, 0.1502, 0.1129, 0.1480,\n",
    "        0.1266, 0.1135, 0.1823, 0.1553, 0.1538, 0.1127, 0.1558,\n",
    "        0.1240, 0.1415, 0.1696, 0.1538, 0.1533, 0.1102, 0.1476,\n",
    "        0.1261, 0.1356, 0.1779, 0.1461, 0.1490, 0.1142, 0.1510,\n",
    "        0.1255, 0.1149, 0.1784, 0.1604, 0.1534, 0.1151, 0.1523,\n",
    "        0.1218, 0.1400, 0.1565, 0.1473, 0.1423, 0.1471, 0.1451,\n",
    "        0.1303, 0.1165, 0.1582, 0.1541, 0.1452, 0.1489, 0.1468,\n",
    "        0.1247, 0.1202, 0.1606, 0.1487, 0.1479, 0.1435, 0.1544,\n",
    "        0.1281, 0.1388, 0.1555, 0.1509, 0.1461, 0.1379, 0.1427,\n",
    "        0.1269, 0.1130, 0.1711, 0.1450, 0.1505, 0.1469, 0.1467,\n",
    "        0.1210, 0.1327, 0.1669, 0.1475, 0.1435, 0.1439, 0.1444,\n",
    "        0.1242, 0.1407, 0.1674, 0.1389, 0.1480, 0.1383, 0.1426,\n",
    "        0.1211, 0.1153, 0.1742, 0.1522, 0.1529, 0.1365, 0.1478])\n",
    "\n",
    "sorted_tensor, indices = tensor.sort()\n",
    "\n",
    "sorted_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T14:25:37.374489Z",
     "start_time": "2024-03-09T14:25:37.365005Z"
    }
   },
   "id": "d026bf1fcce61c25",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[htbp]\n",
      "    \\centering\n",
      "    \\begin{tabular}{|c|c|c|c|c|c|c|c|}\n",
      "        \\hline\n",
      "        \\textbf{Input Layer Neurons} & \\textbf{} & \\textbf{} & \\textbf{} & \\textbf{} & \\textbf{} & \\textbf{} & \\textbf{}\\\\\n",
      "        \\hline\n",
      "        1 & 0.5807 & 0.0 & 0.7195 & -0.5115 & -0.1748 & 0.7038 & -0.1317 \\\\\n",
      "        \\hline\n",
      "        2 & 0.1696 & 0.0 & -0.0854 & 0.7659 & -0.4676 & 0.719 & 0.343 \\\\\n",
      "        \\hline\n",
      "        3 & 0.0835 & 0.0884 & 0.1289 & -0.2663 & -1.1143 & -0.3482 & 0.3153 \\\\\n",
      "        \\hline\n",
      "        4 & 0.497 & 0.0 & -0.4501 & 0.0 & -0.3754 & 0.0885 & -0.8998 \\\\\n",
      "        \\hline\n",
      "        5 & 0.0 & 1.2054 & 0.1353 & 0.1299 & -0.1366 & 0.0732 & -0.0926 \\\\\n",
      "        \\hline\n",
      "        6 & 0.6529 & 0.0 & 0.6603 & 0.608 & -0.0896 & -0.5479 & 0.0 \\\\\n",
      "        \\hline\n",
      "        7 & -0.6563 & -0.0928 & 0.5427 & 0.294 & -0.3917 & 0.2601 & -0.624 \\\\\n",
      "        \\hline\n",
      "    \\end{tabular}\n",
      "    \\caption{SLNN, N = 7, normalized absolute weights}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "# 数据列表\n",
    "data = [[ 0.5807,  0.0000,  0.7195, -0.5115, -0.1748,  0.7038, -0.1317],\n",
    "        [ 0.1696,  0.0000, -0.0854,  0.7659, -0.4676,  0.7190,  0.3430],\n",
    "        [ 0.0835,  0.0884,  0.1289, -0.2663, -1.1143, -0.3482,  0.3153],\n",
    "        [ 0.4970,  0.0000, -0.4501,  0.0000, -0.3754,  0.0885, -0.8998],\n",
    "        [ 0.0000,  1.2054,  0.1353,  0.1299, -0.1366,  0.0732, -0.0926],\n",
    "        [ 0.6529,  0.0000,  0.6603,  0.6080, -0.0896, -0.5479,  0.0000],\n",
    "        [-0.6563, -0.0928,  0.5427,  0.2940, -0.3917,  0.2601, -0.6240]]\n",
    "\n",
    "# 生成 LaTeX 代码\n",
    "latex_code = \"\\\\begin{table}[htbp]\\n\" \\\n",
    "             \"    \\\\centering\\n\" \\\n",
    "             \"    \\\\begin{tabular}{|c|c|c|c|c|c|c|c|}\\n\" \\\n",
    "             \"        \\\\hline\\n\" \\\n",
    "             \"        \\\\textbf{Input Layer Neurons} & \\\\textbf{} & \\\\textbf{} & \\\\textbf{} & \\\\textbf{} & \" \\\n",
    "             \"\\\\textbf{} & \\\\textbf{} & \\\\textbf{}\\\\\\\\\\n\" \\\n",
    "             \"        \\\\hline\\n\"\n",
    "\n",
    "# 遍历数据列表并生成表格行\n",
    "for i, row in enumerate(data):\n",
    "    latex_code += f\"        {i+1} & {' & '.join(map(str, row))} \\\\\\\\\\n\"\n",
    "    latex_code += \"        \\\\hline\\n\"\n",
    "\n",
    "# 添加表格结尾\n",
    "latex_code += \"    \\\\end{tabular}\\n\" \\\n",
    "              \"    \\\\caption{SLNN, N = 7, normalized absolute weights}\\n\" \\\n",
    "              \"\\\\end{table}\"\n",
    "\n",
    "# 输出 LaTeX 代码\n",
    "print(latex_code)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T14:39:55.995288Z",
     "start_time": "2024-02-25T14:39:55.990206Z"
    }
   },
   "id": "8972d4756cfb0b28",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snr 0\n",
      "order tensor(1, dtype=torch.int32)\n",
      "order tensor(2, dtype=torch.int32)\n",
      "order tensor(3, dtype=torch.int32)\n",
      "order tensor(4, dtype=torch.int32)\n",
      "order tensor(5, dtype=torch.int32)\n",
      "order tensor(6, dtype=torch.int32)\n",
      "order tensor(7, dtype=torch.int32)\n",
      "snr 8\n",
      "order tensor(1, dtype=torch.int32)\n",
      "order tensor(2, dtype=torch.int32)\n",
      "order tensor(3, dtype=torch.int32)\n",
      "order tensor(4, dtype=torch.int32)\n",
      "order tensor(5, dtype=torch.int32)\n",
      "order tensor(6, dtype=torch.int32)\n",
      "order tensor(7, dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "order = torch.arange(1, 8, 1).to(torch.int)\n",
    "\n",
    "snr = [0, 8]\n",
    "for i in range(len(snr)):\n",
    "    print(\"snr\", snr[i])\n",
    "\n",
    "    for j in range(len(order)):\n",
    "        print(\"order\", order[j])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T13:48:28.919075Z",
     "start_time": "2024-03-08T13:48:27.832748Z"
    }
   },
   "id": "e40424615971445",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator matrix G:\n",
      "tensor([[-0.1848,  0.5661, -0.3813,  0.1848, -0.5661,  0.3813]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example parity check matrix H\n",
    "H = torch.tensor([[1, 1, 1, 0, 0, 0],\n",
    "                  [0, 0, 0, 1, 1, 1],\n",
    "                  [1, 0, 0, 1, 0, 0],\n",
    "                  [0, 1, 0, 0, 1, 0],\n",
    "                  [0, 0, 1, 0, 0, 1]], dtype=torch.float)\n",
    "\n",
    "# Find the null space of H to get the generator matrix G\n",
    "# This involves finding the solutions to Hx = 0\n",
    "\n",
    "# Using SVD (Singular Value Decomposition) to find the null space\n",
    "u, s, v = torch.svd(H)\n",
    "\n",
    "# The null space is spanned by the columns of V corresponding to zero singular values in S\n",
    "# In practice, due to numerical precision, we consider singular values close to zero as zero\n",
    "tolerance = 1e-5\n",
    "null_mask = (s < tolerance).nonzero(as_tuple=True)[0]\n",
    "G = v[:, null_mask]\n",
    "\n",
    "# Since G is derived from the V matrix of SVD, its columns span the null space\n",
    "# Transpose G to get the standard form (rows are codewords)\n",
    "G = G.t()\n",
    "\n",
    "print(\"Generator matrix G:\")\n",
    "print(G)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T13:00:55.298792Z",
     "start_time": "2024-03-14T13:00:52.280692Z"
    }
   },
   "id": "4c17c8d16139cdac",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "import matlab.engine\n",
    "def test(input):\n",
    "    eng = matlab.engine.start_matlab()\n",
    "    output = eng.sqrt(input)\n",
    "    eng.quit()\n",
    "    return output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T14:35:45.022523Z",
     "start_time": "2024-03-14T14:35:40.893867Z"
    }
   },
   "id": "635a4770f786e587",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 255)\n"
     ]
    }
   ],
   "source": [
    "import galois\n",
    "\n",
    "# Initialize your BCH code\n",
    "bch = galois.BCH(255, 239)\n",
    "print(bch.H.shape)\n",
    "\n",
    "# # Convert the generator polynomial to a list of integers (for compatibility with the join method)\n",
    "# # and then convert each integer to a string.\n",
    "# generator_polynomial_as_strings = list(map(str, bch.G))\n",
    "# \n",
    "# # Join the string representations with commas to create a single string that is CSV-friendly\n",
    "# csv_content = ','.join(generator_polynomial_as_strings)\n",
    "# \n",
    "# # Write the CSV content to a file\n",
    "# with open('BCH255_239.csv', 'w') as file:\n",
    "#     file.write(csv_content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T17:39:47.741303Z",
     "start_time": "2024-03-15T17:39:47.685144Z"
    }
   },
   "id": "d3e913a7fa25ba6e",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string '[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0' to float64 at row 0, column 1.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;31mValueError\u001B[0m: could not convert string to float: '[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloadtxt\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mBCH255_239.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdelimiter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m,\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/thesis/lib/python3.9/site-packages/numpy/lib/npyio.py:1373\u001B[0m, in \u001B[0;36mloadtxt\u001B[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001B[0m\n\u001B[1;32m   1370\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(delimiter, \u001B[38;5;28mbytes\u001B[39m):\n\u001B[1;32m   1371\u001B[0m     delimiter \u001B[38;5;241m=\u001B[39m delimiter\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlatin1\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m-> 1373\u001B[0m arr \u001B[38;5;241m=\u001B[39m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcomment\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcomment\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdelimiter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdelimiter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1374\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconverters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconverters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskiplines\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskiprows\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43musecols\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43musecols\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1375\u001B[0m \u001B[43m            \u001B[49m\u001B[43munpack\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43munpack\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mndmin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mndmin\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1376\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmax_rows\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_rows\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquote\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquotechar\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1378\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m arr\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/thesis/lib/python3.9/site-packages/numpy/lib/npyio.py:1016\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001B[0m\n\u001B[1;32m   1013\u001B[0m     data \u001B[38;5;241m=\u001B[39m _preprocess_comments(data, comments, encoding)\n\u001B[1;32m   1015\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m read_dtype_via_object_chunks \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1016\u001B[0m     arr \u001B[38;5;241m=\u001B[39m \u001B[43m_load_from_filelike\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1017\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdelimiter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdelimiter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcomment\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcomment\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquote\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquote\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1018\u001B[0m \u001B[43m        \u001B[49m\u001B[43mimaginary_unit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mimaginary_unit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1019\u001B[0m \u001B[43m        \u001B[49m\u001B[43musecols\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43musecols\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskiplines\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskiplines\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_rows\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_rows\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1020\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconverters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconverters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1021\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilelike\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilelike\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1022\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbyte_converters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbyte_converters\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1024\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1025\u001B[0m     \u001B[38;5;66;03m# This branch reads the file into chunks of object arrays and then\u001B[39;00m\n\u001B[1;32m   1026\u001B[0m     \u001B[38;5;66;03m# casts them to the desired actual dtype.  This ensures correct\u001B[39;00m\n\u001B[1;32m   1027\u001B[0m     \u001B[38;5;66;03m# string-length and datetime-unit discovery (like `arr.astype()`).\u001B[39;00m\n\u001B[1;32m   1028\u001B[0m     \u001B[38;5;66;03m# Due to chunking, certain error reports are less clear, currently.\u001B[39;00m\n\u001B[1;32m   1029\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m filelike:\n",
      "\u001B[0;31mValueError\u001B[0m: could not convert string '[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0' to float64 at row 0, column 1."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.loadtxt('BCH255_239.csv', delimiter=',')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T14:40:48.919233Z",
     "start_time": "2024-03-15T14:40:48.887535Z"
    }
   },
   "id": "2c13fbac01ff21e1",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expand(torch.LongTensor{[1024, 1]}, size=[1024]): the number of sizes provided (1) must be greater or equal to the number of dimensions in the tensor (2)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 19\u001B[0m\n\u001B[1;32m     17\u001B[0m num_bits \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m  \u001B[38;5;66;03m# Smaller number of bits for demonstration\u001B[39;00m\n\u001B[1;32m     18\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1024\u001B[39m  \u001B[38;5;66;03m# Number of binary codes to generate\u001B[39;00m\n\u001B[0;32m---> 19\u001B[0m binary_codebook \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate_binary_codebook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_bits\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28mprint\u001B[39m(binary_codebook)\n",
      "Cell \u001B[0;32mIn[4], line 12\u001B[0m, in \u001B[0;36mgenerate_binary_codebook\u001B[0;34m(batch_size, num_bits)\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# Convert to binary representation\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_bits):\n\u001B[0;32m---> 12\u001B[0m     \u001B[43mbinary_codebook\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_bits\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m (numbers \u001B[38;5;241m>>\u001B[39m i) \u001B[38;5;241m&\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m binary_codebook\n",
      "\u001B[0;31mRuntimeError\u001B[0m: expand(torch.LongTensor{[1024, 1]}, size=[1024]): the number of sizes provided (1) must be greater or equal to the number of dimensions in the tensor (2)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def generate_binary_codebook(batch_size, num_bits):\n",
    "    # Ensure that `batch_size` numbers are represented in `num_bits` binary format\n",
    "    binary_codebook = torch.zeros((batch_size, num_bits), dtype=torch.uint8)\n",
    "    \n",
    "    # Generate numbers and expand dimensions for binary conversion\n",
    "    numbers = torch.arange(batch_size).unsqueeze(-1)\n",
    "    \n",
    "    # Convert to binary representation\n",
    "    for i in range(num_bits):\n",
    "        binary_codebook[:, num_bits - 1 - i] = (numbers >> i) & 1\n",
    "    \n",
    "    return binary_codebook\n",
    "\n",
    "# Example usage:\n",
    "num_bits = 10  # Smaller number of bits for demonstration\n",
    "batch_size = 1024  # Number of binary codes to generate\n",
    "binary_codebook = generate_binary_codebook(batch_size, num_bits)\n",
    "print(binary_codebook)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T18:39:09.359564Z",
     "start_time": "2024-03-15T18:39:09.332428Z"
    }
   },
   "id": "38e69b819c3fd037",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1145f2ea05f18c8b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
