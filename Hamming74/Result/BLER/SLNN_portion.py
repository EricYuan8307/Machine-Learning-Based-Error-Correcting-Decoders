import matplotlib.pyplot as plt
import torch

SLNN_hidden_size = torch.arange(0, 101, 1)

BLER_SLNN_100 = [9.376706999999999681e-01, 7.200010999999999495e-01, 3.830969000000000180e-01, 1.155351000000000017e-01, 1.473760000000000001e-02,
               2.878200000000000029e-03, 3.159999999999999832e-04, 1.660000000000000031e-05, 1.739999999999999942e-05, 1.520000000000000016e-05, 
               1.749999999999999847e-05, 1.590000000000000023e-05, 1.669999999999999935e-05, 1.599999999999999928e-05, 1.410000000000000053e-05, 
               1.749999999999999847e-05, 1.220000000000000008e-05, 1.590000000000000023e-05, 1.439999999999999935e-05, 1.279999999999999942e-05, 
               1.259999999999999964e-05, 1.569999999999999876e-05, 1.299999999999999920e-05, 1.259999999999999964e-05, 1.399999999999999979e-05, 
               1.340000000000000045e-05, 1.320000000000000067e-05, 1.299999999999999920e-05, 1.390000000000000075e-05, 1.480000000000000060e-05, 
               1.360000000000000023e-05, 1.369999999999999927e-05, 1.430000000000000031e-05, 1.290000000000000016e-05, 1.509999999999999942e-05, 
               1.369999999999999927e-05, 1.279999999999999942e-05, 1.419999999999999957e-05, 1.620000000000000075e-05, 1.489999999999999964e-05, 
               1.329999999999999972e-05, 1.259999999999999964e-05, 1.270000000000000038e-05, 1.200000000000000030e-05, 1.180000000000000052e-05, 
               1.660000000000000031e-05, 1.489999999999999964e-05, 1.529999999999999920e-05, 1.469999999999999986e-05, 1.369999999999999927e-05, 
               1.270000000000000038e-05, 1.410000000000000053e-05, 1.309999999999999994e-05, 1.380000000000000001e-05, 1.290000000000000016e-05, 
               1.139999999999999927e-05, 1.239999999999999986e-05, 1.480000000000000060e-05, 1.230000000000000082e-05, 1.130000000000000023e-05, 
               1.620000000000000075e-05, 1.410000000000000053e-05, 1.509999999999999942e-05, 1.469999999999999986e-05, 1.469999999999999986e-05, 
               1.599999999999999928e-05, 1.250000000000000060e-05, 1.099999999999999971e-05, 1.419999999999999957e-05, 1.360000000000000023e-05, 
               1.270000000000000038e-05, 1.460000000000000082e-05, 1.460000000000000082e-05, 1.259999999999999964e-05, 1.259999999999999964e-05, 
               1.209999999999999935e-05, 1.369999999999999927e-05, 1.460000000000000082e-05, 1.329999999999999972e-05, 1.620000000000000075e-05, 
               1.410000000000000053e-05, 1.329999999999999972e-05, 1.410000000000000053e-05, 1.340000000000000045e-05, 1.390000000000000075e-05, 
               1.270000000000000038e-05, 1.390000000000000075e-05, 1.509999999999999942e-05, 1.469999999999999986e-05, 1.450000000000000009e-05, 
               1.340000000000000045e-05, 1.609999999999999832e-05, 1.329999999999999972e-05, 1.489999999999999964e-05, 1.520000000000000016e-05, 
               1.529999999999999920e-05, 1.480000000000000060e-05, 1.399999999999999979e-05, 1.450000000000000009e-05, 1.220000000000000008e-05, 
               1.460000000000000082e-05]

plt.semilogy(SLNN_hidden_size, BLER_SLNN_100, marker='.', label='N=7', color='blue', linestyle='--')

plt.xlabel('Number of Hidden Layer Neurons', fontsize=20)
plt.ylabel('BLER', fontsize=20)
plt.title('BLER VS number of nodes for Single-label neural decoders', fontsize=20)
plt.legend(['N=7'], loc='upper right')


plt.show()



SLNN_hidden_size = torch.arange(0, 41, 1)

BLER_SLNN_100 = [9.376706999999999681e-01, 7.200010999999999495e-01, 3.830969000000000180e-01, 1.155351000000000017e-01, 1.473760000000000001e-02,
               2.878200000000000029e-03, 3.159999999999999832e-04, 1.660000000000000031e-05, 1.739999999999999942e-05, 1.520000000000000016e-05,
               1.749999999999999847e-05, 1.590000000000000023e-05, 1.669999999999999935e-05, 1.599999999999999928e-05, 1.410000000000000053e-05,
               1.749999999999999847e-05, 1.220000000000000008e-05, 1.590000000000000023e-05, 1.439999999999999935e-05, 1.279999999999999942e-05,
               1.259999999999999964e-05, 1.569999999999999876e-05, 1.299999999999999920e-05, 1.259999999999999964e-05, 1.399999999999999979e-05,
               1.340000000000000045e-05, 1.320000000000000067e-05, 1.299999999999999920e-05, 1.390000000000000075e-05, 1.480000000000000060e-05,
               1.360000000000000023e-05, 1.369999999999999927e-05, 1.430000000000000031e-05, 1.290000000000000016e-05, 1.509999999999999942e-05,
               1.369999999999999927e-05, 1.279999999999999942e-05, 1.419999999999999957e-05, 1.620000000000000075e-05, 1.489999999999999964e-05,
               1.329999999999999972e-05]

plt.figure(figsize=(20, 10))
plt.semilogy(SLNN_hidden_size, BLER_SLNN_100, marker='.', label='N = 7', color='blue', linestyle='--')

plt.xlabel('Number of Hidden Layer Neurons', fontsize=20)
plt.ylabel('BLER', fontsize=20)
plt.title('BLER VS number of nodes for Single-label neural decoders', fontsize=20)
plt.legend(['N=7'], loc='upper right')


plt.show()