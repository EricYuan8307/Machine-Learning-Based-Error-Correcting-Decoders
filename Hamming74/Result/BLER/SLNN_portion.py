import matplotlib.pyplot as plt
import torch

SLNN_hidden_size = torch.arange(0, 101, 1)

SD_ML_74_100 = [1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05,
                1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05,
                1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05,
                1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05,
                1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05,
                1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05,
                1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05,
                1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05,
                1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05,
                1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05]

BLER_SLNN_100 = [9.376706999999999681e-01, 7.200010999999999495e-01, 3.830969000000000180e-01, 1.155351000000000017e-01, 1.473760000000000001e-02,
               2.878200000000000029e-03, 3.159999999999999832e-04, 1.660000000000000031e-05, 1.739999999999999942e-05, 1.520000000000000016e-05,
               1.749999999999999847e-05, 1.590000000000000023e-05, 1.669999999999999935e-05, 1.599999999999999928e-05, 1.410000000000000053e-05,
               1.749999999999999847e-05, 1.220000000000000008e-05, 1.590000000000000023e-05, 1.439999999999999935e-05, 1.279999999999999942e-05,
               1.259999999999999964e-05, 1.569999999999999876e-05, 1.299999999999999920e-05, 1.259999999999999964e-05, 1.399999999999999979e-05, 
               1.340000000000000045e-05, 1.320000000000000067e-05, 1.299999999999999920e-05, 1.390000000000000075e-05, 1.480000000000000060e-05, 
               1.360000000000000023e-05, 1.369999999999999927e-05, 1.430000000000000031e-05, 1.290000000000000016e-05, 1.509999999999999942e-05, 
               1.369999999999999927e-05, 1.279999999999999942e-05, 1.419999999999999957e-05, 1.620000000000000075e-05, 1.489999999999999964e-05, 
               1.329999999999999972e-05, 1.259999999999999964e-05, 1.270000000000000038e-05, 1.200000000000000030e-05, 1.180000000000000052e-05, 
               1.660000000000000031e-05, 1.489999999999999964e-05, 1.529999999999999920e-05, 1.469999999999999986e-05, 1.369999999999999927e-05, 
               1.270000000000000038e-05, 1.410000000000000053e-05, 1.309999999999999994e-05, 1.380000000000000001e-05, 1.290000000000000016e-05, 
               1.139999999999999927e-05, 1.239999999999999986e-05, 1.480000000000000060e-05, 1.230000000000000082e-05, 1.130000000000000023e-05, 
               1.620000000000000075e-05, 1.410000000000000053e-05, 1.509999999999999942e-05, 1.469999999999999986e-05, 1.469999999999999986e-05, 
               1.599999999999999928e-05, 1.250000000000000060e-05, 1.099999999999999971e-05, 1.419999999999999957e-05, 1.360000000000000023e-05, 
               1.270000000000000038e-05, 1.460000000000000082e-05, 1.460000000000000082e-05, 1.259999999999999964e-05, 1.259999999999999964e-05, 
               1.209999999999999935e-05, 1.369999999999999927e-05, 1.460000000000000082e-05, 1.329999999999999972e-05, 1.620000000000000075e-05, 
               1.410000000000000053e-05, 1.329999999999999972e-05, 1.410000000000000053e-05, 1.340000000000000045e-05, 1.390000000000000075e-05, 
               1.270000000000000038e-05, 1.390000000000000075e-05, 1.509999999999999942e-05, 1.469999999999999986e-05, 1.450000000000000009e-05, 
               1.340000000000000045e-05, 1.609999999999999832e-05, 1.329999999999999972e-05, 1.489999999999999964e-05, 1.520000000000000016e-05, 
               1.529999999999999920e-05, 1.480000000000000060e-05, 1.399999999999999979e-05, 1.450000000000000009e-05, 1.220000000000000008e-05, 
               1.460000000000000082e-05]

BLER_SLNN_modified_100 = [9.376617999999999897e-01, 7.195856000000000474e-01, 3.832143000000000077e-01, 1.150904999999999984e-01, 1.478699999999999980e-02,
                          2.877300000000000170e-03, 3.200000000000000262e-04, 1.699999999999999987e-05, 1.720000000000000134e-05, 1.390000000000000075e-05,
                          1.739999999999999942e-05, 1.639999999999999883e-05, 1.769999999999999994e-05, 1.390000000000000075e-05, 1.230000000000000082e-05,
                          1.870000000000000053e-05, 1.769999999999999994e-05, 1.320000000000000067e-05, 1.650000000000000127e-05, 1.360000000000000023e-05,
                          1.150000000000000001e-05, 1.540000000000000163e-05, 1.099999999999999971e-05, 1.139999999999999927e-05, 1.390000000000000075e-05,
                          1.430000000000000031e-05, 1.270000000000000038e-05, 1.739999999999999942e-05, 1.430000000000000031e-05, 1.299999999999999920e-05,
                          1.200000000000000030e-05, 1.559999999999999972e-05, 1.320000000000000067e-05, 1.220000000000000008e-05, 1.200000000000000030e-05,
                          1.239999999999999986e-05, 1.399999999999999979e-05, 1.270000000000000038e-05, 1.209999999999999935e-05, 1.299999999999999920e-05,
                          1.540000000000000163e-05, 1.439999999999999935e-05, 1.550000000000000068e-05, 1.509999999999999942e-05, 1.250000000000000060e-05,
                          1.390000000000000075e-05, 1.320000000000000067e-05, 1.220000000000000008e-05, 1.439999999999999935e-05, 1.450000000000000009e-05,
                          1.160000000000000075e-05, 1.200000000000000030e-05, 1.559999999999999972e-05, 1.259999999999999964e-05, 1.320000000000000067e-05,
                          1.329999999999999972e-05, 1.299999999999999920e-05, 1.290000000000000016e-05, 1.360000000000000023e-05, 1.369999999999999927e-05,
                          1.399999999999999979e-05, 1.380000000000000001e-05, 1.290000000000000016e-05, 1.410000000000000053e-05, 1.500000000000000038e-05,
                          1.340000000000000045e-05, 1.360000000000000023e-05, 1.529999999999999920e-05, 1.609999999999999832e-05, 1.460000000000000082e-05,
                          1.349999999999999949e-05, 1.430000000000000031e-05, 1.259999999999999964e-05, 1.340000000000000045e-05, 1.500000000000000038e-05,
                          1.270000000000000038e-05, 1.259999999999999964e-05, 1.450000000000000009e-05, 1.500000000000000038e-05, 1.329999999999999972e-05,
                          1.160000000000000075e-05, 1.320000000000000067e-05, 1.410000000000000053e-05, 1.399999999999999979e-05, 1.540000000000000163e-05,
                          1.609999999999999832e-05, 1.399999999999999979e-05, 1.180000000000000052e-05, 1.620000000000000075e-05, 1.709999999999999891e-05,
                          1.410000000000000053e-05, 1.430000000000000031e-05, 1.380000000000000001e-05, 1.180000000000000052e-05, 1.360000000000000023e-05,
                          1.419999999999999957e-05, 1.390000000000000075e-05, 1.360000000000000023e-05, 1.500000000000000038e-05, 1.340000000000000045e-05,
                          1.540000000000000163e-05]



plt.figure(figsize=(20, 10))
plt.semilogy(SLNN_hidden_size, BLER_SLNN_100, marker='.', label='N=7', color='blue', linestyle='--')
plt.semilogy(SLNN_hidden_size, BLER_SLNN_modified_100, marker='.', label='N=7, modified', color='red', linestyle='--')
plt.semilogy(SLNN_hidden_size, SD_ML_74_100, label='SD-Maximum Likelihood', color='black')

plt.xlabel('Number of Hidden Layer Neurons', fontsize=20)
plt.ylabel('BLER', fontsize=20)
plt.title('Hamming(7,4) BLER VS number of nodes for Single-label neural decoders, SNR = 8', fontsize=20)
plt.legend(['N=7', 'N=7, modified'], loc='upper right')


plt.show()



SLNN_hidden_size = torch.arange(0, 41, 1)

SD_ML_74_40 = [1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05,
               1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05,
               1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05,
               1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05, 1.32e-05]

BLER_SLNN_40 = [9.376706999999999681e-01, 7.200010999999999495e-01, 3.830969000000000180e-01, 1.155351000000000017e-01, 1.473760000000000001e-02,
               2.878200000000000029e-03, 3.159999999999999832e-04, 1.660000000000000031e-05, 1.739999999999999942e-05, 1.520000000000000016e-05,
               1.749999999999999847e-05, 1.590000000000000023e-05, 1.669999999999999935e-05, 1.599999999999999928e-05, 1.410000000000000053e-05,
               1.749999999999999847e-05, 1.220000000000000008e-05, 1.590000000000000023e-05, 1.439999999999999935e-05, 1.279999999999999942e-05,
               1.259999999999999964e-05, 1.569999999999999876e-05, 1.299999999999999920e-05, 1.259999999999999964e-05, 1.399999999999999979e-05,
               1.340000000000000045e-05, 1.320000000000000067e-05, 1.299999999999999920e-05, 1.390000000000000075e-05, 1.480000000000000060e-05,
               1.360000000000000023e-05, 1.369999999999999927e-05, 1.430000000000000031e-05, 1.290000000000000016e-05, 1.509999999999999942e-05,
               1.369999999999999927e-05, 1.279999999999999942e-05, 1.419999999999999957e-05, 1.620000000000000075e-05, 1.489999999999999964e-05,
               1.329999999999999972e-05]

BLER_SLNN_modified_40 = [9.376617999999999897e-01, 7.195856000000000474e-01, 3.832143000000000077e-01, 1.150904999999999984e-01, 1.478699999999999980e-02,
                2.877300000000000170e-03, 3.200000000000000262e-04, 1.699999999999999987e-05, 1.720000000000000134e-05, 1.390000000000000075e-05,
                1.739999999999999942e-05, 1.639999999999999883e-05, 1.769999999999999994e-05, 1.390000000000000075e-05, 1.230000000000000082e-05,
                1.870000000000000053e-05, 1.769999999999999994e-05, 1.320000000000000067e-05, 1.650000000000000127e-05, 1.360000000000000023e-05,
                1.150000000000000001e-05, 1.540000000000000163e-05, 1.099999999999999971e-05, 1.139999999999999927e-05, 1.390000000000000075e-05,
                1.430000000000000031e-05, 1.270000000000000038e-05, 1.739999999999999942e-05, 1.430000000000000031e-05, 1.299999999999999920e-05,
                1.200000000000000030e-05, 1.559999999999999972e-05, 1.320000000000000067e-05, 1.220000000000000008e-05, 1.200000000000000030e-05,
                1.239999999999999986e-05, 1.399999999999999979e-05, 1.270000000000000038e-05, 1.209999999999999935e-05, 1.299999999999999920e-05,
                1.540000000000000163e-05]

plt.figure(figsize=(20, 10))
plt.semilogy(SLNN_hidden_size, BLER_SLNN_40, marker='.', label='N=7', color='blue', linestyle='--')
plt.semilogy(SLNN_hidden_size, BLER_SLNN_modified_40, marker='.', label='N=7, modified', color='red', linestyle='--')
plt.semilogy(SLNN_hidden_size, SD_ML_74_40, label='SD-Maximum Likelihood', color='black')

plt.xlabel('Number of Hidden Layer Neurons', fontsize=20)
plt.ylabel('BLER', fontsize=20)
plt.title('Hamming(7,4) BLER VS number of nodes for Single-label neural decoders, SNR = 8', fontsize=20)
plt.legend(['N=7', 'N=7, modified'], loc='upper right')


plt.show()